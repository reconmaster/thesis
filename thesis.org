#+TITLE:
#+DATE:
#+AUTHOR:
#+EMAIL:
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t c:nil creator:nil d:(not "LOGBOOK") date:nil e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t
#+OPTIONS: tags:nil tasks:t tex:t timestamp:t title:t toc:nil todo:t |:t
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+LATEX_CLASS:thesis
#+STARTUP: hideblocks
# +STARTUP: latexpreview

#+BEGIN_EXPORT latex
%% Use these commands to set biographic information for the title page:
\title{Enabling Novel IGRT Imaging Trajectories with Optimization-Based Reconstruction Algorithms}
\author{Andrew Davis}
\department{Committee on Medical Physics}
\division{Biological Sciences}
\degree{Ph. D.}
\date{August, 2017}

%% Use these commands to set a dedication and epigraph text
\dedication{Dedication Text}
\epigraph{Epigraph Text}

% If you don't want a title page comment out the next line and uncomment the line after it:
\maketitle
%\omittitle

% These lines can be commented out to disable the copyright/dedication/epigraph pages
\makecopyright
\makededication
\makeepigraph

%% Make the various tables of contents
\tableofcontents
\listoffigures
\listoftables

\acknowledgments

Funding was provided in part by Varian Medical Systems, the Lawrence
H. Lanzl Fellowship (to A. D.), and NIH Grants R01 CA182264, R01
EB018102, S10 RR021039 and P30 CA14599. We are grateful to Pascal
Paysan and Dieter Seghers (also Varian) for providing and assisting
with the iTools Reconstruction software. The contents of this work are
solely the responsibility of the authors and do not necessarily
represent the official view of any of the supporting organizations.
The authors have no relevant conflicts of interest to disclose.

\abstract
% Enter Abstract here

\mainmatter
% Main body of text follows
#+END_EXPORT

* notes                                      :noexport:
  :PROPERTIES:
  :ID:       7f3d97de-795e-402a-82ac-591717f86bfd
  :END:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
** requirements
   :PROPERTIES:
   :ID:       931c9c50-bfaf-4c8e-b2cc-bcfdf62e327d
   :END:
- [[http://www.lib.uchicago.edu/e/phd/][uchicago]] dissertation guide
- [[https://github.com/zuwiki/ucetd-latex][uoc thesis]] template
* Introduction                               :intro:
  :PROPERTIES:
  :ID:       852796c3-9a3b-49da-bc08-1299e93e0768
  :END:
Tomography is the imaging technique of using a penetrating wave to
create an image of a slice in an object while either blurring or
obscuring details from other planes in the object. The ability to peer
inside an object and create a map of its contents is a powerful tool
that is routinely used in myriad applications. Today, tomographic
methods can be found being deployed in locations ranging from
border-control checkpoints to local medical clinics.

As the non-invasive nature of tomographic imaging had obvious benefits
for the field of medicine, a lot of significant advances in
tomographic technology were driven by clinical research. One such form
of tomographic imaging is computed tomography (CT) which uses
projection images acquired from different locations around the object
to compute the distribution of material densities inside the object.
Though the mathematical framework for solving this inverse problem had
been formulated by Johann Radon in 1917 and a patent for what is
essentially CT was filled in 1940 by Gabriel Frank, it was not until
1967 that the work of Allan M. Cormack and Godfrey N. Hounsfield led
to the first clinical CT scanner. For their work, Cormack and
Housfield shared the 1979 Nobel Prize in Physiology and Medicine
cite:hsieh_computed_2009.

*ADD DIAGRAM*

In a CT scanner system, an x-ray source and opposing detector
typically rotate relative to the object being imaged as x-ray
projection images are acquired at different angular positions. Through
the years of CT research, a fundamental questions has always been how
to move the source and detector the imaging system relative to the
object to obtain sufficient projection information to reconstruction a
useful tomographic image. Part of this answer must take into account
certain engineering limitations that go into building such a system.
However, this is fundamentally a question that must address the
requirements of the computational reconstruction algorithm used to
assemble the image from the x-ray projections.

** Organization
In this work, we will discuss the optimization-based,
image-reconstruction framework that enables the use of these new
scanning trajectories. In particular, we will focus on how this
approach was developed in addressing the two clinical bottlenecks of
limited axial FOV coverage and patient collisions with the linac
gantry. By using these two examples, we will hopefully not only show
the feasibility of using these non-circular trajectories, but also a
potential solution to existing clinical needs.

First, we will discuss the framework and considerations of using
optimization-based reconstruction with different scanning trajectories
in [[id:06ec01f2-e128-4baf-9ec7-4569a3aaa886][Optimization-based algorithms]]. Next, we will look at the need for
geometric calibration and discuss a method we developed to do this for
these trajectories in [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Geometric calibration]]. We will then look at
using new trajectories to address the limited axial FOV issue in [[id:eaae199f-f899-4862-af50-720895a31c36][Axial
field-of-view extension]] followed by using these trajectories to
alleviate the issue of patient collisions in [[id:99055e18-4b61-404e-9408-ebd5fd0a5d8d][Collision-avoiding
trajectories]]. Finally, we will summarize this work and discuss
possible clinical considerations with this methodology in [[id:1bade25b-80d6-4650-b8a3-baf370fa657c][Summary and
conclusions]].

* Optimization-based algorithms              :opt:
  :PROPERTIES:
  :ID:       06ec01f2-e128-4baf-9ec7-4569a3aaa886
  :END:
CT image reconstruction using a linearized imaging model of the x-ray
transform has existed since the first CT system built by Cormack and
Hounsfield.

** Background: Computed tomography
   :PROPERTIES:
   :ID:       898c8a79-a3b0-4cb2-b1be-2838c8b86426
   :END:
*** Analytic-Based Reconstruction
    :PROPERTIES:
    :ID:       20c14d08-7649-4644-b616-e86e0b7cc515
    :END:
In the 1980s, a lot of work was done to directly solve the inverse
problem for the cone-beam geometry. By modeling the projection
formation process as a Radon transform or an X-ray transform,
reconstruction algorithms were formulated by finding an analytic-based
inverse to the transform. However, for the inverse to be exact, it
needed to meet strict requirements such as Tuy's condition which
states that every plane through the object must intersect the source
trajectory cite:tuy_inversion_1983. While some exceptions to this
requirement were found, it demonstrates the strict requirements on the
types of scanning trajectories for which an exact inverse could be
found.

The circular scanning trajectory that is ubiquitous in the clinic for
CBCT is one trajectory that fails to meet Tuy's condition. The most
popular reconstruction algorithm for the circular CBCT trajectory is
the filtered-backprojection (FBP) algorithm proposed by Feldkamp,
Davis, and Kress (FDK) cite:feldkamp_practical_1984 which is still the
industry standard. FDK is only an exact inversion to the Radon
transform on the midplane containing the circular source
trajectory. For transaxial planes other than the midplane, a
quasi-redundancy in the scanning data is assumed. It is the violation
of this assumption which leads to cone-angle artifacts. These
artifacts become more severe at larger cone angles where this
assumption is less applicable.

The presence of cone-angle artifacts in FDK reconstructions from the
incomplete data acquired with circular scanning trajectories led to
research into inverse algorithms for cone-beam scans from
theoretically complete trajectories such as a circle plus a line
cite:zeng_cone-beam_1992. It became apparent in the reconstruction
results that implementing these direct reconstruction algorithms did
not produce the anticipated results cite:kudo_derivation_1994. Severe
artifacts and numerical errors were found in the reconstructions due
to factors such as truncation introducing high-frequency components
that are amplified in the filtration process.

*** Optimization-Based Reconstruction
    :PROPERTIES:
    :ID:       07e91084-61be-43d3-a905-65ef0ab997a4
    :END:
Analytic-based reconstruction algorithms are formulated by explicitly
finding an inverse to the X-ray transform
\begin{equation}
  \label{eq:xray}
  g(\mathbf{r}_0,\hat{\theta})=\int_0^{\infty}f(\mathbf{r}_0+t\hat{\theta})dt,
\end{equation}
where the data function $g$ is acquired by integrating along the ray
from the source at $\mathbf{r}_0$ in the direction $\hat{\theta}$ through
the object function $f$. A fundamental problem with these
reconstruction algorithms when practically reconstructing $f$ is the
assumption of a continuous-to-continuous (CC) model. These
analytic-based reconstruction algorithms impose dense sampling
requirements for both the detector and number of views to approximate
a continuous data function. Given that the data function from the
digital detector and the numerical array for storing the reconstructed
image are both discrete, a more natural approach to the inverse
problem would be a discrete-to-discrete (DD) imaging model
cite:barrett_foundations_2003.

Iterative reconstruction algorithms are more robust because they do
implement a more accurate DD model of the imaging system. The X-ray
transform of the object function can be represented as the linear
system
\begin{equation}
  \label{eq:ddsys}
  \mathbf{g}=\mathcal{H}\mathbf{f},
\end{equation}
where $\mathbf{g}$ is the discrete $M$ pixel sampled projection on the
detector, $\mathcal{H}$ is the $M\times N$ discrete form of the X-ray
transform, and $\mathbf{f}$ is the object function represented on a N
voxel basis. As direct inversion of $\mathcal{H}$ is impractical due
to both its size and inconsistencies from factors such as noise,
optimization techniques are used to solve this system for an estimate
of the object $\widetilde{\mathbf{f}}$.

The optimization problem for these iterative reconstruction algorithms
is formulated as an objective function based on the actual data
$\mathbf{g}$ and the image model $\mathcal{H}\mathbf{f}$. An
optimization algorithm is then used to iteratively update the estimate
of $\widetilde{\mathbf{f}}$ until a suitable convergence criterion has
been met. The parameters of the optimization problem, the optimization
algorithm, and the convergence criteria are all important factors in
determining the properties of the reconstructed image and subsequently
its utility.

In applying optimization-based reconstruction to reconstruct
non-circular trajectories, we focus primarily on the well-understood
maximum-likelihood expectation maximization (MLEM)
cite:shepp_maximum_1982,dempster_maximum_1977. Previous work has shown
that these iterative algorithms are able to reconstruct clinically
useful images under scanning conditions for which analytic-based FDK
fails
cite:han_optimization-based_2012,sidky_image_2007,sidky_accurate_2006.
The reconstruction work from sparse-view data
cite:bian_evaluation_2010 alone suggests that views could be
distributed at different axial positions to acquire additional scan
information without imparting more dose than the dense set of angular
views used in current clinical circular scans with analytic-based
reconstruction.

# constrained, total-variation (TV) minimization by adaptive steepest
# descent-projection onto convex sets (ASD-POCS) cite:sidky_image_2008.

** Background: Scanning trajectories
   :PROPERTIES:
   :ID:       c90cd638-44e6-49f3-9283-29f75d163005
   :END:
*** Standard Trajectories
    :PROPERTIES:
    :ID:       6293da29-e448-4614-84b6-065af1cc6be9
    :END:
In IGRT, linac-mounted CBCT imaging systems such as Variant's TrueBeam
JV-imaging system now routinely provide patient image information.
These images are used to check the patient alignment before delivering
the radiation treatment. The circular rotation of the linac gantry
defines the acquisition trajectory for the CBCT scan. While such a
scanning trajectory provides sufficient information for an
analytic-based reconstruction of the scan volume, there are a variety
of limitations that arise from this work flow.

Due to engineering and cost restrictions, the kV detector has a
limited size. This restricts the FOV that can be imaged in a
traditional circular scan. While the offset detector technique
cite:bian_optimization-based_2013,cho_cone-beam_1995 is commonly used
to increase the transaxial FOV, the axial coverage is still very
limited cite:pearson_non-circular_2010. The reason why the limited FOV
has not been addressed by increasing the detector size is partially
due to the industry reliance on the approximate FDK algorithm
cite:pan_why_2009. For increasingly large cone angles at the ends of
the axial FOV, the approximation in the algorithm becomes increasingly
worse resulting in cone-angle artifacts cite:feldkamp_practical_1984.

Another problem with the current circular imaging trajectory is
potential linac collisions with the patient
cite:hua_practical_2004,nioutsikou_patient-specific_2003. Cases arise
when the patient is positioned in the treatment position, a CBCT image
cannot be acquired due to part of the patient being in the path of the
linac's trajectory. As the current FDK algorithm requires a trajectory
with sufficient angular coverage, the patient must be moved to a
position where the gantry can make an uninterrupted rotation around
the patient.

In both of these examples, the default circular trajectory prescribed
by FDK is insufficient for obtaining the desired tomographic
information. Furthermore, the disruption to the clinical workflow
created by these limitation introduces bottlenecks into clinical
efficiency which affects both the clinical staff as well as the
patient's comfort in the procedure. In the case of a potential patient
collision, the inability to acquire the required trajectory can even
result in forgoing the CBCT image. For these particular examples, we
investigated ways in which new trajectories enabled by
optimization-based reconstruction could alleviate the complications
imposed by the standard circular scan required by FDK.

*** Non-circular trajectories
The increased flexibility in choosing different scanning trajectories
allowed by optimization-based reconstruction methods provided two
solutions to the issues of limited axial FOV coverage and potential
patient collisions. For these two problems, we found that the existing
limitations could be resolved by using a different scanning
configuration. In each case, we proposed a trajectory that would solve
the existing problem, and then we evaluated how well the
optimization-based reconstructions compared to the clinical images
currently being used.

For the problem of the limited axial coverage, the current clinical
method of extending the FOV is to acquire two different circular scans
at different axial positions and reconstruct each circle independently
using FDK before stitching the two volumes together. Unfortunately,
the increased distortion from cone-angle artifacts at large cone
angles limits the axial separation between these two circles. This
restricted separation distance is much less than what would be
expected based simply on the coverage expected from the geometry of
the kV detector.

The use of the two circles alone provides one interesting example of a
trajectory were optimization-based reconstruction provides an
interesting advantage to the stacked-FDK method currently used. Unlike
stitching two separate reconstructions together, it is possible to
reconstruct the entire volume at once provided the system matrix is
correctly calculated to reflect the acquisition of two circles in
planes located at different axial positions relative to the patient.
In addition to the reduced cone-angle artifacts already seen in
optimization-based methods *CITE*, reconstructing both volumes
together provides additional information about the overlapping region
between the circles that further helps to reduce the cone-angle
artifacts.

In addition to improving the use of the two circles, the
optimization-based framework then allows for trajectories that can
deviate beyond the circles that are still needed for FDK. Given that
there needs to be a relative axial translation between the kV-imaging
system and the patient, we investigated if there any advantages to
acquiring some of the projection views during the axial translation
to. With the optimization-based approach, any such trajectory where
some of the views were acquired during the translation stage could be
reconstructed provided the positions of these views are accurately
represented in the system matrix.

In the case of potential patient collisions with the linac gantry, a
simple change in the scanning trajectory when such a collision arose
would be sufficient to prevent a collision. Much like the extended
axial FOV case, optimization-based reconstruction is able to handle
variations in the acquisition trajectory provided it is accurately
reflected in the system matrix. As such, there are two different ways
we studied where the scanning trajectory could be modified to avoid a
collision.

If the patient collision were to occur with the kV detector (the
closest component of the CBCT system to the patient), one possible way
to avoid that collision would be to move the kV detector away from the
patient at the collision region. This effectively changes the
magnification for that region, but the reconstruction framework is
able to reconstruct from all the views at both magnifications provided
that it is accurately modeled in the reconstruction problem. The other
trajectory modification that could solve this problem would be to move
the patient.

As with the change in magnification, the change in the patient
position does not prevent reconstruction with the optimization-based
methods provided the patient motion is correctly modeled. Moving the
patient also provides a solution to patient collisions that occur with
the linac treatment head. The MV treatment head on Varian's TrueBeam
system is actually closer to the patient than the kV detector. Unlike
the kV detector, it is not possible to change the position of the
treatment head. In this case, moving the patient would be the only
viable trajectory to avoid a collision.

* Optimization-based algorithms              :opt:
  :PROPERTIES:
  :ID:       06ec01f2-e128-4baf-9ec7-4569a3aaa886
  :END:
** notes                                     :noexport:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
- Chuck said to use this as this is enabling the trajectory work
** Introduction
   :PROPERTIES:
   :ID:       8736adf3-2606-43c1-ba5d-d3f92a74f9f8
   :END:
** Methods
   :PROPERTIES:
   :ID:       f9ebfd7f-108b-4dd3-a24c-dab617ab99dd
   :END:
*** Algorithms
**** MLEM
     :PROPERTIES:
     :ID:       e0a24b69-d136-4f9a-9e85-dc42e1d114a9
     :END:
*** Detector weighting
    :PROPERTIES:
    :ID:       cc6bcac6-a445-4dfb-8815-a95e31f517ed
    :END:
#+LABEL: fig:opt_weighting
#+BEGIN_SRC asymptote :file figures/opt/weighting.pdf :exports results :tangle no
settings.render = 0;
import geometry;
// size(8cm,0);
// unitsize(1cm)

// Affichage du repère par défaut (O,vec{i},vec_{j})
// show(defaultcoordsys);
// show(currentcoordsys);

// detector
real dlat=0, dlng=0, dvrt=50;
point det=(dvrt,dlat);

real ulen=40.0, vlen=30.0;

draw((dvrt,-ulen/2+dlat)--(dvrt,ulen/2+dlat),black);

// source
real slat=0, slng=0, svrt=-100;
point src=(svrt,slat);

draw(src--(dvrt, 0), dashed+red);
draw(src--(dvrt, -ulen/2+dlat), dashed+black);
draw(src--(dvrt, ulen/2+dlat), dashed+black);
dot("Source", src, N, red);

addMargins(0.5cm, 0.5cm);

// dot("Detector",det,N,5bp+.5blue);
// dot("Source",src,N,5bp+.5red);

// dot("Source", src)

// real a=5, b=4, theta=-70, poids=3;
// ellipse el = ellipse(origin, a, b);
// arc     ar = arc(el,(0,-b),(a,0),CCW);
// path p = (0,-b-1)--ar--(a+1,0)--(a+1,-b-1)--cycle;
// point pO = (0,0), pM=angpoint(ar,90+theta);
// abscissa abscM = nodabscissa(el,pM);
// real     timeM = abscM.x;
// vector utangM = -dir(el,timeM),
//        unormM = rotate(90)*utangM,
//        vpoids=(0,-poids),
//        vreactionN = -dot(vpoids,unormM)*unormM,
//        vfrottement = -dot(vpoids,utangM)*utangM;

// filldraw(p,lightgray,blue);
// draw(pO--pM,dashed);
// markangle("$\theta$",1.5cm,pM,origin,(1,0));

// coordsys R=cartesiansystem(pM,i=utangM,j=unormM);
// show("$M$", "$\vec{u_{\theta}}$", "$\vec{u_{r}}$", R, xpen=invisible);

// point RpM=changecoordsys(R, pM);
// show(Label("$\vec{f}$",EndPoint),RpM+vfrottement);
// show(Label("$\vec{R}$",EndPoint),RpM+vreactionN);
// show(Label("$\vec{P}$",EndPoint),RpM+vpoids);

// // size3(140,80,15);
// currentprojection=perspective(1,-1,1,up=Z);
// currentlight=White;

// // detector surface
// // path3 g=(1,0,0)..(0,1,0)..(-1,0,0)..(0,-1,0)..cycle;
// // draw(g);

// draw(O--X,red+dashed,Arrow3);
// draw(O--Y,red+dashed,Arrow3);
// draw(O--Z,red+dashed,Arrow3);

// // draw detector
// draw(((-1,-1,0)--(1,-1,0)--(1,1,0)--(-1,1,0)--cycle));

// real a=-0.4;
// real b=0.95;
// real y1=-5;
// real y2=-3y1/2;
// path A=(a,0){dir(10)}::{dir(89.5)}(0,y2);
// path B=(0,y1){dir(88.3)}::{dir(20)}(b,0);
// real c=0.5*a;
// pair z=(0,2.5);
// transform t=scale(1,15);
// transform T=inverse(scale(t.yy,t.xx));
// path[] g=shift(0,1.979)*scale(0.01)*t*
//   texpath(Label("{\it symptote}",z,0.25*E+0.169S,fontsize(24pt)));
// pair w=(0,1.7);
// pair u=intersectionpoint(A,w-1--w);

// real h=0.25*linewidth();
// real hy=(T*(h,h)).x;
// g.push(t*((a,hy)--(b,hy)..(b+hy,0)..(b,-hy)--(a,-hy)..(a-hy,0)..cycle));
// g.push(T*((h,y1)--(h,y2)..(0,y2+h)..(-h,y2)--(-h,y1)..(0,y1-h)..cycle));
// g.push(shift(0,w.y)*t*((u.x,hy)--(w.x,hy)..(w.x+hy,0)..(w.x,-hy)--(u.x,-hy)..(u.x-hy,0)..cycle));
// real f=0.75;
// g.push(point(A,0)--shift(-f*hy,f*h)*A--point(A,1)--shift(f*hy,-f*h)*reverse(A)--cycle);
// g.push(point(B,0)--shift(f*hy,-f*h)*B--point(B,1)--shift(-f*hy,f*h)*reverse(B)--cycle);

// triple H=-0.1Z;
// material m=material(lightgray,shininess=1.0);

// for(path p : g)
//   draw(extrude(p,H),m);

// surface s=surface(g);
// draw(s,red,nolight);
// draw(shift(H)*s,m);
#+END_SRC

#+CAPTION: Schematic representation of weighting factor
#+ATTR_LaTeX: :width \textwidth
#+RESULTS: fig:opt_weighting
[[file:figures/opt/weighting.pdf]]
*** Stopping criteria
    :PROPERTIES:
    :ID:       03857328-5d45-4133-b4a0-eff3fd941eaa
    :END:
** Conclusion
   :PROPERTIES:
   :ID:       0b2ab8ae-fd94-4d01-a7e0-8bef4db30078
   :END:
* Geometric calibration                      :geo:
  :PROPERTIES:
  :ID:       652970b8-4916-4190-b83b-2d6ae117c8b3
  :END:
** notes                                     :noexport:
   :PROPERTIES:
   :ID:       5c9cdd8b-721f-49b3-b136-c3282bf3659c
   :END:
** Introduction
   :PROPERTIES:
   :ID:       26feb0f0-f33e-4972-af9c-f73e0124f074
   :END:
Correctly modeling the geometric parameters of the image acquisition
is a critical tomographic image reconstruction. This is true
regardless of whether reconstruction is done with analytic-based or
optimization-based methods. Any inconsistency between the real
projection geometry and that used for image reconstruction will appear
as artifacts in the reconstructed image.

While investigating different non-standard scanning trajectories, we
found that correct geometric calibration must be performed to avoid
geometric imaging artifacts. As with the optimization-based image
reconstruction, we needed a calibration procedure that would provide a
robust calibration protocol for the different scanning configurations
we wanted to scan. This is especially true when working with
trajectories where the object is moving in addition to the source and
detector during the scan.

Previous work on geometric calibration for tomographic image
reconstruction has approached the calibration problem via analytic
cite:noo_analytic_2000,smekal_geometric_2004,cho_accurate_2005,yang_geometric_2006,daly_geometric_2008
and estimation
cite:gullberg_estimation_1990,rougee_geometrical_1993,mitschke_optimal_2000,silver_determination_2000,panetta_optimization-based_2008
frameworks. As with CT, the initial calibration efforts utilized
optimization-based methods to determine the geometric offsets from
projections of a known phantom geometry and nominal system setup. By
framing the calibration as an optimization problem, the acquisition
parameters were estimated in a way that minimized a cost function
associated with improper modeling of the acquisition geometry.

These calibration methods (analytic-based methods included) usually
rely on a known calibration phantom. This is typically a set of highly
attenuating fiducials arranged in a specific pattern. After scanning
the phantom with the system of interest, the detected fiducials are
then compared to the known geometry of the phantom. In the
analytic-based approach, the offsets are determined by solving for
parameters that would transform the projection of the phantom to match
the observed projection. In the optimization-based approach, geometric
parameters are varied to improve the match between the projection of
the modeled fiducials an the detected fiducials in the sinogram.

Both methods of performing geometric calibration have their own
strengths and weaknesses. The biggest advantage of utilizing
analytic-based calibration methods is that the sensitivity to
initialization and the sensitivity to the order of parameter variation
due to nonlinearity and coupling of parameters faced by estimation are
avoided cite:smekal_geometric_2004. However, as with
optimization-based reconstruction, optimization-based calibration
methods are more flexible in providing calibration offsets for the
novel trajectories that we studied.

Using previous work for optimization-based geometric calibration
cite:rougee_geometrical_1993,gullberg_estimation_1990,silver_determination_2000,
we developed a calibration method that utilizes a phantom with known
placement of highly attenuating fiducials. By scanning this phantom
and comparing the the projections to the modeled forward-projection of
a mathematical model of the phantom, we can more accurately determine
the system matrix $(\mathcal{H})$ in Equation ([[ref:eq:ddsys]]) for
reconstructing from a non-circular scanning trajectory with
optimization-based methods.

** Methods
   :PROPERTIES:
   :ID:       0b636fe5-fe45-4f10-a5fc-2de8a82bfbe4
   :END:
Where analytic-based methods, such as FDK, require a certain
acquisition trajectory such a as a fixed scanning radius of the source
and detector and the angular position of each projection, the
optimization-based system matrix makes no assumptions of the geometry
in other views. As such, we created a framework that incorporates the
best geometric estimate of the projection geometry of each view. The
flexibility to incorporate geometric corrections in this way is
another useful aspect in using optimization-based methods for image
reconstruction.

Before attempting to determine any geometric errors in our scanning
acquisition, we first modified the calculation of our system matrix to
incorporate the geometry information provided by the TrueBeam system.
In doing this, we took advantage of all the existing calibration
information that is provided with the current clinical system. Any
additional calibration information we could extract in addition to
this would then be the result of imaging with scanning configurations
that are not currently in clinical use.
*** Phantoms
    :PROPERTIES:
    :ID:       F5BECB45-8652-47A3-915C-1E96DA6110E7
    :END:
Our first calibration phantom for determining geometric offsets is
shown in Figure (\ref{fig:geo_geocal}). The phantom is a 15.2 cm outer
diameter acrylic tube with a spiral pattern of CT-spot fiducials
placed 2.5 cm apart every $45^{\circ}$. When scanned, the CT spots are
clearly visible in the projection images which is ideal for automating
the fiducial detection in the data domain.

However, we realized that using such a spiral calibration phantom
creates a degree of ambiguity in the geometry of the projected
fiducials. With both this phantom and additional calibration phantoms
we created, too much symmetry in the phantom design leads to a rather
challenging objective function. To avoid such complexity, a
calibration phantom with intentional asymmetry is desirable.

In addition to the necessary complexity created by this phantom,
another concern for a calibration phantom is the uncertainty in the
geometry of the phantom itself. Though the guide lines on the cylinder
were inscribed with the lathe and its rotational stage, we placed the
fiducials by hand. As we were trying to determine millimeter offsets
with our calibration, this fiducial placement was suboptimal.

#+CAPTION: Initial geometric calibration phantom with a spiral fiducial pattern.
#+ATTR_LaTeX: scale=0.75
#+LABEL: fig:geo_geocal
[[../../research/trajectories/geometry/geocal/20140901_extended_cllc.jpg]]

The phantom we then decided to use for calibration was the Isocal
phantom created by Varian shown in Figure ([[ref:fig:geo_isocal]]). The Isocal
phantom directly addresses the two problems encountered with our first
phantom. First, the phantom is designed with intentional asymmetry.
Additionally, the phantom is manufactured by Varian to help align the
MV-treatment isocenter with the kV-imaging isocenter. As such, the
position of the beads on this phantom have a much tighter tolerance
than that of our original phantom.

#+CAPTION: Varian's Isocal phantom positioned at the isocenter.
#+ATTR_LaTeX: scale=0.75
#+LABEL: fig:geo_isocal
[[../../research/phantoms/isocal/imgs/161012_isocal.jpg]]

*** Calibration method
    :PROPERTIES:
    :ID:       F53F4B5A-83EB-4B16-9B6D-F557D3E441C2
    :END:
We designed a calibration procedure specifically for the non-standard
scanning trajectories we implemented on the TrueBeam system with
Developer Mode. As such, the nominal trajectory we used to initialize
our calibration method was self-reported, view-by-view geometry
provided by the TrueBeam system for each projection. Starting with
this initial guess with which we calculated our reconstruction system
matrix $\mathcal{H}$, the additional calibration information we were
able to extract with our calibration improved our estimate of both the
system matrix and subsequently the estimated image from the
reconstruction.

Figure ([[ref:fig:geo_cal_schematic]]) provides a schematic illustration
of this with the Isocal phantom for a single view. Ideally, the
nominal geometry used to calculate a single projection would produce
the simulated projected fiducials in blue. However, as both our work
and that of others has found, this is not usually the case.
Discrepancies between the reported geometry and the actual scanning
geometry can arise from multiple sources in a given acquisition.

With a typical CBCT scan, deviations from the nominal geometry can
occur in both the phantom's setup (translation and rotation in all
three dimensions) as well as that of the source and detector positions
(due to translation and rotation deviations in the gantry, source, and
detector). The collective impact of these various discrepancies will
subsequently produce projection views for which the projected
fiducials in the data domain do not match the simulated projections
from the nominal geometry as shown by the red projected fiducials in
Figure ([[ref:fig:geo_cal_schematic]]).

#+NAME: fig:geo_cal_schematic
#+BEGIN_SRC asymptote :file figures/geo/cal_schematic.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;

import graph3;
import geometry;
import solids;
import three;

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(10cm);
currentprojection=orthographic(-15,5,13,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// Draw axis
// draw(Label("$y$",1),(0,0,0)--(0,5,0),red,Arrow3);
// draw(Label("$x$",1),(0,0,0)--(5,0,0),red,Arrow3);
// draw(Label("$z$",1),(0,0,0)--(0,0,5),red,Arrow3);

// kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,ulen,0), (0,0,vlen), det_cent-(0,ulen/2,vlen/2));

triple det0 = det_cent-(0,ulen/2,vlen/2);
real s=5;
triple u = (det0+s*(0,1,0));
triple v = (det0+s*(0,0,1));
triple w = (det0+s*(-1,0,0));

// detector coordinate system
draw(det0--u,blue,Arrow3,L=Label("$u$", position=EndPoint, align=W));
draw(det0--v,blue,Arrow3,L=Label("$v$", position=EndPoint, align=N));
draw(det0--w,blue,Arrow3,L=Label("$w$", position=EndPoint, align=S));

draw(detector, blue);

// path3 det180 = rot180*detector;
// path3 det270 = rot270*detector;

// uncal detector coordinate system
transform3 det_pitch=rotate(-5, det_cent, det_cent+(-1,0,0));
transform3 det_roll=rotate(-5, det_cent, det_cent+(0,0,1));
transform3 det_yaw=rotate(5, det_cent, det_cent+(0,-1,0));
transform3 det_shift=shift(5, -8, 2);

path3 detector_uncal = det_pitch*det_roll*det_yaw*det_shift*detector;
path3 det_cent_uncal = det_pitch*det_roll*det_yaw*det_shift*det_cent;
// path3 detector_uncal = det_shift*detector;
// path3 det_cent_uncal = det_shift*det_cent;
real op_uncal=0.35;
draw(detector_uncal, red+opacity(op_uncal));

// labels
//From Charles Staats's tutorial
//Direction of a point toward the camera.
triple cameradirection(triple pt, projection P=currentprojection) {
  if (P.infinity) {
    return unit(P.camera);
  } else {
    return unit(P.camera - pt);
  }
}

//Move a point closer to the camera.
triple towardcamera(triple pt, real distance=1, projection P=currentprojection) {
  return pt + distance * cameradirection(pt, P);
}

// label("$\theta=0^{\circ}$",red,align=S,position=towardcamera((det_cent-(0, ulen/2, -vlen/2))));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// uncal source
// triple src_uncal=shift(0,10,5)*(svrt,slat, slng);

// lines from source to detector edges
draw(src..det_cent-(0,-ulen/2,-vlen/2),blue+opacity(0.15));
draw(src..det_cent-(0,-ulen/2,vlen/2),blue+opacity(0.15));
draw(src..det_cent-(0,ulen/2,vlen/2),blue+opacity(0.15));
draw(src..det_cent-(0,ulen/2,-vlen/2),blue+opacity(0.15));

draw(Label("$X_{\theta_g=0^{\circ}}$", 1),src--det_cent-(110,0,0), blue, arrow=Arrow3);

// transformed frame vectors
triple det0_uncal = point(detector_uncal, 0);
triple u_p = point(detector_uncal, 1) - det0_uncal;
triple v_p = point(detector_uncal, 3) - det0_uncal;

// unit vectors
triple uhat_p = u_p / length(u_p);
triple vhat_p = v_p / length(v_p);
triple what_p = cross(uhat_p, -vhat_p);

// scale
triple u_p = s*uhat_p + det0_uncal;
triple v_p = s*vhat_p + det0_uncal;
triple w_p = s*what_p + det0_uncal;

// uncalibrated detector coordinate system
draw(det0_uncal--u_p,red,Arrow3,L=Label("$u'$", position=EndPoint, align=SE));
draw(det0_uncal--v_p,red,Arrow3,L=Label("$v'$", position=EndPoint, align=S));
draw(det0_uncal--w_p,red,Arrow3,L=Label("$w'$", position=EndPoint, align=S));

// draw(point(detector_uncal, 1)--src, red+opacity(0.15));
// real arrowlength = 5
// vector v_p=new path(real x){
//     return point(detector_uncal, 1)--arrowlength*(-1)*point(detector_uncal, 2));
// };

// draw(v_p)
// draw(point(detector_uncal, 1)--point(detector_uncal, 2),red, arrow=Arrow3);

// // and for real projection
// draw(src_uncal..point(detector_uncal, 0), red+opacity(0.15));
// draw(src_uncal..point(detector_uncal, 1), red+opacity(0.15));
// draw(src_uncal..point(detector_uncal, 2), red+opacity(0.15));
// draw(src_uncal..point(detector_uncal, 3), red+opacity(0.15));

// draw(Label("$\mathcal{H}$", 1),src--det_cent_uncal, red, arrow=Arrow3);

// Draw cylinder
// cylinder(startpoint3d, radius, length, along_this_axis)
triple start = (0,0,-8);
real length = 16;
real radius = 11.3;
triple ax = (0,0,1);
revolution r = cylinder(start,radius,length,ax);
draw(r,black);

// isocal spots
triple[] isocal={(0,-11.3,-7.5),
                 (7.9903,-7.9903,-7.5),
                 (7.9903,7.9903,-7.5),
                 (-11.3,0.0,-7.5),
                 (-7.9903,7.9903,-5),
                 (11.3,0.0,-3),
                 (0,11.3,-2),
                 (-10.4398,4.3243,2),
                 (4.3243,10.4398,3),
                 (-10.4398,-4.3243,5),
                 (4.3243,-10.4398,5),
                 (10.4398,-4.3243,7.5),
                 (10.4398,4.3243,7.5),
                 (-4.3243,10.4398,7.5),
                 (-4.3243,-10.4398,7.5)
};

dot(isocal, black);

// project points
transform3 proj=planeproject(detector);
transform3 proj_uncal=planeproject(detector_uncal);
// transform3 proj090=planeproject(det090);
// transform3 proj180=planeproject(det180);
// transform3 proj270=planeproject(det270);

dot(proj*isocal,blue);
dot(proj_uncal*isocal,red+opacity(op_uncal));
// dot(proj090*isocal,red);
// dot(proj180*isocal,red);
// dot(proj270*isocal,red);
#+END_SRC

#+CAPTION: Schematic represenation of a single projection view for the isocal phantom with the TrueBeam kV-CBCT scanning geometry shown using an orthographic projection. The blue detector and projected isocal fiducials correspond to the self-reported geometry from the imaging system. The red detector and projected fiducials illustrates how translation and rotation offsets create variations in the projected fiducials in the sinogram space. The bottom left corner corresponds to the origin of the detector coordinate system. The detector's translation and rotation offsets are exaggerated here for illustrative purposes.
#+LABEL: fig:geo_cal_schematic
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS: fig:geo_cal_schematic
[[file:figures/geo/cal_schematic.pdf]]

Starting with the nominal scanning geometry reported by the projection
metadata, we first build an initial projection matrix $\boldsymbol{X}$
that transforms the simulated phantom fiducials in room coordinates to
projected spots in detector coordinates. The matrix $\boldsymbol{X}$
is calculated using the variables describing each view shown in Figure
([[ref:fig:geo_cal_proj]]). The source and detector (including the
detector's frame vectors $\left\{ \hat{u}, \hat{v}, \hat{w} \right\}$)
are rotated into the global image space by rotating these vectors by
the gantry angle $\left( \theta_{g} \right)$ at each view (the gantry rotation
axis is the $y$ axis in Figures ([[ref:fig:geo_cal_schematic]],
[[ref:fig:geo_cal_proj]]).

Next, the orthogonal component of the rays from the source to the
detector is calculated by first finding a ray connecting the source to
the detector, $\vec{r}_{\text{sd}}$. The component of this ray that is
orthogonal to the detector is then found using the dot product
\begin{equation}
  L=\vec{r}_{sd}}\cdot \hat{w},
  \label{eq:geo_along}
\end{equation}
where the frame vector $\hat{w}$ corresponds to the detector's normal
unit vector. This then provides the vector describing the piercing
point $\left( \vec{p} \right)$ at that view which is given by
\begin{equation}
  \vec{p}=\vec{r}_s+L \hat{w},
  \label{eq:geo_pierce}
\end{equation}
where $\vec{r}_s$ is the vector corresponding to the source position in
the image coordinates for that view.

#+NAME: fig:geo_cal_proj
#+BEGIN_SRC asymptote :file figures/geo/cal_proj.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;


import graph3;
import geometry;
import solids;
import three;

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(10cm);
currentprojection=orthographic(-15,10,20,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// Draw axis
real ax_scale=15;
draw(Label("$z$",position=EndPoint,align=N),(0,0,0)--(0,ax_scale,0),black,Arrow3);
draw(Label("$x$",position=EndPoint,align=S),(0,0,0)--(ax_scale,0,0),black,Arrow3);
draw(Label("$y$",position=EndPoint,align=SW),(0,0,0)--(0,0,-ax_scale),black,Arrow3);

// show gantry angle
draw(Label("$\theta_{g}$", (2, -0.5, 0)), arc((0, 0, 0), (ax_scale/3, 0, 0), (0, -ax_scale/3, 0)), red, arrow=Arrow3);

// kV schematic
real dlat=-13, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,ulen,0), (0,0,vlen), det_cent-(0,ulen/2,vlen/2));

triple det0 = det_cent-(0,ulen/2,vlen/2);
triple u = (det0+ax_scale/2*(0,1,0));
triple v = (det0+ax_scale/2*(0,0,1));
triple w = (det0+ax_scale/2*(-1,0,0));

// detector norm
triple dnorm = (det_cent+ax_scale*(-1,0,0));

// detector coordinate system
draw(det0--u,black,Arrow3,L=Label("$u$", position=EndPoint, align=W));
draw(det0--v,black,Arrow3,L=Label("$v$", position=EndPoint, align=N));
draw(det0--w,black,Arrow3,L=Label("$w$", position=EndPoint, align=N));

draw(detector, black);

// labels
//From Charles Staats's tutorial
//Direction of a point toward the camera.
triple cameradirection(triple pt, projection P=currentprojection) {
  if (P.infinity) {
    return unit(P.camera);
  } else {
    return unit(P.camera - pt);
  }
}

//Move a point closer to the camera.
triple towardcamera(triple pt, real distance=1, projection P=currentprojection) {
  return pt + distance * cameradirection(pt, P);
}

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
draw(src..det_cent-(0,-ulen/2,-vlen/2),black+opacity(0.15));
draw(src..det_cent-(0,-ulen/2,vlen/2),black+opacity(0.15));
draw(src..det_cent-(0,ulen/2,vlen/2),black+opacity(0.15));
draw(src..det_cent-(0,ulen/2,-vlen/2),black+opacity(0.15));

// ray connecting the source to the detector
triple ray_sd = det_cent-src;
draw(L=Label("$\vec{r}_{sd}$", position=EndPoint, align=E), src--det_cent, blue, Arrow3);

// dot product of ray onto normal vecotr
real along = dot(ray_sd, dnorm);

// detector projection operator
transform3 proj=planeproject(detector);

// show pierecing point
triple pierce = proj*src;

draw(L=Label("$\vec{p}$", position=EndPoint, align=NW),src--pierce,blue+dashed,arrow=Arrow3);
draw(L=Label("$\vec{p}_{uv}$", position=EndPoint, align=SE),det0--pierce,red+dashed,arrow=Arrow3);
// draw(src--pierce,red+dotted, arrow=Arrow3);
#+END_SRC

#+CAPTION: Orthographic schematic of a single projection view and the associated variables used in building the projective transform matrix $\left( \boldsymbol{X} \right)$ for that view. The $\left\{x, y, z \right\}$ coordinate system corresponds to the standard IEC global coordinate system, and the $\left\{u, v, w \right\}$ coordinate system corresponds to the detector frame vectors for that view. The red arrow labeled by $\theta_g$ denotes the gantry rotation angle which is defined from the $x$ axis as shown here for the kV imaging system. The blue vector $\vec{r}_{sd}$ points from the source to the detector center, and the blue vector $\vec{p}$ shows the piercing point of the x-ray source on the detector. The red vector $\vec{p}_{uv}$ corresponds to the piercing point in the detector basis as calculated in Equation ([[ref:eq:geo_pierecuv]]).
#+LABEL: fig:geo_cal_proj
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS: fig:geo_cal_proj
[[file:figures/geo/cal_proj.pdf]]

With this new piercing point, it is possible to now construct a
transform that projects the fiducials as well as transforms them to
the detector basis. The transform to the detector basis is represented
by the homogeneous coordinate transform
\begin{equation}
  \boldsymbol{G} = \begin{bmatrix}
    u_i & u_j & u_k & -r_x \\
    v_i & v_j & v_k & -r_y \\
    w_i & w_j & w_k & -r_z \\
    0 & 0 & 0 & 1
  \end{bmatrix}.
  \label{eq:geo_gmat}
\end{equation}
Then using the orthogonal ray component found in Equation
([[ref:eq:geo_along]]), the homogeneous coordinate projection matrix is
\begin{equation}
  \boldsymbol{P} = \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & \frac{1}{L} & 0 \\
    0 & 0 & 0 & 0
  \end{bmatrix}.
  \label{eq:geo_pmat}
\end{equation}
Using these transforms so that they are pre-multiplied by the fiducial
position vectors, the combined transform is then
\begin{equation}
  \boldsymbol{M} = \boldsymbol{G}\boldsymbol{P}.
  \label{eq:geo_magicmat}
\end{equation}

Finally, this information can be combined to create a single transform
of the fiducials in the global image coordinate system to the
projected spots on the detector in discretized detector bin
coordinates. First, the coordinates of the piercing point must be
calculated in the detector basis as
\begin{equation}
  \vec{p}_{uv} = \(\vec{p}-\vec{r}_d\)\boldsymbol{G},
  \label{eq:geo_pierecuv}
\end{equation}
where $\vec{r}_d_{}$ is the detector coordinates rotated into the global
coordinate system. With all this, the projection transform used to
calculate the projected fiducials in discretized detector bin
coordinates is
\begin{equation}
  \boldsymbol{X} = \boldsymbol{M}\boldsymbol{T} (\vec{p}_{uv})
  \boldsymbol{S}\left( \left[\frac{1}{s_{\text{pix}}},
    \frac{1}{s_{\text{pix}}}, 1 \right]\right) \boldsymbol{T} \left(
  \left[\frac{u_{\text{len}}}{2}+0.5, \frac{v_{\text{len}}}{2}+0.5, 0
    \right] \right),
  \label{eq:geo_xproj}
\end{equation}
where $boldsymbol{S}$ is a scaling transformation along the $\left\{
u,v \right\}$ basis by the inverse of the pixel size $\left(
s_{{\text{pix}} \right)$, and \boldsymbol{T} is a translation
transformation to place the origin of the discretized detector basis
at the center of the corner pixel.

With the projection transform $\boldsymbol{X}$, each vector
corresponding to the fiducials on the Isocal phantom can be projected
onto the discretized detector basis as illustrated in Figure
([[ref:fig:geo_cal_schematic]]). These projected spots are then matched to
the detector spots in the real sinogram. The $L_2$ norm between the
real and simulated projected spots is then calculated as it serves as
the cost function for the optimization-based calibration. The idea
behind this being that when deviations from the nominal geometry are
identified, the simulated and real projected fiducials should
correspond to the same detector coordinates.

As with other optimization-based calibration procedures, we
iteratively varied the parameters corresponding to the geometric
degrees of freedom (DOF) of the scanning trajectory. The phantom pose
(position and orientation) is first allowed to vary in the room
coordinate system to account for potential setup errors between the
room coordinates and the modeled position of the phantom. Once the
pose of the Isocal phantom is identified, then the source, detector,
and patient couch translations and rotations are allowed to vary, and
the cost of the simulated fiducial projections are calculated at each
step. We used the Nelder-Mead simplex algorithm
cite:lagarias_convergence_1998 to minimize the $L_{2}\text{-norm}$ cost
function.

Given that there are there are different combinations of couch, source
and detector motions that can cause the same change of the object
relative to the source and detector within the image coordinate
system, there are some degrees of freedom that can couple with others.
For instance, shifting the patient in the positive longitudinal
direction if effectively the same as allowing the source and detector
to move the same distance in the negative longitudinal direction. This
requires that only a few parameters are allowed to vary at once as
allowing too many parameters on this non-convex surface will often
produce nonphysical geometric corrections. Once the cost has been
minimized, the geometric offsets are used as the calibration
information for calculating the system matrix $\mathcal{H}$ for the
image reconstruction.

For a new trajectory, this phantom is first scanned to identify any
geometric offsets that are incorrectly reported in the TrueBeam data
headers. Though we found the self-reported position accuracy from the
acquisition metadata to be very good, there were still some scanning
configurations for which we found the additional refinement from our
geometric calibration to be critical for obtaining a useful
reconstruction. This was particularly true for scanning trajectories
where the object and the kV imaging system were moving simultaneously.
*** Geometric-offset artifact catalog        :noexport:
    :PROPERTIES:
    :ID:       DED4A0A6-3775-41ED-AF64-BD6604B2B3AD
    :END:
Though the type of artifacts that are introduced by geometric offsets
for circular scanning trajectories are relatively well known, this
same sort of understanding is lacking for these new trajectories. To
study how geometric offsets affect images reconstructed from these new
trajectories, we will create a simulation catalog of artifacts
produced by different geometric errors. By introducing intentional
geometric inconsistencies in the reconstruction system matrix, we can
characterize the artifacts that appear in the reconstruction compared
to a numerically-exact inverse crime reconstruction.

As one of our primary objectives in using these novel trajectories is
to create an extended axial FOV image, we need to study how these
geometric errors degrade the image quality along the axial
direction. To ensure our simulation can adequately identify these
artifacts, we will create a simulated phantom such as an axially
extended version of the Catphan high resolution module. This will
provide resolution metrics not only in the axial dimension, but also
in the transverse planes as a function of axial position.

The simulation catalog of different artifacts that arise from
geometric offsets will provide a guide to visually identify potential
geometric errors based on the reconstructed image. This provide one
way in which we can verify the effectiveness of our geometric
calibration procedure. By incorporating the calibration information we
obtain with the calibration, known geometric error artifacts should be
reduced.
**** notebooks                               :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"geometry/overview.ipynb")][geometry/overview.ipynb]]
- Overview of the simulated work/analysis
*** Image entropy                            :noexport:
    :PROPERTIES:
    :ID:       2410E321-8750-473F-B6B6-13DC1719B6AE
    :END:
To further verify the effectiveness of the calibration procedure, we
will also need to use additional metrics to quantitatively
characterize the impact of using the calibration on image quality. The
work of Wicklein et al. has suggested that the best metric for
measuring the impact of geometric error on image quality is entropy
$(E)$ of the image's gray-level histogram $(H)$. This is defined as
\begin{equation}
  \label{eq:entropy}
  E=-\sum_{q=0}^Q h(q)\cdot\text{log}(h(q))
\end{equation}
where $Q$ is the maximum intensity value and
\begin{equation}
  \label{eq:norm_hist}
  h(q)=\frac{H(q)}{N}
\end{equation}
is the normalized histogram cite:wicklein_image_2012. For this metric,
minimum entropy is obtained for an image with a single intensity value
while an image with uniform distribution over all intensity values
would have maximum entropy.

Geometric errors introduce blurring at sharp boundaries in the image
which increases the entropy. By reducing geometric errors with
calibration, this blurring effect and subsequently entropy should
reduced. For our non-circular trajectories, Wicklein's conclusion can
be verified readily with the images in our catalog of geometric
errors. The image entropy of the correct-geometry reconstruction will
be against the reconstructions with intentional geometric errors to
determine if improved geometric modeling reduces the image entropy in
Equation (\ref{eq:entropy}).

If the entropy calculations based on simulation agree with Wicklein's
findings, entropy would be reasonable metric to characterize the
benefits and limitations of using the geometric offsets from the
calibration phantom on different non-circular trajectory
reconstructions. We would then use entropy as the metric to compare
reconstructions with and without calibration. From this, we can not
only verify the effectiveness of our calibration method with different
non-circular trajectories, but also then characterize the impact
additional geometric corrections have on image quality.
*** Experimental validation
    :PROPERTIES:
    :ID:       150f19dd-e68d-4226-bdd4-01e31ea1176f
    :END:
To evaluate the efficacy of our calibration procedure, we investigated
its performance on calibrating both a standard, half-fan, circular
trajectory where the couch is stationary as well as a virtual
isocenter trajectory with the same object illumination where the couch
moves during the acquisition. For each of these trajectories, we used
the same Developer Mode script to scan both the Catphan phantom and
the Isocal phantom. We subsequently used the sinogram from the Isocal
scan to extract calibration offsets for that particular trajectory
using the calibration method described in Section ([[id:F53F4B5A-83EB-4B16-9B6D-F557D3E441C2][Calibration
method]]).

With this calibration extracted from the data domain using our
calibration routine, we reconstructed the Catphan scans from these two
trajectories with and without the calibrations offsets. We
reconstructed onto an isotropic image grid of 0.473 mm for each
reconstruction, and applied the half-fan weighting described in
Section ([[id:cc6bcac6-a445-4dfb-8815-a95e31f517ed][Detector weighting]]). For all of these reconstructions we used
200 iterations of MLEM as described in Section ([[id:e0a24b69-d136-4f9a-9e85-dc42e1d114a9][MLEM]]).

*Should we run the metric analysis on these two scans w/ and w/o calibration?*
*** figures                                  :noexport:
**** four detector schematic
# +LABEL: fig:geo_schematic
#+BEGIN_SRC asymptote :file figures/geo/schematic.pdf :exports results :tangle no
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;

import graph3;
import solids;
import three;

// view configuration
size(10cm);
// currentprojection=orthographic(-5,1,5,up=Y);
currentprojection=perspective(-5,1,5,up=Y);
// currentlight=White;

// Draw axis
// draw(Label("$y$",1),(0,0,0)--(0,5,0),red,Arrow3);
// draw(Label("$x$",1),(0,0,0)--(5,0,0),red,Arrow3);
// draw(Label("$z$",1),(0,0,0)--(0,0,5),red,Arrow3);

// kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,ulen,0), (0,0,vlen), det-(0,ulen/2,vlen/2));

transform3 rot090=rotate(90, Z);
transform3 rot180=rotate(180, Z);
transform3 rot270=rotate(270, Z);

path3 det090 = rot090*detector;
path3 det180 = rot180*detector;
path3 det270 = rot270*detector;

draw(detector, black);
draw(det090, black);
draw(det180, black);
draw(det270, black);

// labels
//From Charles Staats's tutorial
//Direction of a point toward the camera.
triple cameradirection(triple pt, projection P=currentprojection) {
  if (P.infinity) {
    return unit(P.camera);
  } else {
    return unit(P.camera - pt);
  }
}

//Move a point closer to the camera.
triple towardcamera(triple pt, real distance=1, projection P=currentprojection) {
  return pt + distance * cameradirection(pt, P);
}

label("$\theta=0^{\circ}$",red,align=S,position=towardcamera((det-(0, ulen/2, -vlen/2))));
// label("$B$",align=S,position=towardcamera((B)));
// label("$C$",align=SE,position=towardcamera((C)));
// label("$D$",align=SE,position=towardcamera((D)));
// label("$E$",align=NE,position=towardcamera((E)));
// label("$F$",align=S,position=towardcamera((F)));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
// draw(src..det-(0,-ulen/2,-vlen/2),black);
// draw(src..det-(0,-ulen/2,vlen/2),black);
// draw(src..det-(0,ulen/2,-vlen/2),black);
// draw(src..det-(0,ulen/2,vlen/2),black);

// Draw cylinder
// cylinder(startpoint3d, radius, length, along_this_axis)
triple start = (0,0,-8);
real length = 16;
real radius = 11.3;
triple ax = (0,0,1);
revolution r = cylinder(start,radius,length,ax);
draw(r,black);

// isocal spots
triple[] isocal={(0,-11.3,-7.5),
                 (7.9903,-7.9903,-7.5),
                 (7.9903,7.9903,-7.5),
                 (-11.3,0.0,-7.5),
                 (-7.9903,7.9903,-5),
                 (11.3,0.0,-3),
                 (0,11.3,-2),
                 (-10.4398,4.3243,2),
                 (4.3243,10.4398,3),
                 (-10.4398,-4.3243,5),
                 (4.3243,-10.4398,5),
                 (10.4398,-4.3243,7.5),
                 (10.4398,4.3243,7.5),
                 (-4.3243,10.4398,7.5),
                 (-4.3243,-10.4398,7.5)
};

dot(isocal, black);

// project points
transform3 proj=planeproject(detector);
transform3 proj090=planeproject(det090);
transform3 proj180=planeproject(det180);
transform3 proj270=planeproject(det270);

dot(proj*isocal,red);
dot(proj090*isocal,red);
dot(proj180*isocal,red);
dot(proj270*isocal,red);
#+END_SRC

#+CAPTION: Schematic representation of the scanning geometry
#+ATTR_LaTeX: :width 0.75\textwidth
# +RESULTS: fig:geo_schematic
*** geocal procedure                         :noexport:
    :PROPERTIES:
    :ID:       DD6F1968-D9A8-46AB-AC2C-BF79512B530A
    :END:
The current version of the geocal procedure uses a single step
projection matrix to transform positions in room coordinates to pixels
on the detector. do you want to incude the equation for that? this is
it basically, where “framevecs” are the 3 detector basis vectors
rotated by roll, pitch, yaw and then gantry angle - your usual frame
vectors. also note that my htransform_vectors function premultiplies
the matrix by the vector, i.e. X’ = X M, so the component
transformations are applied from left to right - if M=ABC, then it’s A
first followed by B followed by C.

#+BEGIN_SRC matlab :tangle no
grotvecs=framevecs;
dnormrot=grotvecs(3,:);

sourcedetray=rotdet-rotsrc;  % this can be any ray connecting the source
                             % with a point on the detector

along=dot(sourcedetray,dnormrot);  % this is the new L for projection.
                                   % the "along" component is the same for
                                   % every ray from source to detector

% find the new piercing point, of ray through source along det normal
% direction.
newpierce=rotsrc+along*dnormrot;
mygmat=eye(4,4);
mygmat(1:3,1:3)=grotvecs';
mygtmat=hmatrix_translate(-rotsrc)*mygmat;

projmat=eye(4,4);
projmat(4,4)=0;
projmat(3,4)=1.0/along;
% compress the above to a single step - transform to detector basis,
% project
magicmat=mygtmat*projmat;

% to compute pixel coordinates, first find the U and V coordinates of the
% piercing point.  then just add the fids_on_detector U and V values.
% note these will still be in cm, not in pixels.  last thing will be to
% scale by pixel size and add detector center position, e.g. (512,384).
pierceoffset=newpierce-rotdet;
uvpierce=htransform_vectors(mygmat,pierceoffset);

%uvfids1=(fids_on_det_4(:,1:2)+repmat(uvpierce(1:2),size(fids_on_det_4,1),1))/pixsize;
xprojmat=magicmat*hmatrix_translate(uvpierce)* ...
         hmatrix_scale([1.0/pixsize 1.0/pixsize 1])* ...
         hmatrix_translate([usize/2+0.5, vsize/2+0.5, 0]);

#+END_SRC

#+RESULTS:
*** ideas                                    :noexport:
Given that part of the robust nature of optimization-based algorithms
is the ability to handle the poorly-conditioned nature of the inverse
problem...
** Results
   :PROPERTIES:
   :ID:       bc50c80a-fbb7-41d3-a9d0-ebc552f59896
   :END:
*** Experimental validation
    :PROPERTIES:
    :ID:       2c3c25d5-477a-4013-bf2a-5a74716b9c20
    :END:
Figure ([[ref:fig:geo_cal_catphan_sens]]) shows the CTP 528 spatial
resolution module slice from the reconstructions of both the circular
scan in the left column and the virtual isocenter scan in the right
column. The top row shows the slice from the uncalibrated
reconstruction using just the nominal scanning information from scan's
metadata. It can be seen by comparing the circle and virtual isocenter
scans without calibration that the additional complexity of moving the
treatment couch during the scan introduces additional geometric error
over the standard circle scan which visually degrades spatial
resolution.

The bottom row of Figure ([[ref:fig:geo_cal_catphan_sens]]) shows the same
slice from the corresponding trajectory with the geometric offsets
from the calibration procedure incorporated into the system matrix
$\mathcal(H)$. For the circular scan, using the calibration
information does provide a bit of an improvement in spatial
resolution. However, the efficacy of the calibration method is
particularly striking for the virtual isocenter scan. By using the
calibration offsets in the reconstruction model, the spatial
resolution of the virtual isocenter reconstruction becomes comparable
to that of the circular scan.

Figure ([[ref:fig:geo_cal_cost]]) shows the $L_{2}_{}-\text{norm}$ from the data
domain between the simulated fiducial projections and the real
fiducial projections acquired from the circle and virtual isocenter
scans of the isocal phantom. As this served as the cost function which
we used as the minimization objective for the optimized offset search,
we can see that the calibration did effectively reduce this cost from
the nominal geometry (blue) to the calibrated geometry (green). This
cost also reflects the same trend we see in the spatial resolution of
the images shown in Figure ([[ref:fig:geo_cal_catphan_sens]]).

Comparing the the $L_{2}_{}-\text{norm}$ of the uncalibrated scans in Figure
([[ref:fig:geo_cal_cost]]), we see that there is far more disagreement
between the nominal trajectory and the real data for the virtual
isocenter scan than that of the circular scan. We see that this
subsequently produces far more artifacts and loss of spatial
resolution in the virtual isocenter reconstruction than in that of the
circular scan. We also see that after running the optimization-based
calibration procedure, the cost for both trajectories is reduced to
approximately the same order of magnitude. Again, this agrees with the
reconstructed images as the spatial resolution in both the circular
scan and the virtual isocetner scan is comparable after incorporating
the calibrated geometry into the system matrix $\mathcal{H}$.

*Describe TB1 virtual isocenter couch backlash?*
#+BEGIN_EXPORT latex
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.65\textwidth}
    \includegraphics[width=\textwidth]{figures/geo/catphanCalComp}
    \caption{}
    \label{fig:geo_cal_catphan_sens}
  \end{subfigure}
  ~ %add desired spacing between images, e. g. ~, \quad, \qquad,
  % \hfill etc.
  % (or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figures/geo/costComp1p5}
    \caption{}
    \label{fig:geo_cal_cost}
  \end{subfigure}
  \caption{(a) shows the 200$^{\text{th}}$ iteration of MLEM
    reconstructions of the CTP 528 spatial resolution module from the
    Catphan phantom for two different trajectories. The left column is
    from a 1.5X circular scan, and the right column is from a 1.5X
    virtual isocenter scan reconstructed onto a 0.473 mm isotropic
    image grid([-100, 2000] HU). The top row shows the reconstruction
    using the nominal geometry from self-reported metadata, and the
    bottom row corresponds to the calibrated reconstructions. (b)
    shows the $L_{2}$-norm used for the calibration cost function
    before (blue) and after (green) calibration for both the circle
    (left) and the virtual isocenter (right).}
  \label{fig:geo_cal_sens_cost}
\end{figure}
#+END_EXPORT
**** figures                                 :noexport:
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/calibration_images.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/calibration_images.ipynb]]
**** notes                                   :noexport:
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/calibs/calib_analysis.ipynb")][170603_virtiso_circ_smth_catphan/dynmag/calibs/calib_analysis.ipynb]]
** Conclusion
   :PROPERTIES:
   :ID:       fd41d566-a4b3-4dcd-9f8c-7417276ad25c
   :END:
In developing our optimization-based geometry calibration procedure,
we found that proper geometric calibration is a critical component of
improving tomographic image quality. This is particularly true for
more complicated trajectories where additional motion components such
as that of the treatment couch introduce additional degrees of freedom
in which geometric errors can arise. As shown in Figure
([[ref:fig:geo_cal_sens_cost]]), the additional motion of the couch with
the simultaneous motion of the source and detector introduces a larger
deviation from the nominal scanning geometry.

The optimization-based calibration we used in this study provides a
robust framework for calibrating arbitrary scanning trajectories. The
ability to acquire view-by-view calibration information with this
approach dovetails nicely with the optimization-based framework that
enables the reconstruction from the different trajectories we studied
in this research. Though many of the different analytic-based methods
described in the literature could be adopted to many of these
trajectories (and have been for some), the benefit of the
optimization-based framework for both reconstruction and geometric
calibration comes from freedom to easily model and reconstruct from
trajectories as well as geometric offsets that deviate from the
analytically prescribed model.

Though this does imply that calibration scans must be acquired for
each scan of interest, there are optimization-based calibration
methods similar to ours that attempt to extract calibration
information with no /a priori/ knowledge of the phantom
cite:panetta_optimization-based_2008. Such calibration methods or
built-in calibration markers in the table are potential ways in which
it would be possible to avoid acquiring calibration information for
every scan of interest. As we used the TrueBeam kV-CBCT system for our
data acquisition, Varian's Isocal phantom provided a convenient means
of calibrating the imaging system as the linac use case already
demands accurate calibration for treatment accuracy in addition to
image quality alone.

In the following chapters we where we investigate particular
applications of these different trajectories, we will use our
calibration method with the Isocal phantom to more accurately model
the system matrix $\mathcal(H)$. Though the more exotic scanning
trajectories introduce more degrees of freedom that create greater
geometric uncertainty, our calibration procedure performs rather well
in determining what these deviations are from the self-reported
geometry metadata. For these trajectories, we found that
incorporating geometric calibration consistently improves image
quality.
* Axial field-of-view extension              :fov:
  :PROPERTIES:
  :ID:       eaae199f-f899-4862-af50-720895a31c36
  :END:
** notes                                     :noexport:
   :PROPERTIES:
   :ID:       7c250434-fff6-41a3-aea3-e7bc9ff88dc6
   :END:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
*** publications
    :PROPERTIES:
    :ID:       48459222-20e7-43e5-9863-5022a5803a1b
    :END:
**** cite:davis_extended_2013
     :PROPERTIES:
     :ID:       5b4c7bca-d59b-4f33-8151-a6b359071249
     :END:
- simulation study of axial FOV extension
**** cite:davis_verifying_2013
     :PROPERTIES:
     :ID:       d4c20a7d-4982-4318-b591-9ff84ee809f5
     :END:
- Trilogy scans of RANDO and Defrise phantom for axial FOV extension
**** cite:pearson_investigation_2013
     :PROPERTIES:
     :ID:       6ae09b4c-d1d3-4705-b110-8a4a0e1f33dd
     :END:
- Similar results to [[id:d4c20a7d-4982-4318-b591-9ff84ee809f5][cite:davis_verifying_2013]] using RANDO and Defrise
  Trilogy scans
**** cite:davis_we-g-brf-07:_2014
     :PROPERTIES:
     :ID:       3f9687ce-f913-43a0-8e96-0ace96d7f67c
     :END:
- AAPM talk using CLLC scan from TrueBeam
**** cite:davis_su-e-i-02:_2015
     :PROPERTIES:
     :ID:       15f62bff-3fae-4083-b4b1-ad0594d25121
     :END:
- AAPM poster for disk phantom metrics
**** cite:davis_non-circular_2015
     :PROPERTIES:
     :ID:       cee07d24-100a-4c78-a42d-59cd707cda3b
     :END:
- Varian meeting showing non-circular scans
** Introduction
   :PROPERTIES:
   :ID:       b815fcd4-92c6-4f72-9905-10acc22b580e
   :END:
# What question (problem) was studied?
The use of cone-beam computed tomography (CBCT) in image-guided
radiation therapy (IGRT) has become increasingly popular in radiation
oncology
cite:xing_overview_2006,bissonnette_quality_2012,dawson_advances_2007. A
kV imaging system is mounted on the treatment linear accelerator
(linac) orthogonally to the MV treatment beam. This allows the
acquisition of projection data of the patient while the gantry
rotates. The reconstructed CT image from these projections provides
volumetric information to assist with patient setup and target volume
positioning cite:jaffray_flat-panel_2002-1. Linac manufacturers now
routinely included kV imaging systems on their linacs, such as the
Varian Medical Systems' (Palo Alto, CA) TrueBeam kV imaging system.

A major limitation of these imaging systems is a lack of extended
axial coverage. This is partially due to the detector size which is
restricted due to engineering concerns. Another reason for this
limited coverage is the prevalence of analytic-based reconstruction
algorithms in the clinic cite:pan_why_2009. These algorithms, such as
FDK cite:feldkamp_practical_1984, are known to suffer from cone-angle
artifacts at the axial extremes of the reconstruction volume. The
increasing severity of these artifacts at the axial extremes is
partially why developing larger kV detectors have not been pursued.

Analytic-based reconstruction algorithms are problematic in that they
require a fixed trajectory in formulating the inverse. When
approximations are made for the inverse as in FDK, deviations from
where these approximations are valid lead to inconsistencies in the
model and subsequently artifacts in the reconstruction. For FDK, at
larger cone angles (edges of the FOV at the axial extremes), the
assumption of quasi redundancy for planes other than that of the
source's circular trajectory becomes increasingly invalid at larger
cone angles leading to cone-angle artifacts.  In contrast to these
analytic models, optimization-based reconstruction algorithms have
demonstrated more robust model of the image formation process reducing
the artifacts that arise from these analytic-based methods
cite:shepp_maximum_1982,han_optimization-based_2012,sidky_image_2008,sidky_accurate_2006,bian_evaluation_2010.

By utilizing the robust modeling properties of these new
optimization-based algorithms, we are no longer bound to the strict
trajectory limitations imposed by analytic-based reconstruction
methods. Provided that the correct geometry of the acquisition
trajectory is well understood, the system matrix of the image
formation process can be calculated for arbitrary CBCT scanning
configurations. These new trajectories are no longer limited to the
few cases of non-circular trajectories for which analytic inverse
formulations exist such as the line cite:sidky_volume_2005, circle and
line cite:zeng_cone-beam_1992,katsevich_image_2004, circle and arcs
cite:zou_image_2005-1,katsevich_image_2005, and non-planar orbits
cite:kudo_derivation_1994

With some of the new trajectories allowed by these optimization-based
algorithms, we can address the problem of the limited axial coverage
for these kV imaging systems. This is possible for trajectories with a
component of axial translation that extends the projection information
beyond the limits of the small detector coverage. For source
trajectories where the source and detector move in the axial direction
relative to the patient, projection data can be obtained for axial
positions beyond what is acquired with a traditional circular
trajectory. Optimization-based reconstruction algorithms make it
possible to formulate an imaging model for any trajectory that could
resolve a variety of limitations imposed by traditional trajectories.

In this work, we compare a few different trajectories that can address
the limited axial coverage that currently restricts clinical work in
head and neck cancer as well as breast cancer patients *CITE*. Using
these new optimization-based reconstruction algorithms, we studied
some potential trajectories and then compared the subsequent
extended-axial images to the clinical FDK standard. The hypothesis is
that there can be extensive gains in clinical utility for these
extended volume images provided that the image quality is comparable
to the current clinical standard.
*** proposal                                 :noexport:
 In the 1980s, a lot of work was done to directly solve the inverse
 problem for the cone-beam geometry. By modeling the projection
 formation process as a Radon transform or an X-ray transform,
 reconstruction algorithms were formulated by finding an analytic-based
 inverse to the transform. However, for the inverse to be exact, it
 needed to meet strict requirements such as Tuy's condition which
 states that every plane through the object must intersect the source
 trajectory cite:tuy_inversion_1983. While some exceptions to this
 requirement were found, it demonstrates the strict requirements on the
 types of scanning trajectories for which an exact inverse could be
 found.

 The circular scanning trajectory that is ubiquitous in the clinic for
 CBCT is one trajectory that fails to meet Tuy's condition. The most
 popular reconstruction algorithm for the circular CBCT trajectory is
 the filtered-backprojection (FBP) algorithm proposed by Feldkamp,
 Davis, and Kress (FDK) cite:feldkamp_practical_1984 which is still the
 industry standard. FDK is only an exact inversion to the Radon
 transform on the midplane containing the circular source
 trajectory. For transaxial planes other than the midplane, a
 quasi-redundancy in the scanning data is assumed. It is the violation
 of this assumption which leads to cone-angle artifacts. These
 artifacts become more severe at larger cone angles where this
 assumption is less applicable.

 The presence of cone-angle artifacts in FDK reconstructions from the
 incomplete data acquired with circular scanning trajectories led to
 research into inverse algorithms for cone-beam scans from
 theoretically complete trajectories such as a circle plus a line
 cite:zeng_cone-beam_1992. It became apparent in the reconstruction
 results that implementing these direct reconstruction algorithms did
 not produce the anticipated results cite:kudo_derivation_1994. Severe
 artifacts and numerical errors were found in the reconstructions due
 to factors such as truncation introducing high-frequency components
 that are amplified in the filtration process.

 Analytic-based reconstruction algorithms are formulated by explicitly
 finding an inverse to the X-ray transform
 #+BEGIN_LaTeX
   \begin{equation}
     \label{eq:xray}
     g(\mathbf{r}_0,\hat{\theta})=\int_0^{\infty}f(\mathbf{r}_0+t\hat{\theta})dt,
   \end{equation}
 #+END_LaTeX
 where the data function $g$ is acquired by integrating along the ray
 from the source at $\mathbf{r}_0$ in the direction $\hat{\theta}$ through
 the object function $f$. A fundamental problem with these
 reconstruction algorithms when practically reconstructing $f$ is the
 assumption of a continuous-to-continuous (CC) model. These
 analytic-based reconstruction algorithms impose dense sampling
 requirements for both the detector and number of views to approximate
 a continuous data function. Given that the data function from the
 digital detector and the numerical array for storing the reconstructed
 image are both discrete, a more natural approach to the inverse
 problem would be a discrete-to-discrete (DD) imaging model
 cite:barrett_foundations_2003.

 Iterative reconstruction algorithms are more robust because they do
 implement a more accurate DD model of the imaging system. The X-ray
 transform of the object function can be represented as the linear
 system
 #+BEGIN_LaTeX
   \begin{equation}
     \label{eq:ddsys}
     \mathbf{g}=\mathcal{H}\mathbf{f},
   \end{equation}
 #+END_LaTeX
 where $\mathbf{g}$ is the discrete $M$ pixel sampled projection on the
 detector, $\mathcal{H}$ is the $M\times N$ discrete form of the X-ray
 transform, and $\mathbf{f}$ is the object function represented on a N
 voxel basis. As direct inversion of $\mathcal{H}$ is impractical due
 to both its size and inconsistencies from factors such as noise,
 optimization techniques are used to solve this system for an estimate
 of the object $\widetilde{\mathbf{f}}$.

 The optimization problem for these iterative reconstruction algorithms
 is formulated as an objective function based on the actual data
 $\mathbf{g}$ and the image model $\mathcal{H}\mathbf{f}$. An
 optimization algorithm is then used to iteratively update the estimate
 of $\widetilde{\mathbf{f}}$ until a suitable convergence criterion has
 been met. The parameters of the optimization problem, the optimization
 algorithm, and the convergence criteria are all important factors in
 determining the properties of the reconstructed image and subsequently
 its utility.

 Two optimization-based reconstruction methods we will use with these
 non-circular trajectories are maximum-likelihood expectation
 maximization (MLEM) cite:shepp_maximum_1982,dempster_maximum_1977 and
 constrained, total-variation (TV) minimization by adaptive steepest
 descent-projection onto convex sets (ASD-POCS)
 cite:sidky_image_2008. Previous work has shown that these iterative
 algorithms are able to reconstruct clinically useful images under
 scanning conditions for which analytic-based FDK fails
 cite:han_optimization-based_2012,sidky_image_2007,sidky_accurate_2006. The
 reconstruction work from sparse-view data cite:bian_evaluation_2010
 alone suggests that views could be distributed at different axial
 positions to acquire additional scan information without imparting
 more dose than the dense set of angular views used in current clinical
 circular scans with analytic-based reconstruction.

** Methods
   :PROPERTIES:
   :ID:       b42e5e65-dfda-4692-8ea6-f6d96bc1dd5b
   :END:
*** Simulation
    Clinical extended-axial-FOV images are obtained by stitching
    together two circular scans at different axial locations. We first
    wanted to find the maximum axial coverage that can be achieved with
    such a trajectory. That is, what would be the maximum axial
    spacing between the two planes of the source's trajectory for
    which a useful extended volume image could be reconstructed?

    Simulating forward projections from this trajectory, we compared
    the images obtained from stitching together the independent FDK
    images to those obtained by reconstructing the two circles as a
    single trajectory with MLEM. We also compared stacked FDK images
    to reconstructions from the simulated *CLC* and smooth
    trajectories.

    We simulated a Defrise-style phantom modeled with the 3D X-ray
    projection software TAKE cite:seger_matlab/c_2005. The phantom was
    composed of a 15.2 cm outer diameter acrylic cylinder with
    alternating density disks of Delrin and cork 0.5 mm thick. This
    particular phantom with alternating density disks is acknowledged
    by the authors of FDK as being particularly susceptible to
    cone-angle artifacts cite:feldkamp_practical_1984.

    We used the TAKE software to forward project the phantom as well
    as generate a digitized "truth" phantom for calculating comparison
    metrics. The projector generates a forward projection from a
    specified trajectory given a mathematical definition of the
    phantom as well as its material properties and the spectrum
    generated by the x-ray source.

    We created projection data for a set of dual-circle trajectories
    that had an increasing amount of axial separation between the two
    circles. With a 1.5x magnification factor and a 30 cm detector
    size along the axial direction, a single circular scan has a
    maximum axial coverage of 20 cm in the image space. Furthermore,
    the maximum spacing between the two circles is 20 cm as any
    separation larger than this means the independent image volumes
    from the two circles are no longer contiguous. We therefore
    created trajectories with 10, 12, 14, 16, 18, and 20 cm
    separations *only show the larger gaps that are of interest?*
    between the planes of the source's dual-circle trajectory.

    We uniformly distributed 600 views over the entire trajectory
    which is comparable to the total number of views used in a single
    clinical CBCT scan with the kV imaging system. For the other two
    trajectories with a component of projection views taken during the
    axial translation (CLC and smooth), 600 views were used with 20% of
    the views being distributed along the axial translation stage.

    *FIX*

    The reconstruction image space consisted of a $256\times256$ transverse
    grid of 1 mm isotropic voxels. As the spacing between the circles
    increased, the number of voxels in the axial direction also
    increased to accommodate the increasingly large FOV.

    For the extended-volume reconstruction using the stacked FDK, we
    independently reconstructed each circular scan with FDK using a
    standard Hann filter. To combine the two reconstructed volumes for an
    extended axial-coverage image at a given spacing, we used the midplane
    between the two planes of the source's circular trajectory to select
    how much of each reconstruction to put in the combined image.

    For the MLEM reconstructions, we used all of the projection data
    simultaneously to reconstruct the extended volume. After defining the
    extended image volume, we computed the system matrix for each of the
    different spacings and trajectories based on the trajectory of the
    source and detector. We used 100 iterations *justify choice* of the
    MLEM algorithm to find an estimate for the image.


    *FIX*

    Our initial evaluation of the images obtained from non-circular
    trajectories is simply a qualitative visual inspection which does
    provide an informative assessment of the variety of artifacts that
    occur for a given reconstruction. For a more rigorous evaluation of
    the images obtained from different trajectories, we will use mutual
    information (MI) cite:pluim_mutual-information-based_2003 and the
    universal quality index (UQI) cite:wang_universal_2002 to provide a
    quantitative assessment of the image similarity between the reference
    image and the images from different trajectories.

*** Old FOV Paper Simulation
   :PROPERTIES:
   :ID:       6888683a-4d00-4cb2-be7e-8ac554af7595
   :END:
Since extended axial images in the clinic are obtained with two
circular scans at different axial locations, we wanted to find the
maximum axial coverage allowed by this dual-circle trajectory. That
is, what would be the maximum axial spacing between the two planes of
the source's trajectory for which a useful extended volume image could
be reconstructed? Using simulated forward projections from this
trajectory, we compared the images obtained from stacking the
independent FDK images to those obtained by reconstructing the two
circles as a single trajectory with MLEM. We also compared stacked FDK
images to reconstructions from the simulated CLC and smooth
trajectories.

**** Phantom
    :PROPERTIES:
    :ID:       bd73b61b-002b-481a-8b3a-712f1f2f1743
    :END:
The simulated phantom was a Defrise-style phantom modeled with the 3D
X-ray projection software TAKE cite:seger_matlab/c_2005. The phantom
was composed of a 15.2 cm outer diameter acrylic cylinder with
alternating density disks of Delrin and cork 0.5 mm thick. This
particular phantom with alternating density disks is acknowledged by
the authors of FDK as being particularly susceptible to cone-angle
artifacts cite:feldkamp_practical_1984.

**** Forward projection
    :PROPERTIES:
    :ID:       17f947de-c9f5-4313-ad70-3b77ff7ca929
    :END:
- [ ] Verify that the new version with the tested polychromatic
  behavior produces sinograms that are comparable to the ones we used
  in the initial study.

The forward projections of the phantom were acquired from the TAKE
software. The projector generates a forward projection from a
specified trajectory given a mathematical definition of the phantom as
well as its material properties and the spectrum generated by the
x-ray source. A digitized truth of the phantom was rendered by the
software to match the image space of the reconstruction for
calculating comparison metrics.

**** Trajectories
    :PROPERTIES:
    :ID:       5d84bea3-21b6-4311-a7de-ee73a956a152
    :END:
Given the 1.5 magnification factor and the 30 cm detector size along
the axial direction, a single circular scan has a maximum axial
coverage of 20 cm in the image space. Furthermore, the maximum spacing
between the two circles is 20 cm as any separation larger than this
means the independent image volumes from the two circles are no longer
contiguous. We therefore created trajectories with 10, 12, 14, 16, 18,
and 20 cm separations *only show the larger gaps that are of
interest?* between the planes of the source's dual-circle trajectory.

We created projection data for a set of dual-circle trajectories that
had an increasing amount of axial separation between the two
circles. We uniformly distributed 600 views over the entire trajectory
which is comparable to the total number of views used in a single
clinical CBCT scan with the kV imaging system. For the other two
trajectories with a component of projection views taken during the
axial translation (CLC and smooth), 600 views were used with 20% of
the views being distributed along the axial translation stage.

***** TAKE check
:PROPERTIES:
:ID:       2bacd921-aa76-4225-9992-4b8f5b1f3198
:END:
- [ ] Verify new projection data matches old sinograms.
- [ ] Verify the number of views that compose the trajectory.
- [ ] If all of the projection information matches, use the
  reconstructions I presented in my proposal.

**** Reconstruction
    :PROPERTIES:
    :ID:       1c0fa74f-e955-492e-a1d4-bfb81cd21cbf
    :END:
The reconstruction image space consisted of a $256\times256$ transverse
grid of 1 mm isotropic voxels. As the spacing between the circles
increased, the number of voxels in the axial direction also increased
to accommodate the increasingly large FOV.

For the extended-volume reconstruction using the stacked FDK, we
independently reconstructed each circular scan with FDK using a
standard Hann filter. To combine the two reconstructed volumes for an
extended axial-coverage image at a given spacing, we used the midplane
between the two planes of the source's circular trajectory to select
how much of each reconstruction to put in the combined image.

For the MLEM reconstructions, we used all of the projection data
simultaneously to reconstruct the extended volume. After defining the
extended image volume, we computed the system matrix for each of the
different spacings and trajectories based on the trajectory of the
source and detector. We used 100 iterations *justify choice* of the
MLEM algorithm to find an estimate for the image.

**** Evaluation
:PROPERTIES:
:ID:       7b8e3df7-2509-4e65-8e5a-9b5a468322d8
:END:
Our initial evaluation of the images obtained from non-circular
trajectories is simply a qualitative visual inspection which does
provide an informative assessment of the variety of artifacts that
occur for a given reconstruction. For a more rigorous evaluation of
the images obtained from different trajectories, we will use mutual
information (MI) cite:pluim_mutual-information-based_2003 and the
universal quality index (UQI) cite:wang_universal_2002 to provide a
quantitative assessment of the image similarity between the reference
image and the images from different trajectories.

*** Linac-mounted kV-imaging system geometry
    :PROPERTIES:
    :ID:       60de42d1-aa6d-47d0-a27d-cc2e1a632254
    :END:
 We used the Varian TrueBeam kV imaging system to acquire the data in
 this study. It consists of a kV imaging source opposite a flat-panel
 detector with a source-to-detector-distance of 150 cm and a
 source-to-isocenter distance of 100 cm. The detector's active area is
 40 cm $\times$ 30 cm with a $2048 \times 1536$ pixel array that performs a $2 \times
 2$ binning for a readout of $1024 \times 768$ square pixels of effective
 size 0.388 mm.

*** Reconstruction
    :PROPERTIES:
    :ID:       6cdf439a-318d-4c75-a479-e4dbfcb7a076
    :END:
 To utilize optimization-based methods for image reconstruction, the
 image formation process is modeled as the linear system
 #+BEGIN_LaTeX
 \begin{equation}
   \label{eq:ddsys}
   \mathbf{g}=\mathcal{H}\mathbf{f},
 \end{equation}
 #+END_LaTeX
 where $\mathbf{g}$ is the discrete $M$-pixel sampled projection on the
 detector, $\mathcal{H}$ is the $M\times N$ discrete form of the X-ray
 transform, and $\mathbf{f}$ is the object function represented on a
 $N$-voxel basis. As direct inversion of $\mathcal{H}$ is impractical
 due to both its size and inconsistencies from factors such as noise,
 optimization techniques are used to solve this system for an estimate
 of the object $\widetilde{\mathbf{f}}$.

 The optimization problem for this approach is then framed as an
 objective function based on the actual data $\mathbf{g}$ and the image
 model $\mathcal{H}\mathbf{f}$. An optimization algorithm is then used
 to iteratively update the estimate of $\widetilde{\mathbf{f}}$ until a
 suitable convergence criterion has been met.

 Where, we used the maximum-likelihood expectation maximization (MLEM)
 algorithm cite:dempster_maximum_1977. As we are interested in using
 optimization-based methods to enable reconstruction from novel
 trajectories, we selected an algorithm that is well understood and has
 relatively few parameters. However, the freedom in calculating the
 system matrix by modeling the image formation process as a linear
 system does not limit the algorithm choice to MLEM alone.

 The reconstruction program for solving Equation (\ref{eq:ddsys}) using
 MLEM can be formulated as
 #+BEGIN_LaTeX
 \begin{equation}
   D_{KL}(\mathbf{f})\leq \epsilon_{KL}
   \label{eq:kl}
 \end{equation}
 #+END_LaTeX
 where $D_{KL}(\mathbf{f})$ is the Kullback-Leibler (KL) divergence
 between $\mathbf{g}$ and $\mathcal{H}\mathbf{f}$
 cite:barrett_foundations_2003 and $\epsilon_{KL}>0$ is the upper bound for the
 KL divergence. The KL divergence can be minimized with the MLEM
 algorithm
 #+BEGIN_LaTeX
 \begin{equation}
   f_j^{(n+1)}=\frac{f_j^{(n)}}{\sum\nolimits_{i=1}^{M}\mathcal{W}_{ii}\mathcal{H}_{ij}}\sum\limits_{i=1}^{M}\mathcal{W}_{ii}\mathcal{H}_{ij}\frac{g_i}{\sum\nolimits_{j=1}^{N}\mathcal{H}_{ij}f_j^{(n)}}}
     \label{eq:mlem}
 \end{equation}
 #+END_LaTeX
 where $f_{j}^{n}$ is $j$-th voxel value at iteration $n$ and
 $\mathcal{H}_{ij}$ is the element of the system matrix at the $i$-th
 row and $j$-th column for $i=1,2,...,M$ and $j=1,2,...,N$. The initial
 image estimate for the reconstructions was $\mathbf{f}^{(0)}=1$. The
 $M\times M$ diagonal matrix $\mathcal{W}$ weights the corresponding
 data entries cite:bian_optimization-based_2013.

 *list the voxel/FOV size*

*** Trajectories
    :PROPERTIES:
    :ID:       b16942be-e3d8-4fb2-a872-aa68fe6bd4fd
    :END:
 We define a scanning trajectory as the sequence of source and detector
 positions used to acquire each projection view. The coordinates of the
 trajectory are then defined relative to a fixed origin in the patient.
 Moving either the imaging arms or the patient, it is possible to
 create a component of axial translation that acquires projection views
 with information of the patient volume at extended axial positions.
 Moving either the imaging arms or the patient is equivalent provided
 the relative translation is correctly accounted for when developing
 the system matrix for the acquisition.

 The current clinical method of obtaining an extended axial image
 involves stacking the FDK reconstructions of two circular scans at
 different axial positions. For this reason, the first trajectory we
 wanted to study was the dual-circle trajectory show in Figure ([[ref:fig:traj_dcirc][double
 circle]]). This provided a direct comparison between the clinical
 practice of using analytic-based to optimization-based reconstruction
 of the entire image volume using all the dual-circle projection data
 at once.

 In addition to the dual circle trajectory, we studied two additional
 trajectories. One trajectory consists of two circles with a line
 connecting them in the axial direction shown in Figure ([[ref:fig:traj_clc][clc]]). We will
 refer to this as the circle-line-circle (CLC) trajectory. The other
 trajectory is a smooth trajectory that translates the source in the
 axial direction while the gantry rotation is slowing and reversing
 direction before acquiring the second circle show in Figure ([[ref:fig:traj_smth][smooth]]).

 #+BEGIN_LaTeX
 \begin{figure*}
   \centering
   \begin{subfigure}[b]{0.3\textwidth}
     \includegraphics[width=\textwidth]{img/traject/dual_circle_20cm.png}
     \caption{Dual circle}
     \label{fig:traj_dcirc}
   \end{subfigure}
   ~
   \begin{subfigure}[b]{0.3\textwidth}
     \includegraphics[width=\textwidth]{img/traject/dual_circle_line_20cm.png}
     \caption{Circle line circle}
     \label{fig:traj_clc}}
   \end{subfigure}
   ~
   \begin{subfigure}[b]{0.3\textwidth}
     \includegraphics[width=\textwidth]{img/traject/dual_smth_20cm.png}
     \caption{Smooth}
     \label{fig:traj_smth}}
   \end{subfigure}
   ~
   \caption{The left image shows the dual circle trajectory. The center
     image shows the circle-line-circle trajectory. The right image shows
     the smooth trajectory. These diagrams of the source trajectory do
     not show the opposing trajectory of the detector around the digital
     patient.}
   \label{fig:poly}
 \end{figure*}
 #+END_LaTeX

**** Developer mode
     :PROPERTIES:
     :ID:       3b90dfa6-e2de-4bdf-886a-31238cfa1cec
     :END:
 To study the new trajectories with a real clinical kV imaging system,
 we implemented some of these trajectories on Varian's TrueBeam
 system. The TrueBeam Developer Mode provides control of the kV imaging
 system to allow for motion control that is unavailable in clinical
 modes. Developer Mode allows control of the gantry rotation, the c-arm
 positions of the source and detector as well as the position of the
 treatment couch. By combining motions with all of these components, it
 is possible to acquire kV projection data for the trajectories studied
 in the simulations.

**** Trajectories
     :PROPERTIES:
     :ID:       4787aeca-bdf3-4b8b-bfda-6c7248cb01d4
     :END:
 After simulation, we then wanted to see how well combining these
 trajectories with optimization-based reconstruction could extend the
 axial FOV with real projection data. Based on the simulation results,
 we acquired a scans from spacings of 17, 18,19, and 20 cm between the
 two circular planes of these trajectories. These larger spacings
 provided data for potential axial FOV's of 37, 38, 39, and 40 cm
 respectively.

 For each of these spacings, we acquired the same three trajectories
 mentioned in the simulation study. First the dual-circle trajectory
 was acquired by moving the c-arms and acquiring circular scans at two
 different axial positions. We then acquired the CLC trajectory with
 the c-arms by also acquiring projection data as they translated along
 the axial direction from the plane of the first circle to the plane of
 the second circle. Finally, the smooth trajectory was acquired by
 having the treatment couch move relative to the source and detector as
 the gantry rotated. *maybe cut this last sentence?* While we would
 like to demonstrate this motion while moving only the c-arms during
 the gantry rotation, this is unfortunately not possible with our
 TrueBeam model due to hardware limitations.

 #+NAME: tab:disk_trajects
 | Trajectory | Axial gap [cm] | Detector configuration | Air scan  | lognorm | Notes                      |
 |------------+----------------+------------------------+-----------+---------+----------------------------|
 | Circle     |                | Full                   |           | x       |                            |
 | Circle     |                | Half                   |           | x       |                            |
 |------------+----------------+------------------------+-----------+---------+----------------------------|
 | CLLC       |             20 | Full                   | 20 cm air | x       |                            |
 | CLLC       |             19 | Full                   | ""        | x       |                            |
 | CLLC       |             18 | Full                   | ""        | x       |                            |
 | CLLC       |             17 | Full                   | ""        | x       |                            |
 |------------+----------------+------------------------+-----------+---------+----------------------------|
 | CLLC       |             18 | Half                   |           | x       | 2 of these for some reason |
 |------------+----------------+------------------------+-----------+---------+----------------------------|
 | SMTH       |             20 | Full                   |           | x       |                            |
 | SMTH       |             19 | Full                   |           | x       |                            |
 | SMTH       |             18 | Full                   |           | x       |                            |
 | SMTH       |             17 | Full                   |           | x       |                            |
 |------------+----------------+------------------------+-----------+---------+----------------------------|
 | SMTH       |             18 | Half                   |           | x       |                            |
 |------------+----------------+------------------------+-----------+---------+----------------------------|

**** Phantoms
     :PROPERTIES:
     :ID:       cd67b907-804c-4212-bf45-6ca6daad766c
     :END:
 The image quality that results from using these trajectories with
 optimization-based algorithms must be quantitatively evaluated for the
 different trajectories and spacings chosen. Given that contrast
 resolution is on of the tasks that enables physicians to utilize the
 imaging system's clinical potential cite:dawson_advances_2007, we
 wanted to characterize the low-contrast resolution as a function of
 axial position for the different trajectories and spacings.

 As the extended axial coverage we obtain with the kV imaging system
 using these methods is novel, the authors do not know of any standard
 phantom for characterizing low-contrast resolution as a function of
 axial position within a single scan. For this reason, we built a
 custom low-contrast disk phantoms that fit in an acrylic tube with
 extended axial coverage as shown in Figure ([[ref:fig:disk_tube][tube setup]]). The disks
 themselves, such as the one shown in Figure ([[ref:fig:lc_disk][low constrast disk]]) *get
 updated disk*, are designed to provide similar metrics such as those
 obtained with the Catphan (The Phantom Laboratory, Salem, NY)
 phantom's low-contrast module CTP515. Additionally, the largest holes
 are designed to hold the different electron density plugs from the
 Gammex (Middleton, WI) RMI tissue characterization phantom. By placing
 four of these disks in the tube, we can obtain these metrics as a
 function of axial position within a given reconstruction.

 #+BEGIN_LaTeX
   \begin{figure}
   \centering
   \begin{subfigure}[b]{0.45\textwidth}
   \centering
   \includegraphics[height=1.75in]{img/poly/20150408_183320_setup.jpg}
   \caption{Disk phantom tube}
   \label{fig:disk_tube}
   \end{subfigure}
   \qquad
   \begin{subfigure}[b]{0.45\textwidth}
   \centering
   \includegraphics[height=1.75in]{img/poly/20150609_disk_phantom.jpg}
   \caption{Low-contrast disk phantom}
   \label{fig:lc_disk}}
   \end{subfigure}
   \caption{The left image shows the experimental setup of the acrylic
     tube with four low-contrast disks. Given they symmetry of the
     scanning geometry, one disk is placed at the plane between the two
     circles. The remaining 3 are place at different axial positions in
     one half of the image volume. The right image shows one of the
     low-contrast disks with the larger holes for the solid water RMI
     inserts.}
   \label{fig:poly}
   \end{figure}
 #+END_LaTeX

 To study these techniques with an anthropomorphic phantom, we used the
 CIRS (Norfolk, VA) Model 600 torso phantom shown in Figure ([[ref:fig:ed][ed]]). Using
 a 14 cm offset detector, we acquired a smooth trajectory scan at *18
 cm spacing*? This scan was chosen as it had the best performance with
 the metrics obtained with the disk phantom.

 #+BEGIN_LaTeX
   \begin{figure}
   \centering
   \begin{subfigure}[b]{0.45\textwidth}
   \centering
   \includegraphics[height=1.75in]{../../research/trajectories/phantoms/cirs/20140901_ed_cllc.jpg}
   \caption{CIRS torso phantom}
   \label{fig:ed_setup}
   \end{subfigure}
   \qquad
   \begin{subfigure}[b]{0.45\textwidth}
   \centering
   \includegraphics[height=1.75in]{../../research/trajectories/phantoms/cirs/600_PHO_01.jpg}
   \caption{Phantom cross sections}
   \label{fig:ed_secs}}
   \end{subfigure}
   \caption{The left image shows the experimental setup of the CIRS torso
     phantom. The right image shows the cross sections of this phantom
     with some of its low-contrast features.}
   \label{fig:ed}
   \end{figure}
 #+END_LaTeX

**** TODO Evaluation
     :PROPERTIES:
     :ID:       3e094a71-3492-4025-885c-12414ccddab5
     :END:
 - Rather than get into a discussion with the reviewers in regard to
   FDK vs iterative, I could use just the EM reconstruction of a
   typical circular scan to avoid complicating the argument in regard
   to the simply the algorithm. Except that I need to show what happens
   at the axial extremes with stacked FDK.

*** proposal                                 :noexport:
**** Simulated non-circular trajectories
     :PROPERTIES:
     :ID:       e054809f-7e83-4b52-9005-5c8b325624b9
     :END:
 When an extended axial FOV is needed in the clinic, in current
 practice two circular scans are acquired at different axial
 positions. Once each independent volume has been reconstructed with
 the analytic-based FDK, the two volumes are stacked to create the
 extended image. While this stacked image does have extended axial
 coverage, there are problems with this approach that can be alleviated
 with iterative reconstruction techniques. To evaluate this, we
 compared the simulated results of stacking FDK images from two
 circular scans to the iterative reconstruction from the combined
 projection data of the two circular scans treated as a single
 trajectory composed of two circles cite:davis_extended_2013.

 # How much detail do I want to go into, just present the main point
 # that at the extended spacing, the FDK algorithm cannot even recover
 # enough of the volume to provide a useful image volume
 # *Leave XCAT out for now* The
 # other phantom was the anthropomorphic XCAT phantom which is defined
 # analytically as a NURBS surface with polychromatic forward projectors
 # cite:segars_realistic_2008.

***** Simulation model
      :PROPERTIES:
      :ID:       e4cdbd91-3ea9-4606-81bb-2e4e8380942d
      :END:
 For these simulations, the imaging system was modeled from the
 TrueBeam kV imaging system. This imaging system consists of a 40 x 30 cm^2 flat-panel
 detector with a 1.5 magnification factor. Given the detector's length
 in the axial direction is 30 cm, a 1.5 magnification factor means the
 axial length in the image FOV from a single circular scan is 20 cm.

 We generated forward projections from pairs of circular scans with
 different axial spacing between the two planes of the source's
 rotation. Since the maximum axial coverage for a single circular scan
 in the image volume is 20 cm, the maximum shift that will still allow
 data collection from a contiguous region of the image volume is 20
 cm. This 20 cm shift should provide a maximum axial coverage in the
 image volume of 40 cm, the same axial length as the treatment field of
 the TrueBeam.

***** Defrise-style phantom
      :PROPERTIES:
      :ID:       89bedf9d-7a7b-410b-aef9-a4b5e021d0f0
      :END:
 We used a simulated Defrise-style phantom composed of 5 mm thick disks
 of alternating high and low densities in the axial direction. This
 geometric design is acknowledged by the FDK authors as being the type
 of phantom most susceptible to cone-angle artifacts
 cite:feldkamp_practical_1984. We simulated and forward projected the
 Defrise phantom with the TAKE software
 cite:muller-merbach_simulation_1996 using 300 views distributed
 uniformly over each circular scan.

***** Reconstruction
      :PROPERTIES:
      :ID:       db5e90cd-9b76-4ca9-95ee-f48c122bed6b
      :END:
 To create the stacked FDK reconstructions, we first reconstructed the
 FDK volume from each circular scan. We then used the axial plane at
 the midpoint between the two circular planes as a discriminator for
 selecting the FDK volume from which each slice was taken. For
 iterative reconstructions, we used 100 iterations of the maximum
 likelihood expectation maximization (MLEM) algorithm
 cite:dempster_maximum_1977,shepp_maximum_1982 to reconstruct the
 entire extended image from all of the projection data at once. Both
 the FDK and iterative reconstructions used the same 256 x 256
 transverse grid size with 1 mm isotropic voxels. Figure
 (\ref{fig:sim_take}) shows mid-sagittal slices from some of these
 simulations.

 #+BEGIN_LaTeX
   \begin{figure*}[t!]
     \centering
     \begin{tabular}{lccc}
       \toprule
       &FDK stacked&MLEM double circle&MLEM smooth\\
       \midrule

       18~cm&
       \includegraphics[height=3cm]{img/take/fdk_18cm.png}&
       \includegraphics[height=3cm]{img/take/mlem_dual_18cm.png}&
       \includegraphics[height=3cm]{img/take/mlem_smth_18cm.png}\\
       20~cm&
       \includegraphics[height=3cm]{img/take/fdk_20cm.png}&
       \includegraphics[height=3cm]{img/take/mlem_dual_20cm.png}&
       \includegraphics[height=3cm]{img/take/mlem_smth_20cm.png}\\

       \bottomrule
     \end{tabular}
     \caption{Mid-sagittal views of the Defrise disk phantom
       reconstructions at different separation distances. The display
       window is [0.1, 0.3]~cm$^{-1}$. The left column shows the stacked
       FDK extended volumes, and the remaining columns show the
       100$^{\text{th}}$ iteration of the MLEM extended volumes for
       different trajectories.}
     \label{fig:sim_take}
     %\vspace{-1em}
   \end{figure*}

 #+END_LaTeX

***** Trajectories
      :PROPERTIES:
      :ID:       f5de64b9-d14d-4a3a-a051-93538e9fc35b
      :END:
 By increasing the separation between the two circular scans up to the
 maximum spacing of 20 cm, it is apparent that FDK has fundamental
 support limitations that restricts the acceptable distance between
 these two circles to less than the maximum 20 cm spacing. The gap in
 the axial coverage is a region with insufficient scan information
 which is known as the shadow zone cite:forthmann_adaptive_2009. The
 MLEM algorithm can use information from both circular scans
 simultaneously, leading to improved reconstruction of the image in the
 shadow zone as seen in Figure (\ref{fig:sim_take}). It is likely that
 if such an extended image volume were to be used in the clinic, it
 would be centered on an object of interest. If this were so, the most
 important content in the image would be in the region most afflicted
 by cone-angle artifacts.

 To acquire more scan information from the central region between the
 two circles, we also simulated two other trajectories. Both of these
 trajectories acquire additional view while translating the source and
 detector from the axial position of one circle to the other. One of
 these trajectories is a circle-line-circle trajectory where the
 translation phase of the source and detector between the two circles
 is a line as Figure (\ref{fig:traj_clc}) shows. The other trajectory
 shown in Figure (\ref{fig:traj_smth}) is a smooth trajectory that is
 similar to the circle-line-circle, but the gantry rotation and
 longitudinal translation are designed to avoid sharp transition points
 in the imaging trajectory.

 #+BEGIN_LaTeX
   \begin{figure}
     \centering
     \subfloat[Circle line circle]{\includegraphics[width=0.45\textwidth]{img/traject/clc.pdf}%
       \label{fig:traj_clc}}
     \qquad
     \subfloat[Smooth]{\includegraphics[width=0.45\textwidth]{img/traject/smth.pdf}%
       \label{fig:traj_smth}}
     \caption{The left image (a) shows the circle-line-circle trajectory
       with a 20 cm spacing between the circles. The right image (b)
       shows the smooth trajectory with a 20 cm spacing between the
       circles. The units for the axes are in centimeters, and the color
       gradient shows the temporal evolution of the source position.}
     \label{fig:poly}
   \end{figure}
 #+END_LaTeX

 #+CAPTION: Plot of the RMSE for extended volumes of different trajectories with different spacing between planes of the circles, compared to the central CBCT volume of a single circular scan.
 #+ATTR_LaTeX: :width \textwidth
 #+LABEL: fig:take_rmse
 file:./img/take/central_cbct_rmse.pdf

***** RMSE
      :PROPERTIES:
      :ID:       b579be25-3925-455b-ad5a-00c6bb4bb1fa
      :END:
 Figure (\ref{fig:take_rmse}) shows a root-mean-square error (RMSE)
 comparison of a variety of different trajectories with different
 spacings between the two planes of the circles. The volume for which
 the RMSE is calculated is the central volume between the two circles
 with a 20 cm axial length, which would be the region seen with a
 single CBCT scan. The figure shows that for any extended volume
 spacing, the stacked-FDK reconstruction from two separate circles
 deviates the most from the truth, and it degrades with increasing
 separation. The figure also shows that the iterative reconstruction of
 the same dual-circle trajectory is much closer to the truth, but
 demonstrates the same degradation with increasing spacing between the
 two circles. Finally, the double circle and line trajectory and the
 new smooth trajectory iterative reconstructions remain relatively
 constant for increasing spacing, with the smooth trajectory being
 closer to the truth. The slices shown in Figure (\ref{fig:sim_take})
 visually agree with these results. The double circle and line
 trajectory was left out of Figure (\ref{fig:sim_take}) since the
 results were not visually distinguishable from the smooth trajectory
 reconstructions.

**** TODO Experimental non-circular trajectories
     :PROPERTIES:
     :ID:       eef6d73b-7ca0-4031-bd66-4a14c1fcc015
     :END:
 # We don't need to include the Trilogy data since we have the smooth
 # trajectory acquired with Ed from the smooth trajectory

 After identifying potential benefits from using these non-circular
 trajectories with iterative reconstruction methods from simulations,
 we acquired experimental scan data with Varian's Trilogy OnBoard
 Imager. Though the Trilogy lacks the mechanical control features of
 the TrueBeam Developer Mode, we were able to acquire circular scans at
 different axial positions by translating the treatment couch.

***** Phantoms
      :PROPERTIES:
      :ID:       16e0ec1b-d733-4e67-912e-a6a1f5ac800d
      :END:
 We repeated the same reconstruction process of stacking FDK
 reconstructions and using MLEM to iteratively reconstruct the entire
 image volume from a single trajectory composed of two circular
 scans. One phantom was a Defrise disk phantom of the same dimensions
 of the simulated disk phantom, with alternating disks of Delrin and
 cork. The other phantom was the upper torso of the RANDO Man phantom
 (The Phantom Laboratory, Salem NY). The experimental results shown in
 Figure (\ref{fig:trilogy_data}) demonstrate the same finding that
 iterative reconstruction could recover more of the shadow zone where
 the FDK fails.

 #+BEGIN_LaTeX
   \begin{figure*}[t!]
     \centering
     \begin{tabular}{lccc}
       \toprule
       &Central Single Circle&12~cm Double Circle&20~cm Double Circle\\
       \midrule

       FDK&
       \includegraphics[height=3cm]{img/trilogy/stacked_defrise_00cm_256x256x200_sag.png}&
       \includegraphics[height=3cm]{img/trilogy/stacked_defrise_12cm_256x256x320_sag.png}&
       \includegraphics[height=3cm]{img/trilogy/stacked_defrise_20cm_256x256x400_sag.png}\\
       MLEM&
       \includegraphics[height=3cm]{img/trilogy/disk_dual_00cm_em_list_256x256x234_sag.png}&
       \includegraphics[height=3cm]{img/trilogy/disk_dual_12cm_em_list_256x256x354_sag.png}&
       \includegraphics[height=3cm]{img/trilogy/disk_dual_20cm_em_list_256x256x434_sag.png}\\

       \midrule

       FDK&
       \includegraphics[height=3.5cm]{img/trilogy/stacked_rando_00cm_200x512x512_sag.png}&
       \includegraphics[height=3.5cm]{img/trilogy/stacked_rando_12cm_320x512x512_sag.png}&
       \includegraphics[height=3.5cm]{img/trilogy/stacked_rando_20cm_400x512x512_sag.png}\\
       MLEM&
       \includegraphics[height=3.5cm]{img/trilogy/rando_00cm_hf_300x512x512_sag.png}&
       \includegraphics[height=3.5cm]{img/trilogy/rando_12cm_hf_380x512x512_sag.png}&
       \includegraphics[height=3.5cm]{img/trilogy/rando_20cm_hf_440x512x512_sag.png}\\

       \bottomrule
     \end{tabular}
     \caption{Mid-sagittal views of the Defrise disk and RANDO phantom
       reconstructions for a single scan and double circular scans at
       different separation distances. The top two rows show the Defrise
       disk phantom, and the bottom two rows show the RANDO phantom. The
       display window is [0.1, 0.3]~cm$^{-1}$. The red arrows indicate
       misalignment artifacts in the MLEM reconstruction introduced by
       the couch translation.}
     \label{fig:trilogy_data}
     %\vspace{-1em}
   \end{figure*}

 #+END_LaTeX

***** Dual-circle trajectory
      :PROPERTIES:
      :ID:       fe10444a-7b7c-4eaf-9e2e-6b44b8bb7dc9
      :END:
 While a 20 cm spacing between the two circles is the theoretical
 maximum spacing where contiguous volumes can be combined in an
 extended axial image, there are some practical limitations that
 further limit the spacing. Specifically, the edge of the kV detector
 has a few rows of unusable pixels. When the maximum spacing is used,
 these rows result in a small volume in the image where there is no
 redundancy to fill in the corrupted volume. The lack of redundancy in
 this overlap region also makes the reconstruction more susceptible to
 geometric artifacts like the vertical displacement in the couch
 between the two longitudinal positions. The geometric calibration
 phantom is being developed to detect such displacements which will
 reduce the subsequent artifacts in these regions. By using a slightly
 smaller spacing of 18 cm which still produces an axial FOV of 38 cm,
 sufficient redundancy is available to reconstruct this volume.

***** Dual-circle-extended-line trajectory
      :PROPERTIES:
      :ID:       d48ac1be-2a33-4769-8591-720d753d7bb5
      :END:
 Subsequent experimental scans were performed with Varian's TrueBeam
 kV imaging system. This allowed the use of the TrueBeam Developer Mode to acquire
 scan data from non-circular trajectories other than two circles. In
 addition to programming couch motion, Developer Mode allows the motion
 of the source and detector arms to be programmed as a series of
 control points. The advantage of using just the imaging arms to cover
 an extended axial volume is that the patient can be left at the
 isocenter. This is very advantageous as moving the patient will always
 introduce some uncertainty after moving the patient back, and it is
 more comfortable for the patient when the couch does not move.

 For the dual-circle-extended-line trajectory, it was possible to
 acquire this in Developer Mode by controlling just the c-arms. This
 trajectory shown in Figure (\ref{fig:cllc_traj}) acquires data from
 two circles 19 cm apart and during the translation of the source and
 detector from the superior to inferior circle. It also acquires an
 additional 4.5 cm linear scan above and below the two circles, which
 helps reduce the cone-angle artifacts at the edge of the
 FOV. Downsampling from this data set can provide scan data for the
 dual circle, the dual circle and line, and the dual circle extended
 line. We scanned the CIRS Torso Phantom (Computerized Imaging
 Reference Systems, Norfolk, VA) which contains low-contrast structures
 unlike the RANDO phantom.

 #+BEGIN_LaTeX
   \begin{figure}
     \centering
     \subfloat[Source
     trajectory]{\includegraphics[height=4.5cm]{img/tb/cllc_detector_trajectory_18cm.png}%
       \label{fig:cllc_traj}}
     \qquad
     \subfloat[Mid-sagittal]{\includegraphics[height=4.5cm]{img/tb/ed_cllc_19cm_sag}%
       \label{fig:ed_sag}}
     \qquad
     \subfloat[Mid-coronal]{\includegraphics[height=4.5cm]{img/tb/ed_cllc_19cm_cor}%
       \label{fig:ed_cor}}
     \caption{Dual-circle-extended-line TrueBeam acquisition and
       reconstruction. The left image (a) shows the kV source trajectory
       from the data headers of the scan implemented with Developer
       Mode. Figures (b) and (c) are the sagittal and coronal views of
       200$^{\text{th}}$ MLEM iteration reconstruction of the CIRS torso phantom
       in this scan.}
     \label{fig:cllc}
   \end{figure}
 #+END_LaTeX

***** Smooth trajectory
      :PROPERTIES:
      :ID:       baac07b2-2ba8-4de5-a77b-9c4a75b50da7
      :END:
 One limitation of our version of Developer Mode is that it is not
 possible to move the source and detector arms during the gantry
 rotation. For this work, any desired arm translation during gantry
 rotation is mimicked with the couch translation whenever it will
 produce an equivalent relative translation. While this is not exactly
 equivalent, it allows a close approximation of such a trajectory. For
 this reason, the smooth trajectory discussed in the previous section
 was implemented with gantry rotation and couch translation.

** Results
   :PROPERTIES:
   :ID:       b2a353e8-8531-4a0e-8337-9f702ecf02f8
   :END:
*** Simulation
:PROPERTIES:
:ID:       ff434d74-757c-47b8-bd98-9250d2751ff2
:END:
The initial simulation results demonstrated promising advantages to
using the optimization-based reconstruction to produce extended-axial
coverage images.

- [ ] insert comparison table of FDK
- [ ] show plot of RMSE in the overlap region

From the results shown in Figure (\ref{fig:})
*** Data
**** notebooks
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/fov/em_vs_fdk.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/fov/em_vs_fdk.ipynb]]
** Conclusion
   :PROPERTIES:
   :ID:       99a861bc-c072-4082-806f-9279fa7c3a3c
   :END:
* Collision-avoiding trajectories            :col:
  :PROPERTIES:
  :ID:       99055e18-4b61-404e-9408-ebd5fd0a5d8d
  :END:
** notes                                     :noexport:
   :PROPERTIES:
   :ID:       53a46fd0-a854-4b6a-a253-dde04d4f7a87
   :END:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
*** publications
    :PROPERTIES:
    :ID:       32703eae-6f65-4a6a-9f23-813e60747126
    :END:
- 2015 MIC virtual isocenter
- 2016 CT meeting dyanmic magnification
- 2016 MIC mixed magnification
- 2017 Varian dynamic magnification
** Introduction
   :PROPERTIES:
   :ID:       b0e53ca9-9c57-46e5-a558-c878b2ee1bdd
   :END:
 The addition of a linac-mounted, kV-imaging, cone-beam computed
 tomography (CBCT) system to the gantry-mounted clinical linear
 accelerator (linac)
 cite:jaffray_flat-panel_2002,letourneau_cone-beam-ct_2005,rahman_linac:_2015
 helped this modality become the most popular form of image-guided
 radiation therapy (IGRT). The tomographic information provided in the
 kV energy range improves soft-tissue contrast resolution over that
 provided by the MV electronic portal imaging device (EPID) alone
 cite:jaffray_radiographic_1999. The linac-mounted, kV-imaging, CBCT
 system not only helps with patient setup and target verification, but
 it also allows the monitoring of the tumor response during treatment
 cite:oldham_cone-beam-ct_2005,xing_overview_2006,dawson_advances_2007.

 It is therefore detrimental when adequate tomographic information
 cannot be obtained from the kV-imaging CBCT system. One situation in
 which this can occur is when a collision between the patient and the
 machine arises cite:padilla_collision_2015. These may be of particular
 concern in breast and lung cancer patients where the arm position
 leads to a possible collision as shown in Figure ([[ref:fig:barbie_collision][barbie collision]]).
 Collisions also present a problem in treatment of posterior and
 lateral lesions in stereotactic body radiosurgery (SBRT). Similarly in
 prone breast treatments, where the target is near the couch top and a
 lateral couch translation is needed to bring the target to isocenter,
 collision with the contralateral side of the patient may occur. When
 collisions do occur, the angular range available for scanning is
 restricted and it is not possible to acquire a complete circular scan
 in the treatment position .

 #+BEGIN_EXPORT latex
 \begin{figure*}
   \centering
   \begin{subfigure}[b]{0.45\textwidth}
     \includegraphics[width=\textwidth]{figures/barbie_mv.jpg}
     \caption{}
     \label{fig:barbie_mv}
   \end{subfigure}
   ~%add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
   %(or a blank line to force the subfigure onto a new line)
   \begin{subfigure}[b]{0.45\textwidth}
     \includegraphics[width=\textwidth]{figures/barbie_kv.jpg}
     \caption{}
     \label{fig:barbie_kv}
   \end{subfigure}
   \caption{Two examples of potential collision for a
     typical patient setup using a mannequin in a supine treatment
     position. As can be seen, collisions can occur both with the face
     of the MV treatment head (distance 41.7 cm from isocenter for this
     linac) and with the kV detector (distance 45-70 cm from isocenter,
     depending on magnification).}
   \label{fig:barbie_collision}
 \end{figure*}
 #+END_EXPORT

 To avoid collisions with the treatment head, it could be desirable to
 move the patient away from the gantry as it approaches a collision,
 simply by translating the couch. To avoid collisions with the imaging
 panel, the patient might also be moved away from the panel as a
 collision approaches. As some linac-mounted, kV-imaging panels have
 motion capabilities, another solution would be to move the imager away
 from the patient in the collision zone, which changes the imaging
 magnification for that portion of the scan. Given that the clearance
 distance of the kV-imaging panel is not much larger than that of the
 MV-treatment head, a collision avoidance solution nneeds to take into
 account both of these components.

 Though there has been previous work in developing analytic methods for
 addressing the reconstruction from some novel trajectories
 cite:katsevich_theoretically_2002,katsevich_image_2004,katsevich_image_2005,katsevich_formulation_2006,
 it could be clinically useful to enable reconstruction from an
 arbitrary, collision-avoiding trajectory. As the collision region (if
 one arises) is contingent on the patient's treatment position, the
 imaging trajectory would then vary on a per patient basis. As such,
 deriving the analytic inverse for each patient's scanning trajectory
 would be impractical in a clinical work flow.

 Optimization-based reconstruction algorithms provide a straightforward
 means of enabling reconstruction from patient-specific collision
 avoiding trajectories
 cite:han_optimization-based_2012,bian_optimization-based_2013. The
 imaging model is formulated as the linear transform
 \begin{equation}
   \label{eq:linmodel}
   \mathbf{g}=\mathcal{H}\mathbf{f},
 \end{equation}
 where $\mathbf{g}$ is the discrete $M$ pixel sampled projection on the
 detector, $\mathcal{H}$ is the $M\times N$ discrete form of the X-ray
 transform, and $\mathbf{f}$ is the object function represented on a N
 voxel basis. As the direct inversion of Equation ([[ref:eq:linmodel][linear model]]) is
 impractical due to both its size and inconsistencies from factors such
 as noise, optimization techniques are used to solve this system for an
 estimate of the object $\mathbf{f^{*}}$.

 This approach allows for a generalized reconstruction framework that
 allows for greater flexibility in reconstructing from projections
 acquired with non-circular trajectories. Provided the geometry of each
 view is correctly incorporated into the system matrix $\mathcal{H}$,
 clinically useful reconstructions can be obtained from acquisitions
 for which an analytic inverse may not be available. As the collision
 zone for a given patient would be patient specific, this robust
 approach enables tomographic imaging from collision-avoiding
 trajectories that would accommodate the patient's specific needs.

 In this study, we investigate examples of potential scanning
 trajectories that would allow the acquisition of sufficient projection
 information for a clinically useful image while avoiding a potential
 patient collision with the gantry. As the gantry rotates, there are
 two components of the linac that are potential sources of patient
 collisions. These are the MV-treatment head, shown in Figure ([[ref:fig:barbie_collision][barbie
 collision]]), and the kV-CBCT detector.

 One trajectory that would avoid a patient collision with the
 MV-treatment head is a virtual isocenter trajectory. This trajectory
 avoids such a collision by increasing the effective source-to-axis
 distance (SAD). By using this increased SAD for an imaging trajectory,
 the clearance between the patient and the MV-treatment head as the
 gantry rotates is increased and the collision is avoided.

 The virtual isocenter trajectory utilizes synchronized gantry rotation
 and couch translation to maintain a fixed distance (``virtual SAD'')
 between the MV source and a chosen center of rotation (``virtual
 isocenter'') in the patient. At the beginning of the scan, the patient
 is moved away from the linac head along the MV beam direction. As the
 gantry rotates, the couch moves continuously to maintain the specified
 separation as shown in Figure ([[ref:fig:virtual_iso]]). The virtual SAD
 can be chosen large enough so that collisions as shown in Figure
 ([[ref:fig:barbie_mv]]) are avoided; at this point in the trajectory, the
 couch would have moved far enough to the left to avoid the collision.
 Note that it is only the distance to the linac head that is increased
 in the plain virtual SAD technique; the distance from the kV source
 and detector to the patient and to each other are unchanged.

 #+BEGIN_EXPORT latex
 \begin{figure*}
 \centering
 \includegraphics[width=\textwidth]{figures/gantry_3angles.eps}
 \caption{Patient, kV and MV beams and kV detector at several angles
   during a virtual isocenter rotation. Room coordinate system (dotted
   axes) has its origin at mechanical isocenter, also the intersection
   of the MV (red) and kV (green) beam axes. As the gantry rotates, the
   patient (filled contour) is continually shifted to maintain a
   specified distance along the MV beam direction between the
   mechanical isocenter and the chosen virtual isocenter (circle symbol
   within the patient). The path of the virtual isocenter is a circle
   about the mechanical isocenter, with radius equal to the chosen
   shift (12 cm from the isocenter in this example). Detector may or
   may not be shifted as shown, depending on virtual isocenter position
   and patient geometry.
 \label{fig:virtual_iso}}
 \end{figure*}
 #+END_EXPORT

 Another trajectory that could avoid a patient collision with the kV
 detector would be one during which either the patient or the detector
 is moved during the scan in the angular range of a collision. Either
 solution leads to changing kV-CBCT imaging magnification during the
 acquisition. Again, optimization-based reconstruction methods can
 readily handle such a change in magnification provided the projection
 information is correctly incorporated into the system matrix.

 Finally, we study a trajectory that combines both virtual isocenter
 and dynamic magnification trajectories to create a hybrid scanning
 acquisition that would alleviate collisions with both the MV-treatment
 head and the kV-CBCT detector. We use such a trajectory as an example
 of a patient-specific scanning trajectory designed to avoid a
 collision that would arise with a particular treatment position.

** Methods and Materials
   :PROPERTIES:
   :ID:       973b1793-b733-43ce-a7aa-dd31af58c680
   :END:
*** CBCT System
    :PROPERTIES:
    :ID:       85ce12ce-235b-46da-873d-0ad54468893e
    :END:
 We used Varian's TrueBeam kV imaging system (Varian Medical Systems,
 Palo Alto, CA) to acquire the projection data used in this study. This
 is a linac-mounted CBCT c-arm system consisting of a Varian kV x-ray
 source (GS-1542) and a 39.7 cm x 29.8 cm amorphous silicon flat-panel
 detector (PaxScan 4030CB). The source and detector are mounted on
 robotic arms with the kV beam direction orthogonal to the MV treatment
 beam.

 To implement the different collision-avoiding scanning trajectories,
 we used Varian's TrueBeam 2.0 Developer Mode. This is a research mode
 of the TrueBeam system that allows us to implement scanning
 configurations that are unavailable in clinical modes by programming
 the motions of the gantry, couch and kV imaging arms. As in the case
 of this virtual isocenter study, it is possible to acquire projection
 images while both the treatment table and the gantry are in motion. At
 present, simultaneous motion of the gantry and kV imaging arms is not
 possible. We have worked around this limitation in our variable
 magnification imaging as described in [[id:dd0b68a5-c0eb-4c57-a28f-c27e2c57c8d8][II.C]] below.

*** Phantoms
    :PROPERTIES:
    :ID:       501e0d09-ed7c-4c78-a997-477e6414df18
    :END:
 The abdominal region of the CIRS (Computerized Imaging Reference
 Systems, Norfolk, VA) model 600 torso phantom was scanned. This
 phantom contains both high-contrast (bone) and low-contrast (soft
 tissue) structures in an anthropomorphic form. These features provide
 an indication of imaging performance in more clinically relevant
 conditions.

 To quantify image quality metrics for the different scanning
 trajectories, we used a Catphan 504 (The Phantom Laboratory, Salem,
 NY). This is a standard quality assessment (QA) phantom for clinical
 CT devices that provides a series of sections with different objects
 for calculating image quality metrics. We used the CTP 404 module for
 evaluating low-contrast resolution, and the CTP 404 and 528 modules
 for evaluating spatial resolution.

*** Scans
    :PROPERTIES:
    :ID:       dd0b68a5-c0eb-4c57-a28f-c27e2c57c8d8
    :END:
 For the circular scans, the gantry made a full rotation about the
 patient with the treatment volume at a fixed mechanical SAD of 100 cm.
 For the virtual isocenter scans, the patient couch was translated
 continuously in the gantry rotation plane during gantry rotation to
 maintain a distance of 112 cm between the MV source and the chosen
 target point within the treatment volume (the "virtual isocenter"),
 rather than the mechanical SAD of 100 cm as shown in Figure
 ([[ref:fig:virtual_iso]]). We generated all of the scanning trajectories
 in this study using the Developer Mode 2.0 XML schema to create
 control points for the gantry, the kV imaging arms, and the patient
 treatment table. Imaging control points were placed along the
 trajectory to acquire kV-projection images during the scan. We used a
 half-fan detector configuration with a 13 cm offset for the circular
 acquisition, and an equivalent offset for the virtual isocenter to
 obtain the same illumination.

 To increase the clearance between the kV detector and the patient, we
 increased the radius of the kV detector with accompanying increase in
 magnification of the kV imaging system. To create projection datasets
 where the detector distance changes during a scan, we acquired
 multiple scans using different detector positions and subsequently
 spliced these together to create the sinograms of interest with the
 corresponding system matrix $\mathcal{H}$. This allowed us to create
 different dynamic magnification scan datasets. We acquired both
 circular and virtual isocenter trajectories with detector positions of
 50 cm, 60 cm and 70 cm away from the mechanical isocenter for
 magnifications of 1.5X, 1.6X and 1.7X respectively. In each case, the
 detector cover is 5 cm closer to the patient than the CsI layer,
 potentially leading to collisions with the limits shown in the first
 plot in Figure ([[ref:fig:collision_zones]]).

 #+CAPTION: Collision zones in the patient image space for the kV detector cover and the MV treatment head accessory mount. The left figure shows the increasing radius of the kV-detector collision zone with an increase in magnification. The middle figure shows the increased radius of the kV-detector collision zone for the two dynamic magnification trajectories utilizing a $45^{\circ}$ bump at a higher magnification. The right figure shows the increased radius of the MV-treatment-head collision zone when using the virtual isocenter scanning trajectory.
 #+ATTR_LaTeX: :width \textwidth :float multicolumn
 #+LABEL: fig:collision_zones
 [[file:figures/collision_zones.pdf]]

 To create the combined sinogram of a hypothetical collision-avoiding
 dynamic magnification scan, we replaced a $45^{\circ}$ region of the 1.5X
 circular scan with the corresponding angular range from scans at
 different magnifications. We chose this region to be centered on the
 angular position where the mannequin's elbow is in Figure
 ([[ref:fig:barbie_collision]]). Increasing the magnification in this
 region corresponds to increasing the clearance between the kV-detector
 and the patient. Increasing the magnification to 1.6X provides an
 additional 10 cm of clearance, and to 1.7X an additional 20 cm of
 clearance. We also created an additional $35^{\circ}$ 1.7X bump
 magnification with $5^{\circ}$ transitions at a 1.6X magnification. The
 kV-detector collision zones of these dynamic magnification
 trajectories are shown in the middle plot shown in Figure
 ([[ref:fig:collision_zones]]).

 For the collision with the MV treatment head accessory mount shown in
 Figure ([[ref:fig:barbie_collision]]), using the virtual isocenter imaging
 trajectory would alleviate this problem. The radius of the accessory
 mount from the mechanical isocenter is 41.7 cm. For the virtual
 isocenter used in this study, there is a 12 cm increase in the radius
 of this collision zone as shown in the last plot in Figure
 ([[ref:fig:collision_zones]]). Utilizing a different virtual SAD would
 allow for additional clearance if necessary.

 The last set of trajectories we studied combines the dynamic
 magnification with the virtual isocenter trajectory. As the collision
 radius with the MV treatment head and the kV detector are similar for
 the current clinical scan, collisions with both could arise. By
 combining the change in magnification with the virtual isocenter
 trajectory, both collision zones could be avoided. Table
 ([[ref:tab:trajectories]]) shows the different scans investigated in this
 study.

 # +ATTR_LATEX: :environment longtable
 #+CAPTION: Scanning trajectories
 #+NAME: tab:trajectories
 |-------------------+------------------------------------------|
 | Trajectory        | Magnification                            |
 |-------------------+------------------------------------------|
 | Circle            | 1.5X                                     |
 |                   | 1.5X & $45^{\circ}$ 1.6X bump                   |
 |                   | 1.5X & $45^{\circ}$ 1.7X bump                   |
 |                   | 1.5X & $35^{\circ}$ 1.7X bump, 1.6X transitions |
 |-------------------+------------------------------------------|
 | Virtual isocenter | 1.5X                                     |
 |                   | 1.5X & $45^{\circ}$ 1.6X bump                   |
 |                   | 1.5X & $45^{\circ}$ 1.7X bump                   |
 |                   | 1.5X & $35^{\circ}$ 1.7X bump, 1.6X transitions |
 |-------------------+------------------------------------------|
**** figures                                 :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/collision_avoidance.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/collision_avoidance.ipynb]]
*** Reconstruction
    :PROPERTIES:
    :ID:       d0eac288-37d6-4cef-97c8-7896dcc67733
    :END:
 To find an estimate of the object $\mathbf{f^{*}}$ as an approximate
 solution to Equation ([[ref:eq:linmodel]]), we choose a reconstruction
 program that can be solved with the well-understood maximum-likelihood
 expectation maximization (MLEM) algorithm cite:dempster_maximum_1977.
 Here, our reconstruction program is formulated as
 \begin{equation}
   \mathbf{f^{*}} = \text{argmin}D_{KL} \left(\mathbf{f}\right)
   \label{eq:kl}
 \end{equation}
 where $D_{KL}(\mathbf{f})$ is the KL divergence between $\mathbf{g}$ and
 $\mathcal{H}\mathbf{f}$ cite:barrett_foundations_2003. The KL
 divergence is minimized with the MLEM algorithm
 \begin{equation}
 f_j^{(n+1)}=\frac{f_j^{(n)}}{\sum\nolimits_{i=1}^{M}\mathcal{W}_{ii}\mathcal{H}_{ij}}\sum\limits_{i=1}^{M}\mathcal{W}_{ii}\mathcal{H}_{ij}\frac{g_i}{\sum\nolimits_{j=1}^{N}\mathcal{H}_{ij}f_j^{(n)}}
   \label{eq:mlem}
 \end{equation}
 where $f_{j}^{n}$ is $j-\text{th}$ voxel value at iteration $n$ and
 $\mathcal{H}_{ij}$ is the element of the system matrix at the
 $i-\text{th}$ row and $j-\text{th}$ column for $i=1,2,...,M$ and
 $j=1,2,...,N$. The initial image estimate for the reconstructions was
 $\mathbf{f}^{(0)}=1$. The $M\times M$ diagonal matrix $\mathcal{W}$ weights
 the corresponding data entries as is typically done for a standard
 half-fan detector configuration for a circular scan
 cite:bian_optimization-based_2013.

 In a traditional scanning configuration where the patient is
 stationary, the system matrix $\mathcal{H}_{ij}$ projects the object
 $\mathbf{f}$ from image space to the data space of $\mathbf{g}$. When
 this is the case, it is sufficient that the coordinate basis of the
 image space coincides with the room coordinate system, or is at least
 stationary relative to it. From each projection view acquired from the
 TrueBeam system, we extracted the position information of the CBCT
 imaging arms and subsequently built $\mathcal{H}_{ij}$ as the projective
 transform from image space in the IEC coordinate system to the data
 space of the kV detector.

 For a virtual isocenter-scanning trajectory, the image space
 $(\mathbf{f}_{\text{patient}})$ is moving relative to the room coordinate
 system for each projection view. As such, a change of basis for the
 columns space of $\mathcal{H}$ is necessary so that the new system
 matrix represents a transform from the image space of the patient to
 the data space of the detector represented as $\mathcal{H'}$. As the
 acquisition system also reports the couch position, we used this to
 build the required transformation matrix
 $\mathcal{T}_{\text{IEC,patient}$ for each projection view. The
 imaging model in Equation ([[ref:eq:linmodel]]) then becomes
 \begin{equation}
   \label{eq:linmodel_patient}
   \mathbf{g}=\mathcal{H'}\mathbf{f_{\text{patient}}},
 \end{equation}
 where
 \begin{equation}
   \label{eq:sys_patient}
   \mathcal{H'}=\mathcal{H}\mathcal{T_{\text{IEC,patient}}}.
 \end{equation}
 Once the change of basis is accounted for, the reconstruction program
 in Equation ([[ref:eq:kl]]) can be reformulated with $\mathbf{f_{\text{patient}}}$
 instead of $\mathbf{f}$ and solved with the MLEM algorithm in Equation
 ([[ref:eq:mlem]]) using $\mathcal{H'}$ instead of $\mathcal{H}$.

 The addition of couch motion to the imaging trajectory does increase
 the degrees of freedom for which proper geometric calibration must be
 acquired. Using Varian's Isocal calibration phantom, we developed an
 optimization-based calibration protocol that allows us to extract
 calibration offsets for improving our estimate of the system matrix
 $\mathcal{H'}$. Using same scanning trajectory to image the Isocal
 phantom, the nominal scanning metadata from the TrueBeam projections
 provided an initial estimate of the imaging geometry. We then used the
 Nelder-Mead simplex program to search for the geometric offsets for
 the source, detector, and treatment couch positions at each view, as
 well as the phantom pose to account for possible setup errors. The
 cost of this optimization used the $L_{2}-\text{norm}$ between the
 projected fiducials in the real data sinogram and the simulated
 projection of the fiducials using the current estimate of the system
 geometry. We used the estimated offsets that minimized the cost
 function to refine our system matrix $\mathcal{H'}$ that we
 subsequently used in the MLEM reconstruction program.

 We reconstructed all of these fixed magnification and dynamic
 magnification scans from circular and virtual isocenter trajectories
 into the patient image space described by the imaging model in
 Equation ([[ref:eq:linmodel_patient]]). The Catphan scans were
 reconstructed onto an isotropic voxel size of 0.473 mm. The CIRS torso
 scans were reconstructed onto an isotropic voxel size of 0.836 mm. As
 the circular acquisition with 1.5X magnification is the typical
 clinical acquisition trajectory, this provides a clinical reference
 volume for the reconstructions from the other scanning configurations.

 #+CAPTION: Plot of the Catphan's edge-spread function MTF at 50% and 25% as well as the MTF AUC for the clinical circular 1.5X half-fan scan.
 #+ATTR_LaTeX: :width \columnwidth
 #+LABEL: fig:mtf_vs_iteration
 [[./figures/edge_spread_mtf_iteration.pdf]]

 Figure ([[ref:fig:mtf_vs_iteration]]) shows the 25% and 50% MTF crossing
 spatial frequencies and the MTF AUC of the edge spread function from
 the MLEM reconstruction of the Catphan phantom acquired with a
 circular scan at 1.5X magnification, vs. iteration number. Based on
 this result from a typical scanning configuration, we chose to use 200
 iterations of the MLEM algorithm for all reconstructions, using
 approximately 900 projection views for each scan.
**** figs                                    :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/iteration_plots.ipynb")][truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/iteration_plots.ipynb]]
*** Metric Evaluation
    :PROPERTIES:
    :ID:       bbb809be-d901-4945-b045-bb886cf349bd
    :END:
 To evaluate the different magnifications of both the circular and
 virtual isocenter trajectory, we used the sensitometry and spatial
 resolution modules (CTP 404 and CTP 528 respectively) of the Catphan
 phantom. Using metrics that quantify these image qualities, we
 compared the different magnifications of both the circular and virtual
 isocenter scans to the MLEM reconstruction of a standard circular
 scan.
**** Catphan spatial resolution metrics
 There are a number of ways to evaluate the spatial resolution from
 images of the Catphan phantom in a CT image. The CTP528 module
 contains a circular array of bar patterns which we used to,
 subjectively, determine the highest frequency set which is resolvable.
 The same module also has two 0.28mm tungsten carbide beads simulating
 an impulse source from which a point spread and then modulation
 transfer function (MTF) can be determined. Furthermore, the MTF can be
 calculated from the bar patterns themselves
 cite:droege_practical_1982, as well as any suitably high contrast edge
 in the image cite:rossmann_point_1969.

 While the use of MTF in CT has its challenges, notably the assumption
 of shift-invariance is not satisfied, it still can be useful when
 treated with some care. Each of the methods above has some advantages
 and disadvantages. The point source method can provide 3D directional
 estimates of the point-spread function (PSF), however it can also be
 sensitive to the location of the bead relative to the image grid with
 significant difference between a bead located totally within a single
 voxel or on the interface of many.

 The bar pattern based evaluation is a clear complement to the visual
 analysis, however the orientation of the bars relative to the grid
 will affect some frequencies differently than others which can result
 in atypical appearing MTF curves. Using an edge spread analysis on the
 circular phantom boundary provides many samples, at varying directions
 to the image grid which can be averaged out. It can be impacted by
 scatter or saturation in the air region near the phantom boundary,
 however this has not proven to be a significant factor in the images
 we have analyzed.
**** Edge spread calculation method          :noexport:
 The image slice for analysis, the central slice here, is first
 thresholded based on the image intensity, the connected component with
 area of the appropriate size is isolated and any holes in the
 thresholded region are filled. The center of this region is taken as
 the phantom center and used as the origin of the coordinates for
 analysis. The data are then resampled at high density, along radial
 spokes at 8 angles chosen to avoid surface alignment marks, using a
 linear interpolant from 5 mm inside to 5 mm outside the surface
 boundary. The edge-spread function is then the mean $(\mu(X))$
 subtracted profile over the standard deviation $(\sigma(X))$, or
 \begin{equation}
 \text{ESF} = \frac{X-\mu(X)}{\sigma(X)}.
 \end{equation}
 In standard form, the line-spread function (LSF) can be computed from
 the derivate of the edge-spread function (ESF),
 \begin{equation}
 \text{LSF} = \frac{d}{dX}\text{ESF},
 \end{equation}
 and the MTF as the discrete fourier transform $(\mathcal{D})$ of the
 LSF,
 \begin{equation}
 \text{MTF} = \mathcal{D}(\text{LSF})
 \end{equation}
**** Low-contrast resolution
     :PROPERTIES:
     :ID:       c91ac952-b03c-4bc2-b694-28040b955011
     :END:
 To characterize low-contrast resolution, we calculated the
 contrast-to-noise ratio (CNR) using the polystyrene insert in the CTP
 404 sensitometry module. These inserts have CT numbers which are the
 closest to the water-like polymer that surrounds them. The metric is
 defined as
 \begin{equation}
 \label{eq:lcv}
 \text{CNR} = \frac{2\left|\mu_{\text{roi}}-\mu_{\text{bkg}}\right|}{\sigma_\text{roi}+\sigma_\text{bkg}}
 \end{equation}
 where $\sigma$ represents the standard deviation and $\mu$ the mean of the of
 the pixel values in the respective regions.
**** CT-number comparison
     :PROPERTIES:
     :ID:       0494C872-381F-4CA6-BC91-2FAB4CDC0FC0
     :END:
 The last metric we evaluated was the reproducibility of the CT numbers
 between the circular and virtual isocenter scan, and the different
 combinations of magnification bumps. For this we used the mean and
 standard deviations in ROIs for all the material insert the Catphan
 CTP 404 sensitometry module in addition to the polystyrene and
 background ROIs used for the low-contrast CNR calculations. We also
 evaluated three additional ROIs of the water-like background for a
 total of four background ROIs.

 In addition to the catphan modules, we also analyzed ROIs
 corresponding to aorta, liver and spleen in the abdomen of the CIRS
 torso phantom. For each of the magnifications from both the circular
 and virtual isocenter trajectories, the mean HU values and standard
 deviations were calculated.
*** analysis                                 :noexport:
 - [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"161213_virtiso_circ_half_dynmag_catphan_isocal/collision_avoidance.ipynb")][collisions figures]]
 - [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"170126_virtiso_circ_half_dynmag_ed/ed_images.ipynb")][ed analysis]]
** Results
   :PROPERTIES:
   :ID:       28832b04-7d26-4ef8-83f2-08db94493ab9
   :END:
 Figure ([[ref:fig:recons_catphan]]) shows slices of the CTP 528
 spatial-resolution module from the $200^{\text{th}}$ iteration of the
 MLEM reconstructions of the Catphan phantom for the different scanning
 trajectories. The top row shows reconstructions from the circular
 scanning trajectories, and the bottom row shows reconstructions from
 the virtual isocenter trajectories. The left column is from a single
 1.5X magnification, and the remaining columns are different
 synthesized trajectories with different magnifications as illustrated
 in Figure ([[ref:fig:collision_zones]]). In all of these images, the
 $8^{\text{th}}$ largest gauge is visually resolvable.

 #+CAPTION: Images of the Catphan 528 spatial resolution module in a display window of [-100, 2000] HU. The top row shows all the circular scan permutations while the bottom row shows those of the virtual isocenter. The columns show different magnification combinations from left to right of 1.5X only, 1.5X with a 1.6X bump, 1.5X with a 1.7X bump, and a 1.5X with a 1.7X bump and a 1.6X transition on either side. For all of the reconstructions, the 8$^{\text{th}}$ largest gauge is resolvable (indicated by the red arrow).
 #+ATTR_LaTeX: :width \textwidth :float multicolumn
 #+LABEL: fig:recons_catphan
 [[./figures/catphanDynmagQuarter.pdf]]

 The visual similarity in the spatial resolution shown in Figure
 ([[ref:fig:recons_catphan]]) is reflected in the MTF metrics for all of
 the different scanning configurations. We compared MTF metrics derived
 from the PSF using the Catphan beads, the bar pattern shown in Figure
 ([[ref:fig:recons_catphan]]), and the edge-spread function (ESF) measure
 along an ensemble of radial lines. When comparing these MTF-based
 metrics between the circle and the virtual isocenter scans with
 different magnifications, we found no clear trend distinguishing the
 different trajectories.

 #+CAPTION: Plot of low-contrast CNR and error bars corresponding to $\pm$ one standard deviation of the CNR from the Catphan scanned with both the circular and virtual isocenter trajectories.
 #+ATTR_LaTeX: :width \columnwidth
 #+LABEL: fig:catphan_cnr
 [[./figures/catphanCNR_ps.pdf]]

 Figure ([[ref:fig:catphan_cnr]]) shows the low-contrast CNR from the
 Catphan with these different imaging configurations which are also in
 good agreement with each other. In addition to using the material rods
 in the CTP 404 sensitometry module to calculate the CNR, we also
 compared mean values from each of the materials for the different
 scanning trajectories and magnifications. Figure
 ([[ref:fig:catphan_rois]]) shows the ROI means for these different
 scanning configurations. The height of the bar represents the standard
 deviation of the ROI. The first four bars for each material are from
 the circular scans, and the remaining four from the virtual isocenter
 scans.

 #+BEGIN_EXPORT latex
 \begin{figure*}
   \centering
   \begin{subfigure}[b]{\textwidth}
     \includegraphics[width=\textwidth]{figures/sensRoiplot.pdf}
     \caption{}
     \label{fig:catphan_rois}
   \end{subfigure}
   ~%add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
   %(or a blank line to force the subfigure onto a new line)
   \begin{subfigure}[b]{\textwidth}
     \includegraphics[width=\textwidth]{figures/edROIplot.pdf}
     \caption{}
     \label{fig:ed_rois}
   \end{subfigure}
   \caption{ROI material comaprison results for the Catphan CTP 404
     module and the CIRS torso phantom. The height of the bars are $\pm$
     one standard deviation of the ROI mean. The first four bars for
     each material ROI are from the circular scans, and the remaining four
     bars for each material ROI are from the virtual isocenter scans. The
     order of the scans for each material ROI are displayed in the order listed in the
     legend in (a) from left to right.}
   \label{fig:hu_results}
 \end{figure*}
 #+END_EXPORT

 #+CAPTION: Images of the CIRS torso phantom's abdomen in a display window of display window of [-200, 500] HU. The top row shows all the circular scan permutations while the bottom row shows those of the virtual isocenter. The columns show different magnification combinations from left to right of 1.5X only, 1.5X with a 1.6X bump, 1.5X with a 1.7X bump, and a 1.5X with a 1.7X bump and a 1.6X transition on either side.
 #+ATTR_LaTeX: :width \textwidth :float multicolumn :placement
 #+LABEL: fig:recons_ed
 [[./figures/edDynmag.pdf]]

 Figure ([[ref:fig:recons_ed]]) shows an abdominal slice from the
 $200^{\text{th}}$ iteration MLEM reconstruction of the CIRS torso phantom
 scanned with a 13 cm offset half-fan configuration. The layout of
 these images is the same as that in Figure ([[ref:fig:recons_catphan]])
 with the top row showing magnification variations from the circular
 trajectory. The bottom row shows the corresponding magnifications from
 the virtual isocenter trajectory. The slice is the same as that in
 Figure ([[ref:fig:ed_rois]]) which we used to calculate values for three
 organ ROIs.

 For the different organ ROIs, we recorded the means and standard
 deviations for the different scanning trajectories and magnifications.
 Figure ([[ref:fig:ed_rois]]) shows these mean values and the
 associated standard deviations. Though the circular scan variations
 fluctuate more than the virtual isocenter scans, the values are in
 agreement for the different organs of interest. As with Figure
 ([[ref:fig:catphan_rois]]), the first four points for each organ are
 from the circular scan, and the remaining four are from the virtual
 isocenter trajectory.
*** fixed illumination analysis              :noexport:
**** [[file:/ssh:remus:/data/amdavis/truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/figs/][figs]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/catphan_images.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/catphan_images.ipynb]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/metric_analysis.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/metric_analysis.ipynb]]
*** new analysis                             :noexport:
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/catphan_images.ipynb")][161213_virtiso_circ_half_dynmag_catphan_isocal/catphan_images.ipynb]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/metrics.ipynb")][161213_virtiso_circ_half_dynmag_catphan_isocal/metrics.ipynb]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170126_virtiso_circ_half_dynmag_ed/ed_images.ipynb")][170126_virtiso_circ_half_dynmag_ed/ed_images.ipynb]]
*** old analysis                             :noexport:
    :PROPERTIES:
    :var:      iter=75
    :ID:       c2336149-1ac8-4474-ae0a-ed1b97efcdf8
    :END:
**** catphan
     :PROPERTIES:
     :ID:       066a0563-0e56-4ae2-ba5d-66c120f05c92
     :END:
***** contrast
      :PROPERTIES:
      :ID:       12232f76-bd36-4c93-abc4-3d14828dbbc5
      :END:
****** images
       :PROPERTIES:
       :ID:       9694ff06-d9cc-40f0-aaa1-7e5b3f937bf5
       :END:
 #+BEGIN_SRC python :results file
import dicom
import glob
import numpy as np
import matplotlib.pyplot as plt

from IPython.core.debugger import Tracer
debug_here = Tracer()

def crop(center, width, res):
    """Crop image

    Keyword Arguments:
    center -- [x, y] of center
    width  -- deisred width (mm)
    res    -- res (mm/px)
    """
    px_width = np.int(width*0.5/res)

    xbox = [center[0]-px_width, center[0]+px_width]
    ybox = [center[1]-px_width, center[1]+px_width]

    return(xbox, ybox)

# window
window_hu = [-160, 240]         # HU
window_em = [0.015, 0.026]      # mm^1

# itools
catphan_dcm = dicom.read_file(('itools/161213_catphan_circ_1p5x_ringrem/IMG_0043.dcm'))
catphan_hu = catphan_dcm.pixel_array*catphan_dcm.RescaleSlope+catphan_dcm.RescaleIntercept

# crop
width = 230.                 # mm each way

res_hu = 0.473                 # mm/px
center_hu = [np.int(catphan_hu.shape[0]*0.5), np.int(catphan_hu.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

catphan_hu = catphan_hu[winx[0]:winx[1], winy[0]:winy[1]]

plt.imsave('figures/catphan_itools_lcr.png', catphan_hu, vmin=window_hu[0], vmax=window_hu[1])

# recon
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"

files = sorted(glob.glob(dir+"*catphan*itools*{0:04d}*.raw".format(iter)))

catphan_circular = np.fromfile(files[0], 'f').reshape(125, 528, 528).swapaxes(1, 2).T
catphan_virtiso = np.fromfile(files[1], 'f').reshape(125, 528, 528).swapaxes(1, 2).T

catphan_circular = catphan_circular[...,
                                    int(catphan_circular.shape[2]/2)]
catphan_virtiso = catphan_virtiso[...,
                                  int(catphan_virtiso.shape[2]/2)]

# crop
res_hu = 0.473                 # mm/px
center_circular = [np.int(catphan_circular.shape[0]*0.5), np.int(catphan_circular.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

catphan_circular = catphan_circular[winx[0]:winx[1], winy[0]:winy[1]]
catphan_virtiso = catphan_virtiso[winx[0]:winx[1], winy[0]:winy[1]]

plt.imsave('figures/catphan_circular_lcr_mlem_iter_{0:03d}.png'.format(iter), catphan_circular, vmin=window_em[0], vmax=window_em[1])
plt.imsave('figures/catphan_virtiso_lcr_mlem_iter_{0:03d}.png'.format(iter), catphan_virtiso, vmin=window_em[0], vmax=window_em[1])

# return('figures/catphan_itools_lcr.png')
# return('figures/catphan_circular_lcr_mlem.png')
# return('figures/catphan_virtiso_lcr_mlem.png')

fig = plt.figure()
ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

ax1.imshow(catphan_hu, vmin=window_hu[0], vmax=window_hu[1])
ax1.set_title('Circular iTools FDK')
ax1.axis('off')

ax2.imshow(catphan_circular, vmin=window_em[0], vmax=window_em[1])
ax2.set_title('Circular MLEM')
ax2.axis('off')

ax3.imshow(catphan_virtiso, vmin=window_em[0], vmax=window_em[1])
ax3.set_title('Virtual Isocenter MLEM')
ax3.axis('off')

fig.savefig('figures/catphan_comparison_iter_{0:03d}.png'.format(iter), bbox_inches="tight")
return('figures/catphan_comparison_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/catphan_comparison_iter_075.png]]
****** itools analyis
       :PROPERTIES:
       :ID:       bc6df6dd-13e6-4bc5-826c-2002d54ab552
       :END:
  Contrast analysis for catphan

 #+BEGIN_SRC python :results output
import dicom
import numpy as np
import matplotlib.pyplot as plt

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

catphan_dcm = dicom.read_file(('itools/161213_catphan_circ_1p5x_ringrem/IMG_0042.dcm'))
catphan_hu = catphan_dcm.pixel_array*catphan_dcm.RescaleSlope+catphan_dcm.RescaleIntercept

itools_lcr = lcr.CatphanLowContrast(catphan_hu, xres=0.473, x0=121.8/0.473,
                                    y0=121.6/0.473, z=0, rot=-3.48, hu=True)

itools_lcr.save_contrast_calcs('data/', 'catphan_circular_itools')

# itools_lcr.show_rod_locs(vmin=-60, vmax=60)
# plt.savefig('figures/catphan_itools_lcr_locs.png')
# return('figures/catphan_itools_lcr_locs.png')
print(itools_lcr.contrast_1_0)
print(itools_lcr.contrast_0_5)
print(itools_lcr.contrast_0_3)
 #+END_SRC

 #+RESULTS:
 #+begin_example
              % contrast  % contrast sigma       cnr  cnr sigma
rod diameter
15.0            1.273217          1.022240  1.236393   1.414493
9.0             1.157174          1.021059  1.100177   1.415368
8.0             0.767365          1.017061  0.898154   1.437275
7.0             1.198443          1.021447  1.296850   1.420209
6.0             0.486577          1.014224  0.484239   1.414228
5.0             0.860374          1.018018  0.881201   1.415018
4.0             0.763490          1.017019  0.933650   1.452495
3.0             0.356576          1.012901  0.589711   1.701662
2.0             1.844718          1.027938  2.757142   1.586562
              % contrast  % contrast sigma       cnr  cnr sigma
rod diameter
15.0            0.501931          1.033669  0.492042   1.414261
9.0             0.094065          1.029462  0.093504   1.414567
8.0             0.392379          1.032535  0.429770   1.425485
7.0            -0.057559          1.027902  0.061673   1.421552
6.0             0.466486          1.033301  0.477422   1.416169
5.0             0.405244          1.032665  0.482771   1.449648
4.0            -0.082372          1.027647  0.091132   1.427591
3.0            -0.630458          1.022024  0.675272   1.421494
2.0            -0.591860          1.022407  0.984642   1.735271
              % contrast  % contrast sigma       cnr  cnr sigma
rod diameter
15.0            0.162203          0.979250  0.181559   1.420491
9.0            -0.001550          0.977648  0.001615   1.414454
8.0             0.488048          0.982444  0.519364   1.415367
7.0             0.614937          0.983694  0.624087   1.414256
6.0             0.189741          0.979519  0.207107   1.417398
5.0             1.030511          0.987745  1.524829   1.548857
4.0             0.985444          0.987344  1.008152   1.414214
3.0             0.322520          0.980822  0.318188   1.415103
2.0            -0.096169          0.976723  0.107345   1.420092
 #+end_example
****** recon em analysis
       :PROPERTIES:
       :ID:       73598a41-2659-4be4-8473-9086ba73c896
       :END:
 Results from my reconstructions

 #+BEGIN_SRC python :results output
import glob
import numpy as np
import matplotlib.pyplot as plt

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

# get files we have
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"
files = sorted(glob.glob(dir+"*catphan*itools*{0:04d}*.raw".format(iter)))

catphan_circular = np.fromfile(files[0], 'f').reshape(125, 528, 528).swapaxes(1, 2).T
catphan_virtiso = np.fromfile(files[1], 'f').reshape(125, 528, 528).swapaxes(1, 2).T

catphan_circular = catphan_circular[...,
                                    int(catphan_circular.shape[2]/2)]
catphan_virtiso = catphan_virtiso[...,
                                  int(catphan_virtiso.shape[2]/2)]

circular_lcr = lcr.CatphanLowContrast(catphan_circular, xres=0.473,
                                      x0=263.5, y0=261.5, z=0, rot=-3.,
                                      hu=False)

virtiso_lcr = lcr.CatphanLowContrast(catphan_virtiso, xres=0.473,
                                     x0=272, y0=259.5, z=0, rot=-3.,
                                     hu=False)

circular_lcr.save_contrast_calcs('data/', 'catphan_circular_mlem_iter_{0:03d}'.format(iter))
virtiso_lcr.save_contrast_calcs('data/', 'catphan_virtiso_mlem_iter_{0:03d}'.format(iter))

# circ_fig = circular_lcr.show_rod_locs(vmin=0.02, vmax=0.021)
# virt_fig = virtiso_lcr.show_rod_locs(vmin=0.019, vmax=0.021)

# circ_fig.savefig('figures/catphan_circular_mlem_lcr_locs.png')
# virt_fig.savefig('figures/catphan_virtiso_mlem_lcr_locs.png')
# return('figures/catphan_circular_mlem_lcr_locs.png')
# return('figures/virtiso_circular_mlem_lcr_locs.png')

print("\n0.3% circular")
print(circular_lcr.contrast_0_3)
print("\n0.3% virtiso")
print(virtiso_lcr.contrast_0_3)

print("\n0.5% circular")
print(circular_lcr.contrast_0_5)
print("\n0.5% virtiso")
print(virtiso_lcr.contrast_0_5)

print("\n1.0% circular")
print(circular_lcr.contrast_1_0)
print("\n1.0% virtiso")
print(virtiso_lcr.contrast_1_0)
 #+END_SRC

 #+RESULTS:
 #+begin_example

0.3% circular
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.336178          0.632722  0.757847   1.423412
9.0     0.292402          0.669551  0.619270   1.415762
8.0     0.131968          0.623152  0.302362   1.426568
7.0     0.431134          0.613007  1.009752   1.431675
6.0     0.290603          0.656327  0.628716   1.417611
5.0     0.422215          0.665411  0.900781   1.416314
4.0     0.155166          0.543975  0.431161   1.509609
3.0    -0.297085          0.688549  0.609311   1.414347
2.0     0.472236          0.741477  0.903903   1.416268

0.3% virtiso
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.382718          0.830310  0.658319   1.424841
9.0     0.092026          0.799518  0.165280   1.435069
8.0    -0.107992          0.868174  0.176177   1.417189
7.0    -0.103785          0.786340  0.190046   1.440932
6.0    -0.309173          0.774152  0.576760   1.447345
5.0    -0.309976          0.759113  0.594024   1.458054
4.0    -0.223083          1.130837  0.282885   1.435041
3.0    -0.471983          0.698019  1.039611   1.543806
2.0    -1.038081          0.691397  2.308892   1.551891

0.5% circular
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.335700          0.647368  0.735412   1.415590
9.0     0.015566          0.591873  0.037623   1.430468
8.0     0.560906          0.624661  1.278832   1.419516
7.0     0.200324          0.689673  0.411264   1.414540
6.0    -0.258247          0.630936  0.579385   1.417608
5.0     0.550274          0.624253  1.255414   1.419604
4.0     0.465531          0.577228  1.165342   1.440343
3.0     0.078896          0.601583  0.187137   1.426210
2.0    -0.371316          0.476344  1.444140   1.859480

0.5% virtiso
      % contrast  % contrast sigma       cnr  cnr sigma
15.0   -0.323800          0.992989  0.467154   1.435720
9.0    -0.265211          0.949907  0.405867   1.456524
8.0     0.103588          0.939622  0.161663   1.465258
7.0     0.500131          0.977952  0.741149   1.444188
6.0     0.876336          0.922225  1.421072   1.485184
5.0     0.751536          0.897809  1.275159   1.513860
4.0     0.118879          0.984507  0.174040   1.440150
3.0     1.058663          1.008137  1.516077   1.433655
2.0     0.703962          0.820208  1.728628   2.000000

1.0% circular
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.891881          0.658649  1.933036   1.420049
9.0     0.723097          0.732432  1.401420   1.414637
8.0     0.697721          0.628473  1.594919   1.430160
7.0     0.958346          0.679275  2.008902   1.416360
6.0     0.700465          0.639470  1.568403   1.425579
5.0     0.878039          0.685795  1.821070   1.415579
4.0     0.613320          0.672501  1.296906   1.417139
3.0     0.315199          0.567085  0.827869   1.485735
2.0     0.664848          0.506692  2.641720   2.000000

1.0% virtiso
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    1.216002          0.926873  1.869765   1.415754
9.0     0.418370          0.884876  0.673363   1.420661
8.0     1.236294          0.892132  1.982379   1.420123
7.0     0.963466          0.803941  1.755233   1.454411
6.0     1.147464          0.792635  2.137994   1.464240
5.0     0.164518          0.983530  0.236795   1.414503
4.0    -0.124803          0.796152  0.227947   1.455467
3.0    -0.180899          0.874025  0.294034   1.422201
2.0    -1.164900          0.681244  2.957545   1.749484
 #+end_example
****** plots
       :PROPERTIES:
       :ID:       229ce930-658c-447c-9cbc-d1958f97022b
       :END:
******* CNR
        :PROPERTIES:
        :ID:       184b9d1e-9b95-4aa3-a7f9-127053b3246e
        :END:
 #+BEGIN_SRC python :results file
import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas
import seaborn as sns

sns.set(font='serif', font_scale=0.8)

from itertools import cycle
lines = ["-","--","-."]
linecycler = cycle(lines)

from matplotlib.ticker import FormatStrFormatter

# setup plot params
sns.set_context("paper")

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

# load previous calculations
circ_fdk = sorted(glob.glob("data/*itools*rods.pkl"))
circ_em = sorted(glob.glob("data/*circular_mlem*_iter_{0:03d}*rods.pkl".format(iter)))
virt_em = sorted(glob.glob("data/*virtiso*_iter_{0:03d}*rods.pkl".format(iter)))

# load 0.3%, 0.5%, 1.0% rod contrast
circ_fdk = [pandas.read_pickle(f) for f in circ_fdk]
circ_em = [pandas.read_pickle(f) for f in circ_em]
virt_em = [pandas.read_pickle(f) for f in virt_em]

# data sets
titles = ['0.3% contrast rods', '0.5% contrast rods', '1.0% contrast rods']

fig, axs = plt.subplots(3, 1, True)

for j, ax in enumerate(axs):
    ax.errorbar(circ_fdk[j].index, 'cnr', yerr='cnr sigma', data=circ_fdk[j], label='FDK Circular', ls=next(linecycler))
    ax.errorbar(circ_em[j].index, 'cnr', yerr='cnr sigma', data=circ_em[j], label='MLEM Circular', ls=next(linecycler))
    ax.errorbar(virt_em[j].index, 'cnr', yerr='cnr sigma', data=virt_em[j], label='MLEM Virtual Isocenter', ls=next(linecycler))

    ax.set_xlim([1, 16])
    # ax.set_ylim([-3, 3])
    ax.set_ylabel('CNR')
    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))
    ax.set_title(titles[j])

ax.legend(loc='best', fancybox=True, framealpha=0.5)
ax.set_xlabel('Rod diameter [mm]')

fig.savefig('figures/cnr_iter_{0:03d}.pdf'.format(iter))

fig.savefig('figures/cnr_iter_{0:03d}.png'.format(iter))
return('figures/cnr_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/cnr_iter_075.png]]

******* % contrast
        :PROPERTIES:
        :ID:       03ee4467-a1d4-4d7e-8c12-b8e767bf43a3
        :END:
 #+BEGIN_SRC python :results file
import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas
import seaborn as sns

sns.set(font='serif', font_scale=0.8)

from itertools import cycle
lines = ["-","--","-."]
linecycler = cycle(lines)

from matplotlib.ticker import FormatStrFormatter

# setup plot params
sns.set_context("paper")

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

# load previous calculations
circ_fdk = sorted(glob.glob("data/*itools*rods.pkl"))
circ_em = sorted(glob.glob("data/*circular_mlem*_iter_{0:03d}*rods.pkl".format(iter)))
virt_em = sorted(glob.glob("data/*virtiso*_iter_{0:03d}*rods.pkl".format(iter)))

# load 0.3%, 0.5%, 1.0% rod contrast
circ_fdk = [pandas.read_pickle(f) for f in circ_fdk]
circ_em = [pandas.read_pickle(f) for f in circ_em]
virt_em = [pandas.read_pickle(f) for f in virt_em]

# data sets
titles = ['0.3% contrast rods', '0.5% contrast rods', '1.0% contrast rods']

fig, axs = plt.subplots(3, 1, True)

for j, ax in enumerate(axs):
    ax.errorbar(circ_fdk[j].index, '% contrast', yerr='% contrast sigma', data=circ_fdk[j], label='FDK Circular', ls=next(linecycler))
    ax.errorbar(circ_em[j].index, '% contrast', yerr='% contrast sigma', data=circ_em[j], label='MLEM Circular', ls=next(linecycler))
    ax.errorbar(virt_em[j].index, '% contrast', yerr='% contrast sigma', data=virt_em[j], label='MLEM Virtual Isocenter', ls=next(linecycler))

    ax.set_xlim([1, 16])
    ax.set_ylim([-3, 3])
    ax.set_ylabel('% contrast')
    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))
    ax.set_title(titles[j])

ax.legend(loc='best', fancybox=True, framealpha=0.5)
ax.set_xlabel('Rod diameter [mm]')

fig.savefig('figures/percent_contrast_iter_{0:03d}.pdf'.format(iter))

fig.savefig('figures/percent_contrast_iter_{0:03d}.png'.format(iter))
return('figures/percent_contrast_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/percent_contrast_iter_075.png]]

***** spatial res
      :PROPERTIES:
      :ID:       b755dc97-c01c-461c-99d3-7f116bfc4f5f
      :END:
****** images
       :PROPERTIES:
       :ID:       1a7be01c-fc76-42bf-a09d-7e7556456fd8
       :END:
  #+BEGIN_SRC python :results file
import dicom
import glob
import numpy as np
import matplotlib.pyplot as plt

from IPython.core.debugger import Tracer
debug_here = Tracer()


def crop(center, width, res):
    """Crop image

    Keyword Arguments:
    center -- [x, y] of center
    width  -- deisred width (mm)
    res    -- res (mm/px)
    """
    px_width = np.int(width*0.5/res)

    xbox = [center[0]-px_width, center[0]+px_width]
    ybox = [center[1]-px_width, center[1]+px_width]

    return(xbox, ybox)

# window
window_hu = [150, 1000]         # HU
window_em = [0.022, 0.032]      # mm^1

# itools
catphan_dcm = dicom.read_file(('itools/150902_catphan_full_low_contrast/hu/IMG_0075.dcm'))
catphan_hu = catphan_dcm.pixel_array*catphan_dcm.RescaleSlope+catphan_dcm.RescaleIntercept

# crop
width = 130.                 # mm each way

res_hu = 0.473                 # mm/px
center_hu = [np.int(catphan_hu.shape[0]*0.5), np.int(catphan_hu.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

catphan_hu = catphan_hu[winx[0]:center_hu[0], winy[0]:winy[1]]

plt.imsave('figures/catphan_itools_sr.png', catphan_hu, vmin=window_hu[0], vmax=window_hu[1])

# recon
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"
files = sorted(glob.glob(dir+"*catphan*itools*{0:04d}*.raw".format(iter)))

catphan_circular = np.fromfile(files[0], 'f').reshape(125, 528, 528).swapaxes(1, 2).T
catphan_virtiso = np.fromfile(files[1], 'f').reshape(125, 528, 528).swapaxes(1, 2).T

sr_slice = 93
catphan_circular = catphan_circular[..., sr_slice]
catphan_virtiso = catphan_virtiso[..., sr_slice]

# crop
res_em = 0.5                 # mm/px
center_circular = [np.int(catphan_circular.shape[0]*0.5), np.int(catphan_circular.shape[1]*0.5)]

winx, winy = crop(center_circular, width, res_em)

catphan_circular = catphan_circular[winx[0]:center_circular[0], winy[0]:winy[1]]
catphan_virtiso = catphan_virtiso[winx[0]:center_circular[0], winy[0]:winy[1]]

plt.imsave('figures/catphan_circular_sr_mlem_iter_{0:03d}.png'.format(iter), catphan_circular, vmin=window_em[0], vmax=window_em[1])
plt.imsave('figures/catphan_virtiso_sr_mlem_iter_{0:03d}.png'.format(iter), catphan_virtiso, vmin=window_em[0], vmax=window_em[1])

# return('figures/catphan_itools_sr.png')
# return('figures/catphan_circular_sr_mlem.png')
# return('figures/catphan_virtiso_sr_mlem.png')

fig = plt.figure()
ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

ax1.imshow(catphan_hu, vmin=window_hu[0], vmax=window_hu[1])
ax1.set_title('Circular iTools FDK')
ax1.axis('off')

ax2.imshow(catphan_circular, vmin=window_em[0], vmax=window_em[1])
ax2.set_title('Circular MLEM')
ax2.axis('off')

ax3.imshow(catphan_virtiso, vmin=window_em[0], vmax=window_em[1])
ax3.set_title('Virtual Isocenter MLEM')
ax3.axis('off')

fig.savefig('figures/catphan_comparison_sr_iter_{0:03d}.png'.format(iter), bbox_inches="tight")
return('figures/catphan_comparison_sr_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/catphan_comparison_sr_iter_075.png]]
**** ed
     :PROPERTIES:
     :ID:       fc37283b-966f-4f98-8693-4c885b4c516d
     :END:
  Generate slices for Ed
  #+BEGIN_SRC python :results file
import glob
import numpy as np
import matplotlib.pyplot as plt
import dicom
# import pickle

# window
window_hu = [-200, 240]         # HU
window_em = [0.015, 0.025]      # mm^1

from IPython.core.debugger import Tracer
debug_here = Tracer()


def crop(center, width, res):
    """Crop image

    Keyword Arguments:
    center -- [x, y] of center
    width  -- deisred width (mm)
    res    -- res (mm/px)
    """
    px_width = np.int(width*0.5/res)

    xbox = [center[0]-px_width, center[0]+px_width]
    ybox = [center[1]-px_width, center[1]+px_width]

    return(xbox, ybox)

# itools
ed_dcm = dicom.read_file(('itools/150902_ed_circular_half_13cm_offset/hu/IMG_0042.dcm'))
ed_hu = ed_dcm.pixel_array*ed_dcm.RescaleSlope+ed_dcm.RescaleIntercept

# crop
width = 300.                 # mm each way

res_hu = 0.836                 # mm/px
center_hu = [np.int(ed_hu.shape[0]*0.5), np.int(ed_hu.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

ed_hu = ed_hu[winx[0]:winx[1], winy[0]:winy[1]]

# recon
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"
files = sorted(glob.glob(dir+"*ed*itools*{0:04d}*.raw".format(iter)))

ed_circular = np.fromfile(files[0], 'f').reshape(126, 418, 418).swapaxes(1, 2).T
ed_virtiso = np.fromfile(files[1], 'f').reshape(126, 418, 418).swapaxes(1, 2).T

ed_circular = ed_circular[..., int(ed_circular.shape[2]/2+1)]
ed_virtiso = ed_virtiso[..., int(ed_virtiso.shape[2]/2+1)]

# crop
res_em = 0.836                    # mm/px
center_em = [int(ed_circular.shape[0]*0.5), int(ed_circular.shape[1]*0.5)]

winx, winy = crop(center_em, width, res_em)

ed_circular = ed_circular[winx[0]:winx[1], winy[0]:winy[1]]
ed_virtiso = ed_virtiso[winx[0]:winx[1], winy[0]:winy[1]]

# save img slice
plt.imsave('figures/ed_itools_fdk.png', ed_hu, vmin=window_hu[0], vmax=window_hu[1])
plt.imsave('figures/ed_circular_mlem_iter_{0:03d}.png'.format(iter), ed_circular, vmin=window_em[0], vmax=window_em[1])
plt.imsave('figures/ed_virtiso_mlem_iter_{0:03d}.png'.format(iter), ed_virtiso, vmin=window_em[0], vmax=window_em[1])

# return('figures/ed_itools_fdk.png')
# return('figures/catphan_circular_lcr_mlem.png')
# return('figures/catphan_virtiso_lcr_mlem.png')

# display all three
fig = plt.figure()
ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

ax1.imshow(ed_hu, vmin=window_hu[0], vmax=window_hu[1])
ax1.set_title('Circular iTools FDK')
ax1.axis('off')

ax2.imshow(ed_circular, vmin=window_em[0], vmax=window_em[1])
ax2.set_title('Circular MLEM')
ax2.axis('off')

ax3.imshow(ed_virtiso, vmin=window_em[0], vmax=window_em[1])
ax3.set_title('Virtual Isocenter MLEM')
ax3.axis('off')

fig.savefig('figures/ed_comparison_iter_{0:03d}.png'.format(iter), bbox_inches="tight")
return('figures/ed_comparison_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/ed_comparison_iter_075.png]]

** Discussion
   :PROPERTIES:
   :ID:       5d03aa38-f620-4ad1-a60d-f02d5000ea97
   :END:
 As mentioned earlier, the virtual isocenter trajectory is designed to
 increase the distance between the gantry head and the patient by
 synchronized table translation and gantry motion. The geometry of the
 imaging arms remains unchanged, though the center of the image space
 is moved from the mechanical isocenter to the virtual isocenter. As
 shown in the previous section, this results in CBCT image quality that
 is comparable to a normal circular scan.

 It is certainly possible to envision situations in which collisions
 with the kV imaging source or (more likely) the detector also occur.
 The system matrix in our optimization-based reconstruction method can
 incorporate changes in the position of the imaging arms as well as the
 patient position. Thus a trajectory with variable source-detector
 distance, caused by the detector moving to avoid a patient collision,
 can also be reconstructed. Such a variable magnification scan may be
 performed with the patient couch moving in a virtual isocenter
 trajectory, or with the patient couch fixed and rotation about the
 physical machine isocenter.

 All virtual isocenter scanning in the present work was done in
 TrueBeam Developer Mode, which is a strictly nonclinical mode of
 operation. Simultaneous motion of couch, gantry and imaging arms is
 not fully supported by the TrueBeam; however, the motions required for
 the virtual isocenter scan, which involve only coupled gantry rotation
 and couch translation, are feasible in Developer Mode. Although the
 linac can clearly execute the required motions and acquire the images,
 virtual isocenter scanning is as yet not available as a clinical
 capability. In addition, these scans must be reconstructed using
 iterative optimization-based methods, rather than the current
 clinically available filtered back-projection method. A historic
 concern about optimization-based methods has been reconstruction
 speed. These are very computationally intensive programs, but with the
 recent availability of GPU-based processing, reconstruction times are
 more manageable.

** Conclusion
   :PROPERTIES:
   :ID:       016dd868-817a-44fc-8717-e64fdc5bc0d3
   :END:
 Virtual isocenter trajectories and dynamic magnification are
 potentially useful as collision-avoiding alternatives to standard
 isocentric rotation, both in cases where arc treatments are being
 delivered and in cases where CBCT scanning is desirable, but a normal
 isocentric scan would cause gantry-patient collisions. Using
 optimization-based reconstruction methods, patient-specific, collision
 avoiding imaging trajectories that utilize virtual isocenter CBCT
 scans and different kV-detector magnifications can be reconstructed by
 incorporating the view-by-view imaging and patient geometry into the
 system matrix. Image quality, as characterized by spatial resolution
 and low contrast object detectability, is comparable for virtual
 isocenter scans and for standard isocentric scans using different
 magnification bumps to avoid kV-detector collisions. Thus, virtual
 isocenter CBCT scans and kV-detector magnification changes could be
 combined with optimization-based reconstruction as a useful clinical
 approach in collision-plagued situations.
* Summary and conclusions                    :conc:
  :PROPERTIES:
  :ID:       1bade25b-80d6-4650-b8a3-baf370fa657c
  :END:

\makebibliography
