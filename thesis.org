#+TITLE:
#+DATE:
#+AUTHOR:
#+EMAIL:
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t c:nil creator:nil d:(not "LOGBOOK") date:nil e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t
#+OPTIONS: tags:nil tasks:t tex:t timestamp:t title:t toc:nil todo:t |:t
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+LaTeX_HEADER: \usepackage[encapsulated]{CJK}
#+LaTeX_HEADER: \usepackage{ucs}
#+LaTeX_HEADER: \usepackage[utf8x]{inputenc}
#+LATEX_CLASS:thesis
#+STARTUP: hideblocks
# +STARTUP: latexpreview

#+BEGIN_EXPORT latex
%% Use these commands to set biographic information for the title page:
\title{Enabling Novel IGRT Imaging Trajectories with Optimization-Based Reconstruction Algorithms}
\author{Andrew Davis}
\department{Committee on Medical Physics}
\division{Biological Sciences}
\degree{Ph. D.}
\date{December, 2017}

%% Use these commands to set a dedication and epigraph text
% use one of bsmi(trad Chinese), gbsn(simp Chinese), min(Japanese), mj(Korean); see:
% /usr/share/texmf-dist/tex/latex/cjk/texinput/UTF8/*.fd
\newcommand{\jntext}[1]{\begin{CJK}{UTF8}{min}#1 \end{CJK}}

\dedication{To all who have been directly or indirectly afflicted by
  cancer -- especially my Dad}

\epigraph{
  \raggedright{\it
  The Art of Peace is medicine for a sick world. We want to
  cure the world of the sickness of violence, malcontent, and
  discord—this is the Way of Harmony. There is evil and disorder in
  the world because people have forgotten that all things emanate from
  one source. Return to that source and leave behind all self-centered
  thoughts, petty desires, and anger. Those who are possessed by
  nothing possess everything.
}

  \raggedleft{\jntext{お先生} (Ueshiba Morihei Sensei)}
}

% If you don't want a title page comment out the next line and uncomment the line after it:
\maketitle
%\omittitle

% These lines can be commented out to disable the copyright/dedication/epigraph pages
\makecopyright
\makededication
\makeepigraph

%% Make the various tables of contents
\tableofcontents
\listoffigures
\listoftables

\acknowledgments
I would first like to express my deepest gratitude to the guidance provided by Drs. Charles Pelizzari and Xiaochuan Pan. Working with these exemplarly scientists in their labs has been one of the most rewarding experiences in my life. Their curioisty and dedication to the scietific method as well as their dedication to their students has given me a clear picture of the archetypical scientist and mentor. I am indebted to these two men for their efforts in guiding my scientific training.

I also would like to thank my committee members Drs. Hania Al-Hallaq and Emil Sidky for their stimulating feedback, discussions, and additional guidance in my research. Like Drs. Pan and Pelizzari, they have been extremely supportive of my research endeavors and instrumental in helping me devekop as a scientist. From the intial coursework at the start of my graduate education to the research presented in this work, my committee and adviers have provided me with a high standard of what it means to be a scientist through their example.

Furthermore, I would like to thanks my fellow friends and lab mates Sean Rose and Drs. Buxin Chen, Zheng Zhang, Adrian S\'anchez, Xiao Han, Junguo Bian, Dan Xia, and Erik Pearson. Together, they have provided vast amounts of help, feedback, support, and friendship during my graduate work. I would also like to thank my classmate Dr. Meredith Sadinski as well as fellow students Drs. Dave Rigie, Johnathan Rosenfield, Gage Redler, Alex Cunliffe, Kevin Little, Zachary Grelewic, and Zacariah Labby who also provided engaging discussion and feedback throughout my studies. I also would like to extend my gratitude to the rest of the students in the Committee of Medical Physics for providing a wonderful learning environment.

This work was made possible by in part by the Lawrence H. Lanzl Fellowship and NIH Grants R01 CA182264, R01EB018102, S10 RR021039 and P30 CA14599. Additional funding was provided by Varian Medial Systems with particular gratitude to Dr. Timo Berkhus for stimulating conversation and feedback as well as Pascal Paysan and Dieter Seghers for providing and assisting with the iTools Reconstruction software. The contents of this work are solely the responsibility of the author and do not necessarily represent the official view of any of the supporting organizations.

\abstract
% Enter Abstract here 350 word max
The use of cone-beam computed tomography (CBCT) in image-guided
radiation therapy (IGRT) has helped linear accelerators (LINACs)
become the most popular form of radiation therapy today. The ability
to acquire tomographic information from the patient at the treatment
position allows for setup and target verification as well as steeper
dose gradients and higher dose fractions while simultaneously
providing images that allow the oncologist to monitor the tumor's
response to the therapy. The current kV-CBCT scanning configuration of
this LINAC-mounted imaging system provides a circular trajectory of
the source and detector around the patient as the LINAC gantry makes a
single rotation around the patient. Though this provides the requisite
trajectory for the analytic-base FDK reconstruction algorithm that is
the workhorse of clinical reconstruction in IGRT today, there are some
issues of this scanning geometry that can either limit or even prevent
the use of this CBCT information in clinical practice. In this work,
we develop a generalized non-circular scanning trajectory framework
enabled by optimization-based reconstruction that allow for
non-circular trajectories that directly address two issues of
LINAC-mounted CBCT for IGRT. The first issue is overcoming the limited
axial coverage provided by the current detector size and circular
acquisition trajectory. This is problematic as the CBCT axial coverage
is smaller than the potential treatment field size. As engineering
costs restrict the axial coverage of the detector, we investigate
potential non-circular trajectories that can extend the axial coverage
with current LINAC-mounted CBCT detectors. The other existing
limitation that could be resolved with non-circular scanning
trajectories is that of potential patient collisions with the LINAC
gantry. As some patient treatment positions can put the patient in a
collision path with components of the LINAC gantry, the inability to
acquire the full circular rotation can lead to forgoing the CBCT. This
is another problem to which we provide example trajectories that could
alleviate these collisions while still acquiring useful CBCT images.
We found that in both of these examples, our non-circular imaging
framework was able to reconstruct images that have comparable image
quality to the current clinical method using a single circular scan
while simultaneously providing potential solutions to the current
clinical limitation of restricted axial coverage and potential patient
collisions with the LINAC gantry.

\mainmatter
% Main body of text follows
#+END_EXPORT

* notes                                      :noexport:
  :PROPERTIES:
  :ID:       7f3d97de-795e-402a-82ac-591717f86bfd
  :END:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
** requirements
   :PROPERTIES:
   :ID:       931c9c50-bfaf-4c8e-b2cc-bcfdf62e327d
   :END:
- [[http://www.lib.uchicago.edu/e/phd/][uchicago]] dissertation guide
- [[https://github.com/zuwiki/ucetd-latex][uoc thesis]] template
* Introduction                               :intro:
  :PROPERTIES:
  :ID:       852796c3-9a3b-49da-bc08-1299e93e0768
  :END:
Tomography is the imaging technique of using a penetrating wave to
create an image of a slice in an object while either blurring or
obscuring details from other planes in the object. The ability to peer
inside an object and create a map of its contents is a powerful tool
that is routinely used in myriad applications. Today, tomographic
methods have been deployed in locations ranging from border-control
checkpoints to local medical clinics.

As the non-invasive nature of tomographic imaging had obvious benefits
for the field of medicine, many significant advances in tomographic
technology were driven by clinical research. One such form of
tomographic imaging is x-ray computed tomography (CT) which uses
projection images acquired from different locations around the object
to compute the distribution of material densities inside the object.
With the growth of tomographic imaging, additional technologies were
developed to acquire images using a variety of waves from ultrasound to
injecting radioactive tracers which emit these waves from inside a
patient as in single-photon computed tomography (SPECT) and positron
emission tomography (PET).

** CT development history
   :PROPERTIES:
   :ID:       1b7b31c8-4bd5-4402-b930-d81984ee5901
   :END:
In a CT scanner system, an x-ray source and opposing detector
typically rotate in a circle relative to the object being imaged as
x-ray projection images are acquired at different angular positions.
By modeling the attenuation of the incident x-rays by the object being
imaged at different projection angles and finding an approximate
inversion of this model, an estimate of the object's interior could be
produced. The development of modern CT imaging systems today was
driven not only by innovation in the hardware design, but also by
advances in the algorithms used to invert the poorly conditioned
forward model encountered in CT imaging.

Figure ([[ref:fig:intro_hist_1st_gen]]) shows a schematic of the first
generation of CT scanner, which was built by EMI (/Electric and
Musical Industries Ltd./) in 1967 using the work of Allan M. Cormack
and Godfrey N. Hounsfield cite:buzug_thorston_m._milestones_2008. In
this design, a source and detector acquire a series of pencil-beam
projections by translating together along a line in a plane orthogonal
to the rotation axis. The source and detector then rotate before
acquiring another series of projections along another line. This
process is repeated for successive rotation angles until the system
has rotated an entire $180^{{\circ}}$ and the source and detector have
moved to each other's starting position. For their work, Cormack and
Housfield shared the 1979 Nobel Prize in Physiology or Medicine
cite:hsieh_computed_2009.

#+CAPTION: First-generation CT scanner. At each angle, the source and detector move together in a line to acquire a series of pencil beam projections at that angle. The source and detector then rotate one degree around the object before repeating this process.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:intro_hist_1st_gen
[[file:figures/intro/1st_gen_ct.png]]

The algorithms for reconstructing the tomographic image from these
x-ray projections at different angles evolved concurrently with the
different iterations of CT-scanner hardware. The projection data
acquired from the first-generation scanner was necessarily digitized
as the reconstructed image was computed by solving a linear system of
equations, now known as algebraic reconstruction technique (ART)
cite:hsieh_computed_2009. Though Radon's theories that provide the
basis for some of the analytic-based reconstruction algorithms were
known at the time, the necessary computer hardware needed for a
practical implementation had yet to be developed when Cormack and
Hounsfield reconstructed their first CT image
cite:buzug_thorston_m._milestones_2008.

Though the first-generation CT system was a groundbreaking
achievement, the rasterized scanning of the pencil beam at multiple
angles required approximately 4.5 minutes to acquire the projection
information to reconstruct a single two-dimensional (2D) slice of the
scanned object cite:hsieh_computed_2009. Long scan times are
problematic as they increase the possibility of motion during scanning
which creates motion contamination artifacts in the reconstruction.
The second generation of CT scanners significantly reduced this
acquisition time to about 30 seconds by replacing the pencil beam of
x-rays with a fan beam and a detector array with approximately 30
detector elements. This new design, shown in Figure
([[ref:fig:intro_hist_2nd_gen]]), still required the source and detector
to acquire projections using a linear translation before rotating to a
new angular position and repeating the process
cite:buzug_thorston_m._milestones_2008.

#+CAPTION: Second-generation CT scanner. Though similar to the first-generation scanner in Figure ([[ref:fig:intro_hist_1st_gen]]), a significant reduction in acquisition time was achieved by replacing the pencil beam and single detector with a fan beam and an array of detector elements. The acquistion method remained the same in that the source and detector first acquired multiple projections via a linear translation before rotating to a new angular position and repeating the translation.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:intro_hist_2nd_gen
[[file:figures/intro/2nd_gen_ct.png]]

One of the most important factors driving the hardware development in
CT-scanner technology was the issue of acquisition speed. As the
reconstruction framework used a forward model that assumes the
projections are acquired from a stationary object, the first two
generations were only successful in imaging parts of the patient that
were relatively stationary. As such, these early scanners were
initially only used with the cranium as it is relatively motionless
relative to the required acquisition time. Unlike the cranium, other
anatomical sites such as the thorax and abdomen are greatly affected
by cardiac and respiratory motion. The next generation of scanners
were designed to reduce the acquisition time to under 20 seconds in
order to image a patient's abdomen in a single breath hold
cite:buzug_thorston_m._milestones_2008.

#+CAPTION: Third-generation CT scanner. This design kept the fan-beam x-ray source seen in the second generation of scanners, but the detector size was increased to illuminate the entire patient. This new design no longer required the source and detector to acquire a linear translation before rotating to a new scanning angle. Instead, this generation of scanners simply acquire a single projection at each angle which significantly reduces the acquisition time.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:intro_hist_3rd_gen
[[file:figures/intro/3rd_gen_ct.png]]

The third generation of CT scanners, shown in Figure
([[ref:fig:intro_hist_3rd_gen]]), would soon become the dominant scanner
design. This remains true today as most modern diagnostic CT imaging
systems, such as the one shown in Figure ([[ref:fig:intro_ct_scan]]), are
still based on the third generation design. Unlike the earlier
generations of scanners, this design removed the need for the linear
translation of the source and detector by increasing the size of the
detector so that the entire patient could be illuminated at a given
angle. By doing this, it was only necessary to acquire a single
projection at each rotation angle which significantly reduced the
acquisition time cite:hsieh_computed_2009.

The evolution from the first generation of scanners to the second and
third generations of scanners was enabled by advances in both computer
hardware and reconstruction algorithms for solving the inverse
problem. As we will further discuss in the following chapter,
analytic-based algorithms for solving the CT inverse problem gradually
replaced the initial algebraic solution to the linearized forward
model used by Cormack and Hounsfield. The most popular form of this
implementation is known as filtered-backprojection (FBP)
cite:buzug_thorston_m._two-dimensional_2008,hsieh_computed_2009.

The FBP approach to CT reconstruction was first implemented as the
parallel-beam backprojection algorithm
cite:buzug_thorston_m._two-dimensional_2008. This provided an analytic
inverse to the acquisition method of the first generation of scanners
where at a given angle, all of the projections are acquired as
parallel incident x-ray beams. However, with the second and third
generation of CT scanners, this imaging model was modified from the
parallel-beam geometry to the fan-beam geometry to account for the
divergent x-ray beam of a point-like x-ray source on an array of x-ray
detectors. The new fan-beam FBP algorithm enabled the scanning
geometry of the third generation of scanners which are still the
backbone of clinical CT today cite:pan_why_2009.

#+CAPTION: Modern Brilliance CT Big Bore scanner (Philips, Amsterdam, NL) which is a third generation multislice scanner with 16 detector rows. The unusually large bore (85 cm diameter) is specifically designed for radiation therapy simulation planning in order to avoid collisions.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:intro_ct_scan
[[file:figures/intro/philips_brilliance_bigbore.jpg]]

The fourth generation of CT scanners was developed to eliminate ring
artifacts that can appear in the third-generation CT scanners. These
ring artifacts can occur when there is a mismatch in projection data
of opposing rays along the same line in the patient which can result
from misalignment of the moving detector. With a stationary ring of
detectors, these ring artifacts are eliminated. However, with the
advent of multi-slice detector technology which will be discussed in
[[id:f84fb81e-a07d-4945-9653-fd1544703733][Cone-beam CT and new scanning trajectories]], the engineering and cost
requirements has led to fourth-generation scanners being phased out
cite:hsieh_computed_2009.

#+CAPTION: Fourth-generation CT scanner. In this design, only the x-ray source rotates inside a ring of fixed detector elements.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:intro_hist_4th_gen
[[file:figures/intro/4th_gen_ct.png]]

The fifth generation of CT scanners, also known as electron-beam,
computed-tomography (EBCT) scanners, was developed in the early 1980s
for cardiac imaging. In order to acquire the projection data fast
enough to ''freeze'' cardiac motion (20-50 ms for a full rotation), it
would be impossible to design a mechanical system that could rotate
that quickly and withstand the centripetal force incurred at such high
rotational velocity. Instead, this generation was designed to steer
the electron beam onto the x-ray anode that was curved around the
patient -- effectively placing the patient inside the x-ray tube. The
design is similar to the fourth generation in that the EBCT scanners
have a fixed, partial-ring detector around the patient
cite:buzug_thorston_m._milestones_2008,hsieh_computed_2009.

Though the fourth and fifth generation scanners are interesting
manifestations of CT scanning technology, they are only included here
for completeness and will not be discussed further. In the following
section, we will look at a major development in reconstruction
algorithm technology that cemented the third-generation CT scanner's
popularity. This algorithm development enabled the extension of the CT
detector's axial coverage allowing for volumetric image acquisition
and reconstruction using the third-generation scanner design. This
development also led to the development of a new cone-beam CT (CBCT)
geometry which is the focus of this work.

** Cone-beam CT and new scanning trajectories
   :PROPERTIES:
   :ID:       f84fb81e-a07d-4945-9653-fd1544703733
   :END:
For all the CT scanners discussed in the previous section [[id:1b7b31c8-4bd5-4402-b930-d81984ee5901][CT
development history]], the only scanning trajectory utilized for CT was
the circular rotation of the source and detector around the patient.
This limitation was due to both the hardware geometry and the
reconstruction algorithms that were initially focused on acquiring and
reconstructing 2D-planar slices of the object being imaged.
Unfortunately, this slice-by-slice acquisition and reconstruction
framework was somewhat limiting in acquiring volumetric CT images. 

The use of new scanning trajectories to increase the volumetric
imaging capabilities of CT began with the development of the spiral or
helical CT reconstruction algorithm
cite:kalender_spiral_1990,kudo_helical-scan_1991,katsevich_theoretically_2002,katsevich_exact_2004.
By adding longitudinal translation of the patient couch through a
third-generation scanner, it was possible to perform a helical
trajectory of the source and detector around the patient. This made it
possible to rapidly acquire multi-slice (or volumetric) CT of a
patient using the existing diagnostic imaging hardware of the
third-generation scanners.

Another approach to acquire volumetric tomographic images was to
extend the CT detector array in the longitudinal direction by adding
additional rows of detector arrays. These multi-array detectors helped
to improve the interpolation procedure used for reconstructing the
data acquired from a helical scan, and continue to be used in modern
third generation CT scanners. As these multi-array detectors began to
cover larger extents of the axial field of view (FOV), they eventually
led to large flat-panel detector being used to acquire projection
information. The flat-panel detector systems are now known as
cone-beam CT (CBCT) systems to reflect the cone of x-ray illumination
on these detectors as opposed to the fan-beam geometry of the earlier
slice-by-slice scanners.

With the advent of CBCT scanners, efforts were made to extend the FBP
algorithm to three dimensions (3D)
cite:grangeat_mathematical_1991,kudo_derivation_1994,kudo_fast_1998,buzug_thorston_m._three-dimensional_2008.
Though all of these methods attempted to find an analytic inverse to
the forward-projection imaging model, they require exact Radon data,
which is not provided by the circular trajectory routinely employed by
third generation scanners. It was the development of a modified FBP
algorithm by Feldkamp, Davis and Kress or FDK
cite:feldkamp_practical_1984 (which we will discuss further in
[[id:04DD4E55-A20B-4A27-BBDD-BB493DD82674][Analytic-based reconstruction]]) that made it possible to obtain a
useful reconstruction from a circular scanning trajectory on a CBCT
system.

** Image-guided radiation therapy
   :PROPERTIES:
   :ID:       bbf164a1-25cd-4b35-b4ae-eb2b642d9d18
   :END:
X-ray technology is unique in how rapidly it was applied to the field
of medicine following the discovery of x-rays by Wilhelm
R\text{\"o}ntgen in 1895. The next year in Chicago, Emil Grubbe built
his own x-ray device which he began to use for therapeutic purposes
cite:mukherjee_emperor_2010. Both diagnostic and therapeutic uses of
radiation developed in concert throughout the 20^th century culminating
in radiation treatment devices that combine low-energy CT imaging or
magnetic resonance imaging (MRI) with high-energy treatment beams in
image-guide radiation therapy (IGRT). A particularly popular method of
delivering therapeutic radiation doses are linear accelerators
(linacs) that deliver powerful megavoltage (MV) treatment beams to
diseased tissue.

Though the type of particle and energy spectra of therapeutic
radiation will vary depending on both the type and progression of the
disease, the desired effect of the prescribed dose is to ablate the
diseased tissue by inducing cell death in the cancer cells. Much as
with traditional surgical techniques, there is also a simultaneous
need to spare the healthy tissue while removing the diseased tissue.
In the pursuit of achieving this balance between killing diseased
tissue and sparing healthy tissue with the delivered dose, a variety
of radiation therapy modalities have been developed.

The initial application of radiation for therapeutic purposes was
initially limited to superficial lesions. As great care must be take
to ensure the dose is delivered just to the target area, there must be
a way to visualize the target of the delivered dose. In the early
application of therapeutic radiation, physicians were limited to those
pathologies that were externally visible. It was the Swedish
neurosurgeon Lars Leksell who conceptualized using a high-energy
photon beam to deliver a therapeutic dose deep inside the brain
without the additional complications of invasive surgery
cite:kushnirsky_history_2015.

The half a century between the discovery of x-rays and the use of them
to treat internal structures was the need for imaging technology that
made visualizing these internal targets feasible. The development of
CT technology discussed in [[id:1b7b31c8-4bd5-4402-b930-d81984ee5901][CT development history]] provided the
requisite volumetric information that allowed physicians to locate
these internal lesions in the patient. This was required in order for
the physicians to accurately target the lesions using the high-energy
beams proposed by Leksell. He realized by distributing small-field
beams around the target, we could create a high-dose deposition at a
desired internal target location which led to him and his colleagues
producing the GammaKnife in 1968 which consisted of 179 cobalt-60
sources distributed in a hemisphere around the patient's cranium for
stereotactic radiosurgery (SRS) cite:kushnirsky_history_2015.

The eventual acceptance of SRS in the United States in 1984 and the
subsequent rise in popularity of the technique led to use of linear
accelerators for delivering the therapeutic dose rather than the fixed
cobalt-60 sources cite:kushnirsky_history_2015. Linacs were not only
able to produce treatment beams that were comparable to those provided
the cobalt-60 sources, but they had the additional benefits of being
able to produces much higher energy spectra without the need to
replace the radiation source as they decayed as cobalt-60 sources.
However, despite the tomographic imaging used to plan the prescribed
radiation dose, only radiographic projection imaging was used for
setting up the patient at the treatment isocenter of these devices.

The addition of a linac-mounted, kV-imaging, cone-beam computed
tomography (CBCT) system to the gantry-mounted clinical linear
accelerator
cite:jaffray_flat-panel_2002,letourneau_cone-beam-ct_2005,rahman_linac:_2015
helped this modality become the most popular form of image-guided
radiation therapy (IGRT)
cite:xing_overview_2006,bissonnette_quality_2012,dawson_advances_2007.
The tomographic information provided in the kV energy range improves
soft-tissue contrast resolution over that provided by the MV
electronic portal imaging device (EPID) alone
cite:jaffray_radiographic_1999. The linac-mounted, kV-imaging, CBCT
system not only helps with patient setup and target verification, but
it also allows the monitoring of the tumor response during treatment
cite:oldham_cone-beam-ct_2005.

#+CAPTION: Annotated image of a TrueBeam linac. See text for description of components.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:intro_linac
[[file:figures/intro/annotated_linac.png]]

Figure ([[ref:fig:intro_linac]]) shows an annotated image of a Varian
TrueBeam linac (Varian Medical Systems, Palo Alto, CA). On the patient
couch is the CIRS Torso Phantom (Computerized Imaging Reference
Systems, Norfolk, VA) aligned at the mechanical isocenter using the
laser guidance system. Above the torso phantom to the left is the MV
treatment head with the metallic accessory mount and beam exit window.
Below the table to the left is the kV source which provides the kV
x-rays for the kV-CBCT imaging system. Above the phantom to the right
is the kV detector panel which acquires the projections through the
phantom for the kV-CBCT imaging system. Both the kV source and kV
detector are mounted on robotic position arms. Below the phantom to
the right is the MV electronic portal imaging device, which is
retracted in this image, for acquiring MV projections from the MV
treatment beam. Finally all of these components are mounted on a
rotating gantry which can rotate $360^{\circ}$ around the mechanical
isocenter for a single rotation. A subsequent rotation must occur in
the opposite direction as the gantry lacks the ability to make
multiple rotations in the same direction like a diagnostic CT system
due to the complexity of the MV linac design.

While there are many advantages to using linac-mounted CBCT imaging
systems for IGRT, there are still technical limitations that
negatively impact clinical utility, that could be alleviated by
utilizing non-circular scanning trajectories with optimization-based
reconstruction. One issue is the limited axial FOV coverage provided
by the current detectors and circular scanning trajectory. Another
issue is the increased potential of patient collisions with the
rotating treatment gantry. In this work, we will focus exclusively on
utilizing a generalized optimization-based reconstruction framework
from arbitrary CBCT trajectories to address these clinical issues for
IGRT. However, the framework itself is not necessarily restricted to
IGRT and could be of potential use for a variety of other CBCT
applications.

** Organization
   :PROPERTIES:
   :ID:       252a18dd-1210-4360-b082-fce5510334ab
   :END:
In this work, we will discuss an optimization-based,
image-reconstruction framework that enables the use of new scanning
trajectories. In particular, we will focus on how this approach was
developed to address the two clinical shortcomings of limited axial
FOV coverage and potential patient collisions with the linac gantry.
By using these two examples, we will not only show the feasibility of
using these non-circular trajectories, but also a potential solution
to existing clinical needs.

First, we will discuss the framework and considerations of using
optimization-based reconstruction with different scanning trajectories
in [[id:06ec01f2-e128-4baf-9ec7-4569a3aaa886][Optimization-based algorithms]]. Next, we will discuss the need for
geometric calibration and discuss a method we developed to accomplish
this for these trajectories in [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Geometric calibration]]. We will then
review the use of new trajectories to address the limited axial FOV
issue in [[id:eaae199f-f899-4862-af50-720895a31c36][Axial field-of-view extension]] followed by using these
trajectories to alleviate the issue of patient collisions in
[[id:99055e18-4b61-404e-9408-ebd5fd0a5d8d][Collision-avoiding trajectories]]. Finally, we will summarize this work
and discuss possible clinical considerations with this methodology in
[[id:1bade25b-80d6-4650-b8a3-baf370fa657c][Summary and conclusions]].

The increased flexibility in choosing different scanning trajectories
allowed by optimization-based reconstruction methods provided two
solutions to the issues of limited axial FOV coverage and potential
patient collisions. For these two problems, we found that the existing
limitations could be resolved by using a different scanning
configuration. In each case, we proposed a trajectory that would solve
the existing problem, and then we evaluated how well the
optimization-based reconstructions compared to currently used clinical
images.

* General CBCT trajectory reconstruction framework with optimization-based algorithms :opt:
  :PROPERTIES:
  :ID:       06ec01f2-e128-4baf-9ec7-4569a3aaa886
  :END:
Through the years of CT research, a fundamental question has always
been how to move the source and detector of the imaging system
relative to the object to obtain sufficient projection information to
reconstruct a useful image. Part of this answer must take into account
certain engineering limitations that go into building such a system.
However, this is fundamentally a question that must address the
requirements of the computational reconstruction algorithm used to
assemble the image from the x-ray projections.

There are two main classes of reconstruction algorithms.
Analytic-based algorithms, such as FDK cite:feldkamp_practical_1984,
represent an approximate solution to the inverse imaging problem,
i.e., calculating the object function from its projections.
Optimization-based algorithms represent the forward imaging problem as
a linear system, and attempt to iteratively invert this system to find
an object function that is consistent with the observed projections.
Image reconstruction with optimization-based methods provides a robust
framework for reconstructing from projections acquired with
nonstandard trajectories designed to address specific CBCT limitations
as they require no assumptions about the initial scanning trajectory.

The use of optimization-based methods for tomographic image
reconstruction is a natural extension of linearizing the x-ray
transform imaging model of a tomographic scan. Approaching the image
reconstruction problem as a linearized imaging model has existed since
the first CT system built by Cormack and Hounsfield. As discussed in
the [[id:852796c3-9a3b-49da-bc08-1299e93e0768][Introduction]], they utilized the algebraic reconstruction technique
(ART) to solve a system of equations created by the summation of the
rays through the image pixel grid at each projection angle
cite:herman_art:_1973.

Though the initial optimization-based image reconstruction with ART
was successful in providing a solution to the inverse problem, the
limited computational power available at the time proved to be an
intractable limitation. Though the number of unknown variables in the
system of equations associated with this 2D reconstruction problem is
trivial by today's standards, the lack of parallelization and other
engineering limitations of transistors at the time were too onerous
for the clinical workflow. This computational complexity was further
increased when moving from two-dimension (2D), single-slice images to
three-dimensional (3D), volumetric image reconstruction which
introduces a greater number of unknowns. However, a recent renaissance
of utilizing graphics processing units (GPUs) -- technology once
solely in the purview of video games -- for scientific computation has
made optimization-based methods temporally competitive with
analytic-based methods cite:xu_accelerating_2005,sharp_gpu-based_2007.
** Background: Cone-beam computed tomography
   :PROPERTIES:
   :ID:       d136ffd1-6def-4c22-85ed-6049f04b8486
   :END:
*** Analytic-based reconstruction
    :PROPERTIES:
    :ID:       04DD4E55-A20B-4A27-BBDD-BB493DD82674
    :ORDERED:  t
    :END:
Analytic-based reconstruction algorithms are formulated by explicitly
finding an inverse to the X-ray transform
\begin{equation}
  \label{eq:xray}
  g(\mathbf{r}_0,\hat{\theta})=\int_0^{\infty}f(\mathbf{r}_0+t\hat{\theta})dt,
\end{equation}
where the data function $g$ is acquired by integrating along the ray
from the source at $\mathbf{r}_0$ in the direction $\hat{\theta}$ through
the object function $f$. A fundamental problem with these
reconstruction algorithms when practically reconstructing $f$ is the
assumption of a continuous-to-continuous (CC) model. These
analytic-based reconstruction algorithms impose dense sampling
requirements for both the detector and number of views to approximate
a continuous data function. Given that the data function from the
digital detector and the numerical array for storing the reconstructed
image are both discrete, a more natural approach to the inverse
problem would be a discrete-to-discrete (DD) imaging model
cite:barrett_foundations_2003.

#+LABEL: fig:opt_analytic
#+BEGIN_SRC asymptote :file figures/opt/analytic.pdf :exports results :tangle no
settings.multisample=0;
settings.outformat="pdf";
// settings.prc = false;
// settings.render = 0;

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(10cm);
// currentprojection=orthographic(-15,10,20,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// detector
real dlat=0, dvrt=50;
pair det=(dvrt,dlat);

real ulen=40.0, vlen=30.0;

path detector=(dvrt,-ulen/2+dlat)--(dvrt,ulen/2+dlat);
pair det_cent=(dvrt,0);

// source
real slat=0, svrt=-100;
pair src=(svrt,slat);

// rotate sys and draw
real theta=30;

draw(Label("$g\left(\mathbf{r}_{0}, \hat{\theta}\right)$",position=MidPoint),rotate(theta)*detector, black);
draw(Label("$\mathbf{r}_0$",position=BeginPoint,black),rotate(theta)*src--rotate(theta)*det_cent, dashed+red,Arrow(TeXHead));

// show the cone angle
real f_loc = 1.3;
real op_c = 0.5;
draw(rotate(theta)*src--rotate(theta)*(dvrt,ulen/2+dlat), blue+opacity(op_c));
draw(Label("$\gamma$", position=MidPoint),
     arc(rotate(theta)*src,
         r=dvrt*f_loc,
         angle1=theta,
         angle2=theta+degrees(atan(.5*ulen/(dvrt-svrt)))),
     blue, arrow=Arrow(TeXHead));

// label("\mathbf(r)_0", src)
// draw(src--(dvrt, -ulen/2+dlat), dashed+black);
// draw(src--(dvrt, ulen/2+dlat), dashed+black);

addMargins(0.5cm, 0.5cm);

// Draw axis
real ax_scale=30;
draw(Label("$x$",position=EndPoint),(-ax_scale,0)--(ax_scale,0),black,Arrow(TeXHead));
draw(Label("$y$",position=EndPoint),(0,-ax_scale)--(0,ax_scale),black,Arrow(TeXHead));

// show gantry angle
draw(Label("$\theta$",position=MidPoint,E), arc((0, 0), r=2*ax_scale/3, angle1=0, angle2=theta), red, arrow=Arrow(TeXHead));

// generic object
real obj_scale=10;
path obj=(-obj_scale,-obj_scale){dir(45)}..(obj_scale,0)..(obj_scale,obj_scale)..(0,obj_scale)..cycle;
draw(Label("$f$",position=Relative(0.2)),obj,black);
#+END_SRC

#+CAPTION: Single-view schematic of the x-ray transform of an object $f$ from an x-ray source at $\mathbf{r}_{0}$ illuminating the detector in the direction of $\hat{\theta}$ to produce the detector response $g\left(\mathbf{r}_{0}, \hat{\theta}\right)$. The angle $\gamma$ is the maximum cone-angle of this CBCT as determined by the detector size. The source and detector geometry is that of Varian's TrueBeam kV-imaging system.
#+LABEL: fig:opt_analytic
#+ATTR_LaTeX: :width \textwidth
#+RESULTS: fig:opt_analytic
[[file:figures/opt/analytic.pdf]]

In the 1980s, work was done to directly solve the inverse problem for
the cone-beam geometry cite:parker_optimal_1982-1,finch_cone_1985. By
modeling the projection formation process as a Radon transform or an
X-ray transform, reconstruction algorithms were formulated by finding
an analytic-based inverse to the transform. However, for the inverse
to be exact, it needed to meet strict requirements such as Tuy's
condition which states that every plane through the object must
intersect the source trajectory cite:tuy_inversion_1983. Though there
are non-circular trajectories such as the infinite-line trajectory
which satisfy Tuy's condition, the application of such trajectories
for real scanning configurations are always approximations
cite:sidky_volume_2005 which fail to satisfy the requisite geometry to
provide an exact inverse.

The circular scanning trajectory that is ubiquitous in the clinic for
CBCT is one trajectory that fails to meet Tuy's condition. The most
popular reconstruction algorithm for the circular CBCT trajectory is
the filtered-backprojection (FBP) algorithm proposed by Feldkamp,
Davis, and Kress (FDK) cite:feldkamp_practical_1984 which is still the
industry standard. FDK is only an exact inversion to the Radon
transform on the midplane containing the circular source trajectory.
For transaxial planes other than the midplane, a quasi-redundancy in
the scanning data is assumed. It is the violation of this assumption
which leads to cone-angle artifacts, an example of which is shown in
Figure ([[ref:fig:opt_defrise_fdk]]). These artifacts become more severe
at larger cone angles (the angle $\gamma$ in Figure ([[ref:fig:opt_analytic]]))
where this assumption is less applicable.

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{figures/opt/defrise_fdk_sag.jpg}
  \caption{}
  \label{fig:opt_defrise_fdk}
\end{subfigure}
~ %add desired spacing between images, e. g. ~, \quad, \qquad,
% \hfill etc.
% (or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{figures/opt/defrise_mlem_sag.jpg}
  \caption{}
  \label{fig:opt_defrise_mlem}
\end{subfigure}
\caption{Simulated example of cone-angle artifacts seen in the
  sagittal view of a reconstructed Defrise-style phantom. On the left
  is an FDK reconstruction, and on the right is an MLEM reconstruction
  (200 iterations). Such a phantom design of alternating high-contrast
  densities along the longitudinal direction is explicitly identified
  by the FDK authors as being a case where their assumptions breakdown
  at larger cone angles. In the middle of image that corresponds to
  the plane of the source orbit, the sharp boundaries between the
  alternating disks can be seen. However at the edges of the image,
  corresponding to larger cone angles, the breakdown of these
  assumptions and the cone-angle artifacts produced can be seen. The
  cone-angle artifacts at the larger cone angles are less severe in
  the optimization-based reconstruction ([0, 0.3] cm$^{-1}$ display
  window).}
\label{fig:opt_defrise}
\end{figure}
#+END_EXPORT

The presence of cone-angle artifacts in FDK reconstructions from the
incomplete data acquired with circular scanning trajectories led to
research into inverse algorithms for cone-beam scans from
theoretically complete trajectories such as a circle plus a line
cite:zeng_cone-beam_1992. It became apparent in the reconstruction
results that implementing these direct reconstruction algorithms did
not produce the anticipated results cite:kudo_derivation_1994. Severe
artifacts and numerical errors were found in the reconstructions due
to factors such as truncation introducing high-frequency components
that are amplified in the filtration process.

*** Optimization-based reconstruction
    :PROPERTIES:
    :ID:       07e91084-61be-43d3-a905-65ef0ab997a4
    :END:
Analytic-based reconstruction algorithms are problematic in that they
require a fixed scanning trajectory to formulate the inverse. When
approximations are made for the inverse, as in FDK, deviations from
these approximations lead to inconsistencies in the model and
subsequently artifacts in the reconstruction such as the cone-angle
artifacts shown in Figure ([[ref:fig:opt_defrise_fdk]]). In contrast,
optimization-based reconstruction algorithms represent a more robust
model of the image formation process
cite:shepp_maximum_1982,han_optimization-based_2012,sidky_image_2008,sidky_accurate_2006,bian_evaluation_2010.
As Figure ([[ref:fig:opt_defrise_mlem]]) shows, this can help reduce
artifacts such as the cone-angle artifacts.

Optimization-based reconstruction algorithms provide a more accurate
model of the DD imaging system that comprises both the digitized
projection images from the kV-imaging detector and the digitized
tomographic image calculated by the reconstruction program. The X-ray
transform of the object function can be represented as the linear
system
\begin{equation}
  \label{eq:opt_ddsys}
  \mathbf{g}=\mathcal{H}\mathbf{f},
\end{equation}
where $\mathbf{g}$ is the discrete $M$ pixel sampled projection on the
detector, $\mathcal{H}$ is the $M\times N$ discrete form of the X-ray
transform, and $\mathbf{f}$ is the object function represented on a N
voxel basis. As direct inversion of $\mathcal{H}$ is impractical due
to both its size and inconsistencies from factors such as noise,
optimization techniques are used to solve this system for an estimate
of the object $\mathbf{f^{*}}$.

The optimization problem is formulated as an objective function based
on the actual data $\mathbf{g}$ and the image model
$\mathcal{H}\mathbf{f}$. An optimization algorithm is then used to
iteratively update the estimate of $\mathbf{f^{*}}$ until a suitable
convergence criterion has been met. The parameters of the optimization
problem, the optimization algorithm, and the convergence criteria are
all important factors in determining the properties of the
reconstructed image and subsequently its utility. When the
reconstruction program is not run to convergence, a parameter such as
the number of iterations can be fixed provided justification is given
for the choice of iterations.

In selecting the parameters for the reconstruction program,
consideration must be given to the impact each parameter will have on
the reconstructed image quality. As we investigated using
optimization-based reconstruction for non-circular scanning
trajectories, we selected parameters of our reconstruction program to
mimic the relevant clinically-utilized parameters where applicable.
For instance, our reconstruction resolution sizes are chosen to
provide the same voxel sizes used by the clinical reconstruction
software. However, these parameter choices are made only to provide
comparisons to the current clinical image quality. This does not mean
that these values are optimally selected, and for any clinically
relevant evaluation, rigorous parameter optimization must be studied
for the clinical imaging task
cite:metz_basic_1978,xia_optimization-based_2016-2.

Previous work has shown that optimization-basaed algorithms can
reconstruct clinically useful images under scanning conditions for
which analytic-based FDK fails
cite:han_optimization-based_2012,sidky_image_2007,sidky_accurate_2006.
In applying optimization-based reconstruction to non-circular
trajectories, we focus primarily on the well-understood
maximum-likelihood expectation maximization (MLEM)
cite:shepp_maximum_1982,dempster_maximum_1977. Though a variety of
optimization-based reconstruction programs exist, we used the MLEM
program to limit the number of parameters introduced by the
reconstruction program, since new scanning trajectories already
introduce additional parameters that impact the projection data and
resulting tomographic reconstruction.

# constrained, total-variation (TV) minimization by adaptive steepest
# descent-projection onto convex sets (ASD-POCS)
# cite:sidky_image_2008.

** Background: Scanning trajectories
   :PROPERTIES:
   :ID:       c90cd638-44e6-49f3-9283-29f75d163005
   :END:
*** Standard Trajectories
    :PROPERTIES:
    :ID:       6293da29-e448-4614-84b6-065af1cc6be9
    :END:
In IGRT, linac-mounted CBCT imaging systems such as Varian's TrueBeam
kV-imaging system now routinely provide patient image information.
These images are used to check the patient alignment before delivering
the radiation treatment. The circular rotation of the linac gantry
defines the acquisition trajectory for the CBCT scan. While such a
scanning trajectory provides sufficient information for an
analytic-based reconstruction of the scan volume, there are a variety
of limitations that arise from this work flow.

Due to engineering and cost restrictions, the kV detector has a
limited size. The TrueBeam system has a transaxial width of 40 cm and
an axial height of 30 cm. This restricts the FOV that can be imaged in
a traditional circular scan. While the offset detector technique
cite:bian_optimization-based_2013,cho_cone-beam_1995 is commonly used
to increase the transaxial FOV (for a 1.5X magnification, this is an
increase in FOV diameter from 26.7 cm to 44.0 cm on the TrueBeam
system with a 13 cm offset), the axial coverage is still very limited
(20 cm for the same TrueBeam geometry) cite:pearson_non-circular_2010.
The reason that the limited FOV has not been addressed by increasing
the detector size is partially due to the industry's reliance on the
approximate FDK algorithm cite:pan_why_2009. As shown in Figure
([[ref:fig:opt_defrise]]), as the cone angle increases, artifacts near the
end of the axial FOV become more severe.

Another problem with the current circular imaging trajectory is the
potential for linac collisions with the patient
cite:hua_practical_2004,nioutsikou_patient-specific_2003. Cases arise
when the patient is positioned in the treatment position, a CBCT image
cannot be acquired due to part of the patient being in the path of the
linac's trajectory (i.e., gantry clearance cannot be achieved). As the
current FDK algorithm requires a trajectory with sufficient angular
coverage, the patient must be moved to a position where the gantry can
make an uninterrupted rotation around the patient. These workarounds
can incur significant temporal costs in re-positioning the patient on
the treatment couch for a new collision-avoiding setup. A robust
scanning modality that could avoid these collision zones while
providing sufficient tomographic information would alleviate these
expensive re-positioning occurrences.

In both of these examples, the default circular trajectory prescribed
by FDK is inadequate for obtaining the desired tomographic
information. Furthermore, the disruption to the clinical workflow
created by these limitations introduces bottlenecks into clinical
efficiency which affects both the clinical staff as well as the
patient's comfort in the procedure. In the case of a potential patient
collision, the inability to acquire the required trajectory can even
result in forgoing the CBCT image. For these particular examples, we
investigated ways in which new trajectories enabled by
optimization-based reconstruction could alleviate the limitations
imposed by the standard circular scan.

*** General trajectories
    :PROPERTIES:
    :ID:       bb0f7766-83f0-44ba-986a-5062e9532a01
    :END:
Though there has been previous work in developing analytic methods for
addressing the reconstruction from some novel trajectories
cite:katsevich_theoretically_2002,katsevich_image_2004,katsevich_image_2005,katsevich_formulation_2006,
it could be clinically useful to enable reconstruction from an
arbitrary, collision-avoiding trajectory. As the collision region (if
one arises) is contingent on the patient's size and treatment
position, the imaging trajectory would vary on a per patient basis. As
such, deriving the analytic inverse for each patient's scanning
trajectory would be impractical.

Optimization-based reconstruction provides a generalized framework
enabling greater flexibility in reconstructing from projections
acquired with non-circular trajectories. Provided the geometry of each
view is correctly incorporated into the system matrix $\mathcal{H}$ in
Equation ([[ref:eq:opt_ddsys]]), clinically useful reconstructions can be
obtained from acquisitions for which an analytic inverse may not be
available. This robust approach enables tomographic imaging from
collision-avoiding trajectories that would accommodate the patient's
specific needs.

For the problem of the limited axial coverage, the current clinical
method of extending the FOV is to acquire two circular scans at
different axial positions and reconstruct each circle independently
using FDK before stacking the two volumes together
cite:forthmann_adaptive_2009. Unfortunately, the increased distortion
from cone-angle artifacts at large cone angles limits the axial
separation between these two circles illustrated in blue and red in
Figure ([[ref:fig:opt_fov_schematic]]). In addition limitations incurred
by the failure in the FDK approximation at larger cone angles, there
is an additional limitation that the support, or volume of the image
space that can be reconstructed, allowed by analytic-based methods is
restricted to the shaded regions of Figure
([[ref:fig:opt_fov_schematic]]).

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{subfigure}[b]{0.9\textwidth}
\includegraphics[width=\textwidth]{figures/opt/ax_fov_10cm.pdf}
\caption{}
\label{fig:opt_fov_10cm}
\end{subfigure}
~ %add desired spacing between images, e. g. ~, \quad, \qquad,
% \hfill etc.
% (or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.9\textwidth}
\includegraphics[width=\textwidth]{figures/opt/ax_fov_20cm.pdf}
\caption{}
\label{fig:opt_fov_20cm}
\end{subfigure}
\caption{Schematic illustrating the axial coverage provided by
  stacking two circular FDK reconstructions together for the TrueBeam
  kV imaging system. In each figure, the top portion corresponds to
  the projective geometry of the superior circle (blue), and the
  bottom portion corresponds to that of the inferior circle (red). For
  both the inferior and superior circles, two projective views are
  illustrated as opposing projective views at $\theta=0^{\circ}$ (solid lines)
  and $\theta=180^{\circ}$ (dashed lines). The shaded regions corresponds to
  the image support of an FDK reconstruction of the respective circle.
  The top figure (a) represents an axial separation between the two
  circles ($d=10\text{ cm}$) where the support volumes overlap
  (purple). The bottom figure (b) shows the maximum axial separation
  ($d=20\text{ cm}$) for which the two support volumes are contiguous
  though they share no redundancy in the reconstructed volumes.
}
\label{fig:opt_fov_schematic}
\end{figure}
#+END_EXPORT

The use of the two circles alone provides one interesting example of a
trajectory where optimization-based reconstruction provides an
advantage to the stacked-FDK method currently used. Unlike stacking
two separate reconstructions together, it is possible to reconstruct
the entire volume at once provided the system matrix is correctly
calculated to reflect the acquisition of two circles in planes located
at different axial positions relative to the patient. In addition to
the reduced cone-angle artifacts already seen in optimization-based
methods, reconstructing both volumes together provides additional
information about the overlapping region between the circles that
further helps to reduce the cone-angle artifacts.

In addition to improving the use of the two circles, the
optimization-based framework allows for noncircular trajectories.
Given that there needs to be a relative axial translation between the
kV-imaging system and the patient, we investigated if there were any
advantages to acquiring some projection views during the axial
translation. Such trajectories that included an axial translational
stage have been studied before and have the potential to further
reduce the impact of cone-angle artifacts with both analtyic-based
cite:zeng_cone-beam_1992,noo_stable_1996,johnson_feldkamp_1998,katsevich_image_2004
and optimization-based methods cite:davis_we-g-brf-07:_2014.

In the case of potential patient collisions with the linac gantry, a
simple change in the scanning trajectory could be sufficient to
prevent a collision. Much like the extended axial FOV case,
optimization-based reconstruction is able to handle variations in the
acquisition trajectory provided it is accurately reflected in the
system matrix. As such, there are two different ways we studied where
the scanning trajectory could be modified to avoid a collision.

If the patient collision were to occur with the kV detector (the
closest component of the CBCT system to the patient), one possible way
to avoid that collision would be to move the kV detector away from the
patient at the collision region. Since the detector is mounted on a
robotic arm, it should be possible to move the detector outward from
the isocenter radially, increasing the diameter of both the
collision-free region and of the scanning trajectory. This effectively
changes the magnification for that region, but the reconstruction
framework is able to reconstruct from all the views at both
magnifications provided that everything is accurately modeled in the
reconstruction problem. 

The other trajectory modification that could solve this problem would
be to move the patient. As with the change in magnification, the
change in the patient position does not prevent reconstruction with
the optimization-based methods provided the patient motion is
correctly incorporated into the system matrix $\mathcal{H}$. Moving
the patient also provides a solution to avoid potential patient
collisions that occur with the linac treatment head. The MV treatment
head on Varian's TrueBeam system is actually closer to the patient
than the kV detector. Unlike the kV detector, it is not possible to
change the position of the treatment head. In this case, moving the
patient would be the only viable trajectory modification to avoid a
collision.
**** figures                                 :noexport:
***** 10 cm
#+BEGIN_SRC asymptote :file figures/opt/ax_fov_10cm.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
// settings.prc = false;
// settings.render = 0;

import geometry;
import solids;
import three;

defaultpen(fontsize(10pt));
unitsize(1cm);

// view configuration
size(10cm);
addMargins(0.5cm, 0.5cm);

// line opacity
real opl=0.5;
real oplt=0.8;

// area opacity
real opa=0.1;

// currentprojection=orthographic(-15,10,20,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// lngoffset from midplane
real lng = 10/2.;

// det lng len
real vlen=30.0;

// detector 1
real dlng1=-lng, dvrt=50;
point det1=(dvrt, dlng1);
point det1_sup=(dvrt, dlng1+vlen/2);
point det1_inf=(dvrt, dlng1-vlen/2);

// detector 2
real dlng2=lng;
point det2=(dvrt, dlng2);
point det2_sup=(dvrt, dlng2+vlen/2);
point det2_inf=(dvrt, dlng2-vlen/2);

// source
real svrt=-100;
point src1=(svrt, dlng1);
point src2=(svrt, dlng2);

// now the lines
line detector1=line(det1_inf, false, det1_sup, false);
line d1_iray=line(src1, false, det1_inf, false);
line d1_sray=line(src1, false, det1_sup, false);

line detector2=line(det2_inf, false, det2_sup, false);
line d2_iray=line(src2, false, det2_inf, false);
line d2_sray=line(src2, false, det2_sup, false);

// draw source and detectors w/ rays connecting edge
draw(detector1,red+opacity(opl));
draw(d1_iray,red+opacity(opl));
draw(d1_sray,red+opacity(opl));

draw(Label("$\theta_{s}=0^{\circ}$", position=EndPoint, E),
     detector2,blue+opacity(opl));
draw(d2_iray,blue+opacity(opl));
draw(d2_sray,blue+opacity(opl));

// rotate by 180 and show opposing geometry
point src1f=(-src1.x,src1.y);
point det1f_inf=(-det1_inf.x,det1_inf.y);
point det1f_sup=(-det1_sup.x,det1_sup.y);

point src2f=(-src1.x,src2.y);
point det2f_inf=(-det2_inf.x,det2_inf.y);
point det2f_sup=(-det2_sup.x,det2_sup.y);

line detector1f=line(det1f_inf, false, det1f_sup, false);
line d1f_iray=line(src1f, false, det1f_inf, false);
line d1f_sray=line(src1f, false, det1f_sup, false);

line detector2f=line(det2f_inf, false, det2f_sup, false);
line d2f_iray=line(src2f, false, det2f_inf, false);
line d2f_sray=line(src2f, false, det2f_sup, false);

draw(Label("$\theta_{i}=180^{\circ}$", position=BeginPoint, W),
     detector1f,red+dashdotted+opacity(opl));
draw(d1f_iray,red+dashdotted+opacity(opl));
draw(d1f_sray,red+dashdotted+opacity(opl));

draw(detector2f,blue+dashdotted+opacity(opl));
draw(d2f_iray,blue+dashdotted+opacity(opl));
draw(d2f_sray,blue+dashdotted+opacity(opl));

// indicate offset
Label L = Label("$d$", position=MidPoint);

// distance(L, src1, src2, 0, black);
draw(src1 -- src2, L=L, bar=Bars);

// color in the regions of support
fill(intersectionpoint(detector1f, d1_sray) --
     intersectionpoint(d1_sray, d1f_sray) --
     intersectionpoint(d1f_sray, detector1) --
     intersectionpoint(detector1, d1f_iray) --
     intersectionpoint(d1f_iray, d1_iray) --
     intersectionpoint(d1_iray, detector1f) --
     cycle, opacity(opa)+red);

// color in the regions of support
fill(intersectionpoint(detector2f, d2_sray) --
     intersectionpoint(d2_sray, d2f_sray) --
     intersectionpoint(d2f_sray, detector2) --
     intersectionpoint(detector2, d2f_iray) --
     intersectionpoint(d2f_iray, d2_iray) --
     intersectionpoint(d2_iray, detector2f) --
     cycle, opacity(opa)+blue);
#+END_SRC

#+RESULTS:
[[file:figures/opt/ax_fov_10cm.pdf]]
***** 20 cm
#+BEGIN_SRC asymptote :file figures/opt/ax_fov_20cm.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
// settings.prc = false;
// settings.render = 0;

import geometry;
import solids;
import three;

defaultpen(fontsize(10pt));
unitsize(1cm);

// view configuration
size(10cm);
addMargins(0.5cm, 0.5cm);

// line opacity
real opl=0.5;
real oplt=0.8;

// area opacity
real opa=0.1;

// currentprojection=orthographic(-15,10,20,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// lngoffset from midplane
real lng = 20/2.;

// det lng len
real vlen=30.0;

// detector 1
real dlng1=-lng, dvrt=50;
point det1=(dvrt, dlng1);
point det1_sup=(dvrt, dlng1+vlen/2);
point det1_inf=(dvrt, dlng1-vlen/2);

// detector 2
real dlng2=lng;
point det2=(dvrt, dlng2);
point det2_sup=(dvrt, dlng2+vlen/2);
point det2_inf=(dvrt, dlng2-vlen/2);

// source
real svrt=-100;
point src1=(svrt, dlng1);
point src2=(svrt, dlng2);

// now the lines
line detector1=line(det1_inf, false, det1_sup, false);
line d1_iray=line(src1, false, det1_inf, false);
line d1_sray=line(src1, false, det1_sup, false);

line detector2=line(det2_inf, false, det2_sup, false);
line d2_iray=line(src2, false, det2_inf, false);
line d2_sray=line(src2, false, det2_sup, false);

// draw source and detectors w/ rays connecting edge
draw(detector1,red+opacity(opl));
draw(d1_iray,red+opacity(opl));
draw(d1_sray,red+opacity(opl));

draw(Label("$\theta_{s}=0^{\circ}$", position=EndPoint, E),
     detector2,blue+opacity(opl));
draw(d2_iray,blue+opacity(opl));
draw(d2_sray,blue+opacity(opl));

// rotate by 180 and show opposing geometry
point src1f=(-src1.x,src1.y);
point det1f_inf=(-det1_inf.x,det1_inf.y);
point det1f_sup=(-det1_sup.x,det1_sup.y);

point src2f=(-src1.x,src2.y);
point det2f_inf=(-det2_inf.x,det2_inf.y);
point det2f_sup=(-det2_sup.x,det2_sup.y);

line detector1f=line(det1f_inf, false, det1f_sup, false);
line d1f_iray=line(src1f, false, det1f_inf, false);
line d1f_sray=line(src1f, false, det1f_sup, false);

line detector2f=line(det2f_inf, false, det2f_sup, false);
line d2f_iray=line(src2f, false, det2f_inf, false);
line d2f_sray=line(src2f, false, det2f_sup, false);

draw(Label("$\theta_{i}=180^{\circ}$", position=BeginPoint, W),
     detector1f,red+dashdotted+opacity(opl));
draw(d1f_iray,red+dashdotted+opacity(opl));
draw(d1f_sray,red+dashdotted+opacity(opl));

draw(detector2f,blue+dashdotted+opacity(opl));
draw(d2f_iray,blue+dashdotted+opacity(opl));
draw(d2f_sray,blue+dashdotted+opacity(opl));

// indicate offset
Label L = Label("$d$", position=MidPoint);

// distance(L, src1, src2, 0, black);
draw(src1 -- src2, L=L, bar=Bars);

// color in the regions of support
fill(intersectionpoint(detector1f, d1_sray) --
     intersectionpoint(d1_sray, d1f_sray) --
     intersectionpoint(d1f_sray, detector1) --
     intersectionpoint(detector1, d1f_iray) --
     intersectionpoint(d1f_iray, d1_iray) --
     intersectionpoint(d1_iray, detector1f) --
     cycle, opacity(opa)+red);

// color in the regions of support
fill(intersectionpoint(detector2f, d2_sray) --
     intersectionpoint(d2_sray, d2f_sray) --
     intersectionpoint(d2f_sray, detector2) --
     intersectionpoint(detector2, d2f_iray) --
     intersectionpoint(d2f_iray, d2_iray) --
     intersectionpoint(d2_iray, detector2f) --
     cycle, opacity(opa)+blue);
#+END_SRC

#+RESULTS:
[[file:figures/opt/ax_fov_20cm.pdf]]

** Generalized trajectory framework
   :PROPERTIES:
   :ID:       ad13bdd9-4298-4534-979d-a019d80311a5
   :END:
To find an estimate of the object $\mathbf{f^{*}}$ as an approximate
solution to Equation ([[ref:eq:opt_ddsys]]), we choose a reconstruction
program that can be solved with the well-understood maximum-likelihood
expectation maximization (MLEM) algorithm cite:dempster_maximum_1977.
Here, our reconstruction program is formulated as
\begin{equation}
  \mathbf{f^{*}} = \text{argmin}D_{KL} \left(\mathbf{f}\right)
  \label{eq:opt_kl}
\end{equation}
where $D_{KL}(\mathbf{f})$ is the Kullback-Leibler (KL) divergence
between $\mathbf{g}$ and $\mathcal{H}\mathbf{f}$
cite:kullback_information_1951,barrett_foundations_2003. The KL
divergence, which is also known as relative entropy, is minimized with
the MLEM algorithm
\begin{equation}
f_j^{(n+1)}=\frac{f_j^{(n)}}{\sum\nolimits_{i=1}^{M}\mathcal{W}_{ii}\mathcal{H}_{ij}}\sum\limits_{i=1}^{M}\mathcal{W}_{ii}\mathcal{H}_{ij}\frac{g_i}{\sum\nolimits_{j=1}^{N}\mathcal{H}_{ij}f_j^{(n)}}
  \label{eq:opt_mlem}
\end{equation}
where $f_{j}^{n}$ is $j-\text{th}$ voxel value at iteration $n$ and
$\mathcal{H}_{ij}$ is the element of the system matrix at the
$i-\text{th}$ row and $j-\text{th}$ column for $i=1,2,...,M$ and
$j=1,2,...,N$. The initial image estimate for the reconstructions was
$\mathbf{f}^{(0)}=1$. The $M\times M$ diagonal matrix $\mathcal{W}$ weights
the corresponding data entries as is typically done for a standard
half-fan detector configuration for a circular scan
cite:bian_optimization-based_2013.

We define a scanning trajectory as the sequence of source and detector
positions used to acquire each projection view. For all of the
trajectories we studied, the detector moves in diametric opposition to
the kV-imaging source though this is not a requirement of this
formulation. The coordinates of the trajectory are then defined
relative to a fixed origin in the patient. In a traditional scanning
configuration where the patient is stationary, the system matrix
$\mathcal{H}_{ij}$ projects the object $\mathbf{f}$ from image space to
the data space of $\mathbf{g}$. When this is the case, it is
sufficient that the coordinate basis of the image space coincides with
the room coordinate system, or is at least stationary relative to it.
From each projection view acquired from the TrueBeam system, we
extracted the position information of the CBCT imaging arms and
subsequently built $\mathcal{H}_{ij}$ as the projective transform from
image space in the room coordinate system to the data space of the kV
detector.

When the patient is no longer fixed relative to the room-coordinate
system, (e.g. moving the treatment couch as the gantry rotates), the
image space $(\mathbf{f}_{\text{patient}})$ is moving relative to the
room coordinate system for each projection view. As such, a change of
basis for the columns space of $\mathcal{H}$ is necessary so that the
new system matrix represents a transform from the image space of the
patient to the data space of the detector represented as
$\mathcal{H'}$. As the acquisition system also reports the couch
position, we used this to build the required transformation matrix
$\mathcal{T}_{\text{IEC,patient}$ for each projection view. The
imaging model in Equation ([[ref:eq:opt_linmodel_patient]]) then becomes
\begin{equation}
  \label{eq:opt_linmodel_patient}
  \mathbf{g}=\mathcal{H'}\mathbf{f_{\text{patient}}},
\end{equation}
where
\begin{equation}
  \label{eq:sys_patient}
  \mathcal{H'}=\mathcal{H}\mathcal{T}_{\text{IEC,patient}}.
\end{equation}
Once the change of basis is accounted for, the reconstruction program
in Equation ([[ref:eq:opt_kl]]) can be reformulated with
$\mathbf{f_{\text{patient}}}$ instead of $\mathbf{f}$ and solved with the
MLEM algorithm in Equation ([[ref:eq:opt_mlem]]) using $\mathcal{H'}$
instead of $\mathcal{H}$.

*** Detector weighting                       :noexport:
    :PROPERTIES:
    :ID:       81d9f135-01c3-4415-a699-1f364e8c9ce3
    :END:

*weighting factor & schematic*

 #+LABEL: fig:opt_weighting
 #+BEGIN_SRC asymptote :file figures/opt/weighting.pdf :exports results :tangle no
settings.render = 0;
import geometry;
// size(8cm,0);
// unitsize(1cm)

// Affichage du repère par défaut (O,vec{i},vec_{j})
// show(defaultcoordsys);
// show(currentcoordsys);

// detector
real dlat=0, dlng=0, dvrt=50;
point det=(dvrt,dlat);

real ulen=40.0, vlen=30.0;

draw((dvrt,-ulen/2+dlat)--(dvrt,ulen/2+dlat),black);

// source
real slat=0, slng=0, svrt=-100;
point src=(svrt,slat);

draw(src--(dvrt, 0), dashed+red);
draw(src--(dvrt, -ulen/2+dlat), dashed+black);
draw(src--(dvrt, ulen/2+dlat), dashed+black);
dot("Source", src, N, red);

addMargins(0.5cm, 0.5cm);

// dot("Detector",det,N,5bp+.5blue);
// dot("Source",src,N,5bp+.5red);

// dot("Source", src)

// real a=5, b=4, theta=-70, poids=3;
// ellipse el = ellipse(origin, a, b);
// arc     ar = arc(el,(0,-b),(a,0),CCW);
// path p = (0,-b-1)--ar--(a+1,0)--(a+1,-b-1)--cycle;
// point pO = (0,0), pM=angpoint(ar,90+theta);
// abscissa abscM = nodabscissa(el,pM);
// real     timeM = abscM.x;
// vector utangM = -dir(el,timeM),
//        unormM = rotate(90)*utangM,
//        vpoids=(0,-poids),
//        vreactionN = -dot(vpoids,unormM)*unormM,
//        vfrottement = -dot(vpoids,utangM)*utangM;

// filldraw(p,lightgray,blue);
// draw(pO--pM,dashed);
// markangle("$\theta$",1.5cm,pM,origin,(1,0));

// coordsys R=cartesiansystem(pM,i=utangM,j=unormM);
// show("$M$", "$\vec{u_{\theta}}$", "$\vec{u_{r}}$", R, xpen=invisible);

// point RpM=changecoordsys(R, pM);
// show(Label("$\vec{f}$",EndPoint),RpM+vfrottement);
// show(Label("$\vec{R}$",EndPoint),RpM+vreactionN);
// show(Label("$\vec{P}$",EndPoint),RpM+vpoids);

// // size3(140,80,15);
// currentprojection=perspective(1,-1,1,up=Z);
// currentlight=White;

// // detector surface
// // path3 g=(1,0,0)..(0,1,0)..(-1,0,0)..(0,-1,0)..cycle;
// // draw(g);

// draw(O--X,red+dashed,Arrow3);
// draw(O--Y,red+dashed,Arrow3);
// draw(O--Z,red+dashed,Arrow3);

// // draw detector
// draw(((-1,-1,0)--(1,-1,0)--(1,1,0)--(-1,1,0)--cycle));

// real a=-0.4;
// real b=0.95;
// real y1=-5;
// real y2=-3y1/2;
// path A=(a,0){dir(10)}::{dir(89.5)}(0,y2);
// path B=(0,y1){dir(88.3)}::{dir(20)}(b,0);
// real c=0.5*a;
// pair z=(0,2.5);
// transform t=scale(1,15);
// transform T=inverse(scale(t.yy,t.xx));
// path[] g=shift(0,1.979)*scale(0.01)*t*
//   texpath(Label("{\it symptote}",z,0.25*E+0.169S,fontsize(24pt)));
// pair w=(0,1.7);
// pair u=intersectionpoint(A,w-1--w);

// real h=0.25*linewidth();
// real hy=(T*(h,h)).x;
// g.push(t*((a,hy)--(b,hy)..(b+hy,0)..(b,-hy)--(a,-hy)..(a-hy,0)..cycle));
// g.push(T*((h,y1)--(h,y2)..(0,y2+h)..(-h,y2)--(-h,y1)..(0,y1-h)..cycle));
// g.push(shift(0,w.y)*t*((u.x,hy)--(w.x,hy)..(w.x+hy,0)..(w.x,-hy)--(u.x,-hy)..(u.x-hy,0)..cycle));
// real f=0.75;
// g.push(point(A,0)--shift(-f*hy,f*h)*A--point(A,1)--shift(f*hy,-f*h)*reverse(A)--cycle);
// g.push(point(B,0)--shift(f*hy,-f*h)*B--point(B,1)--shift(-f*hy,f*h)*reverse(B)--cycle);

// triple H=-0.1Z;
// material m=material(lightgray,shininess=1.0);

// for(path p : g)
//   draw(extrude(p,H),m);

// surface s=surface(g);
// draw(s,red,nolight);
// draw(shift(H)*s,m);
 #+END_SRC

 #+CAPTION: Schematic representation of weighting factor
 #+ATTR_LaTeX: :width \textwidth
 #+RESULTS: fig:opt_weighting
 [[file:figures/opt/weighting.pdf]]

** Framework implementation with Varian TrueBeam kV-CBCT system
   :PROPERTIES:
   :ID:       58A6E225-522B-4620-BEDB-F81AD30070C3
   :ALT_TITLE: TrueBeam framework
   :END:
*** TrueBeam linac with Developer Mode
     :PROPERTIES:
     :ID:       3b90dfa6-e2de-4bdf-886a-31238cfa1cec
     :END:
To study these trajectories on a clinical, kV-imaging system, we
implemented some of them on Varian's TrueBeam system. The TrueBeam
Developer Mode provides control of the kV imaging system to allow for
motion control that is unavailable in clinical modes. Developer Mode
provides a scriptable control interface that allows control of the
gantry rotation, the kV-imaging arms, as well as the position of the
treatment couch. By combining motions with all of these components, it
is possible to acquire kV projection data from a variety of different
interesting motions. From the acquisition, each projection is returned
with self-reported nominal values that can be used to build the
reconstruction system matrix. Table ([[ref:tab:opt_varian_header]]) shows
a subset of these header variables pertaining to the kV imaging
system.

The TrueBeam's kV imaging system is illustrated in Figure
([[ref:fig:intro_linac]]) in addition to the gantry, couch, and robotic
arms that can all be utilized to implement these trajectories. The
kV-imaging system itself consists of a Varian kV x-ray source
(GS-1542) and a 39.7 cm x 29.8 cm amorphous silicon flat-panel
detector (PaxScan 4030CB) with a $2048 \times 1536$ pixel array that
performs a $2 \times 2$ binning for a readout of $1024 \times 768$ square pixels
of effective size 0.388 mm. The source and detector are mounted on
robotic arms with the kV beam direction orthogonal to the MV treatment
beam.

#+ATTR_LATEX: :environment longtable :align l|l|l|l|l
#+CAPTION: Subset of Varian's TrueBeam projection header variables pertaining to the kV-imaging system.
#+NAME: tab:opt_varian_header
|-------------+----------------+------------------+--------------------+----------------|
|             | Couch          | Detector         | Gantry             | kV Source      |
|-------------+----------------+------------------+--------------------+----------------|
| Acquisition | CouchLat       | ImagerLat        | GantryAcceleration | Current        |
|             | CouchLng       | ImagerLng        | StartAngle         | FrameRate      |
|             | CouchRtn       | ImagerOrigin     | StopAngle          | KVFilter       |
|             | CouchThickness | ImagerResX       |                    | PulseLength    |
|             | CouchVrt       | ImagerResY       |                    | SAD            |
|             | CouchWidth     | ImagerSizeX      |                    | SID            |
|             |                | ImagerSizeY      |                    | Voltage        |
|             |                | ScatterGrid      |                    |                |
|-------------+----------------+------------------+--------------------+----------------|
| Projection  | CouchLat       | ImagerDeltaLat   | GantryRtn          | SourceAngle    |
|             | CouchLng       | ImagerDeltaLng   |                    | SourceDeltaLat |
|             | CouchRtn       | ImagerDeltaPitch |                    | SourceDeltaLng |
|             | CouchVrt       | ImagerDeltaRtn   |                    | SourceDeltaVrt |
|             |                | ImagerDeltaVrt   |                    |                |
|-------------+----------------+------------------+--------------------+----------------|
***** note                                   :noexport:
 Also, you might write a paragraph that describes how these parameters
 come to you - that the acquired projections are stored in files using
 Varian’s XIM or HND formats, which have extensive headers containing
 dozens of parameters associated with the geometry, x-ray technique,
 and other information concerning each specific image. maybe have a
 table showing examples of a subset of the data from one projection -
 all the couch, detector, source, gantry and x-ray parameters like kV,
 mA, timing, exposure, etc? people not in this field probably have no
 idea this stuff exists. it’s kind of like DICOM but specific to Varian
 images. this could equally well go in the chapter where you describe
 your geometry framework for building the system matrix, and you could
 refer to it here.
*** Varian coordinates
    :PROPERTIES:
    :ID:       9e81dc1a-091f-4614-9d0f-5a5d4ee4f0d1
    :END:
Once the scanning trajectory has been completed, the view-by-view
geometry reported in the projection headers shown in Table
([[ref:tab:opt_varian_header]]) must then be transformed so that it
describes the projection information in the desired image-space basis.
In the case of IGRT, the image-basis of interest to physicians is that
of the patient. As discussed, this requires calculating the correct
transform $\mathcal{T}_{{\text{IEC,patient}}}$ so that the system matrix for
reconstructing into the image space $\left(\mathcal{H'}\right)$ as
described in Equation ([[ref:eq:opt_linmodel_patient]]) can be found.

#+LABEL: fig:opt_coords_rad
#+BEGIN_SRC asymptote :file figures/opt/coords_rad.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(5cm);
addMargins(0.5cm, 0.5cm);

// view configuration
currentprojection=orthographic(100,-300,150,up=Z);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// currentprojection=
//   orthographic(camera=(120,-190,130), up=Z,
//               // target=(-26.8372678113593,40.5411784319797,-16.3591562478052),
//               zoom=0.5,
//               // angle=42.0296556458697,
//               autoadjust=false);

// shift different axes along x in IEC
// real ax_shift = 10;
real ax_scale=50;

// Draw axis
// rad
draw(Label("lng",1),(0,0,0)--(0,ax_scale,0),Arrow3);
draw(Label("vrt",1),(0,0,0)--(ax_scale,0,0),Arrow3);
draw(Label("lat",1),(0,0,0)--(0,0,ax_scale),Arrow3);

draw(Label("gantry",1),(0,ax_scale+50,0)--(0,ax_scale+70,0),red+dashed,Arrow3);

// // kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,vlen,0), (0,0,ulen), det_cent-(0,vlen/2,ulen/2));
triple det0 = det_cent-(0,ulen/2,vlen/2);

// real s=5;
// triple u = (det0+s*(0,1,0));
// triple v = (det0+s*(0,0,1));
// triple w = (det0+s*(-1,0,0));

// // detector coordinate system
// draw(det0--u,blue,Arrow3,L=Label("$u$", position=EndPoint, align=W));
// draw(det0--v,blue,Arrow3,L=Label("$v$", position=EndPoint, align=N));
// draw(det0--w,blue,Arrow3,L=Label("$w$", position=EndPoint, align=S));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
real op=0.2;
draw(detector, blue+opacity(op));
draw(src..det_cent-(0, -vlen/2, -ulen/2),blue+opacity(op));
draw(src..det_cent-(0, vlen/2, -ulen/2),blue+opacity(op));
draw(src..det_cent-(0, vlen/2, ulen/2),blue+opacity(op));
draw(src..det_cent-(0, -vlen/2, ulen/2),blue+opacity(op));
#+END_SRC

#+CAPTION: Radiation coordinate system which is the basis of the projection geometry reported in the projection headers. This coordinate system provides a description of the source position relative to the detector bins with the origin at the imaging isocenter of that view. Though this basis is agnostic of the gantry rotation, the red arrow points into the gantry (into the page here in the same direction as the longitudinal bases (lng)) for reference in images showing the other bases used in this transform.
#+LABEL: fig:opt_coords_rad
#+ATTR_LaTeX: :width 0.75\textwidth
#+RESULTS: fig:opt_coords_rad
[[file:figures/opt/coords_rad.pdf]]

The first coordinate system shown in Figure ([[ref:fig:opt_coords_rad]])
is the radiation coordinate system; a basis in which the projection
headers describe the projective geometry of the source onto the
detector at each view. In this convention, the detector pixels can be
converted into the physical units to describe their location relative
to the source at each projection. As the source and detector rotate
together with the gantry, this basis ignores the gantry rotation angle
$\left(\theta_{g}\right)$ at each view.

#+LABEL: fig:opt_coords_iec
#+BEGIN_SRC asymptote :file figures/opt/coords_iec.pdf :exports results
settings.multisample=0;
settings.prc = false;
settings.render = 0;
settings.outformat="pdf";

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(5cm);
addMargins(0.5cm, 0.5cm);

// view configuration
currentprojection=orthographic(100,-300,150,up=Z);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// shift different axes along x in IEC
// real ax_shift = 10;
real ax_scale=50;

// origin
triple iso=(0, 0, 0);

// gantry rotation
real gtheta=45;
transform3 grot=rotate(gtheta, Y);

// // kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,vlen,0), (0,0,ulen), det_cent-(0,vlen/2,ulen/2));
triple det0 = det_cent-(0,ulen/2,vlen/2);

// real s=5;
// triple u = (det0+s*(0,1,0));
// triple v = (det0+s*(0,0,1));
// triple w = (det0+s*(-1,0,0));

// // detector coordinate system
// draw(det0--u,blue,Arrow3,L=Label("$u$", position=EndPoint, align=W));
// draw(det0--v,blue,Arrow3,L=Label("$v$", position=EndPoint, align=N));
// draw(det0--w,blue,Arrow3,L=Label("$w$", position=EndPoint, align=S));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
real op=0.2;
draw(grot*src..grot*(det_cent-(0, -vlen/2, -ulen/2)),blue+opacity(op));
draw(grot*src..grot*(det_cent-(0, vlen/2, -ulen/2)),blue+opacity(op));
draw(grot*src..grot*(det_cent-(0, vlen/2, ulen/2)),blue+opacity(op));
draw(grot*src..grot*(det_cent-(0, -vlen/2, ulen/2)),blue+opacity(op));

// show grot angle
draw(grot*src..grot*det_cent, red+dashed+opacity(op), Arrow3);

draw(Label("$\theta_g$",position=MidPoint,E),
     arc((0,0,0), (2*ax_scale/3,0,0), grot*(2*ax_scale/3,0,0)), red);

draw(grot*detector, blue+opacity(op));

// Draw axis
// rad
draw(Label("$y_{IEC}$",1),(0,0,0)--(0,ax_scale,0),Arrow3);
draw(Label("$x_{IEC}$",1),(0,0,0)--(ax_scale,0,0),Arrow3);
draw(Label("$z_{IEC}$",1),(0,0,0)--(0,0,ax_scale),Arrow3);

draw(Label("gantry",1),(0,ax_scale+50,0)--(0,ax_scale+70,0),red+dashed,Arrow3);
#+END_SRC

#+CAPTION: the IEC coordinate system that is the global-basis for all the linac geometry. To transform the data in the radiation coordinate system into the IEC coordinate system, the gantry rotation angle is used to rotate each view in the radiation-coordinate basis into the global room coordinates. For a gantry angle of $\theta_{g}=0^{\circ}$, the radiation-coordinate system in Figure ([[ref:fig:opt_coords_rad]]) is the same as the IEC.
#+LABEL: fig:opt_coords_iec
#+ATTR_LaTeX: :width 0.75\textwidth
#+RESULTS: fig:opt_coords_iec
[[file:figures/opt/coords_iec.pdf]]

However, in order to determine the relationship of each projection to
the other views, this radiation coordinate system must be transformed
into a global coordinate system describing the ensemble of projections
relative to the image space. The global coordinate system describing
the TrueBeam room geometry is the International Electrotechnical
Commission (IEC) 61217 coordinate system shown in Figure
([[ref:fig:opt_coords_iec]]). This coordinate system is designated by the
IEC as the standard coordinate system for radiotherapy machines
cite:international_electrotechnical_commission_radiotherapy_2011.

For a gantry angle of $\theta_{g}=0^{\circ}$, the radiation-coordinate system
shown in Figure ([[ref:fig:opt_coords_rad]]) has the same basis as the
radiation coordinate system in Figure ([[ref:fig:opt_coords_rad]]). This
can be used to place the view-by-view header information into the IEC
basis ignoring the gantry rotation initially. Using the IEC basis
vectors $X__{}{\text{IEC}}$, $Y__{}{\text{IEC}}$, and $Z__{}{\text{IEC}}$ shown
in Figure ([[ref:fig:opt_coords_rad]]), the source and detector positions
for that view in homogeneous coordinates are then
\begin{equation}
  \boldsymbol{r}_{\text{src,rad}} = \begin{bmatrix}
    \text{SourceVrt} \\
    \text{SourceLng} \\
    \text{SourceLat} \\
    1
  \end{bmatrix},
  \label{eq:opt_src_rad}
\end{equation}
and
\begin{equation}
  \boldsymbol{r}_{\text{det,rad}} = \begin{bmatrix}
    \text{ImagerVrt} \\
    \text{ImagerLng} \\
    \text{ImagerLat} \\
    1
  \end{bmatrix},
  \label{eq:opt_det_rad}
\end{equation}
respectively. 

To then get these source and position vectors into the correct IEC
position, they are transformed via a rotation around the longitudinal
or $y_{\text{IEC}}$ axis by the gantry angle $\theta_{g}$ which is
\begin{equation}
\mathcal{R}\left(\theta_{g}\right) = \begin{bmatrix}
\text{cos}\left(\theta_{g}\right) & 0 & \text{sin}\left(\theta_{g}\right) & 0 \\
0 & 1  & 0  &  0 \\
\text{-sin}\left(\theta_{g}\right) & 0 & \text{cos}\left(\theta_{g}\right) & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}.
\label{eq:opt_rot_rad_iec}
\end{equation}
By then applying this transform to each projection view geometry in the
radiation coordinate system, we then have
\begin{equation}
  \boldsymbol{r}_{\text{src,IEC}} = \mathcal{R}\left(\theta_{g}\right)
  \boldsymbol{r}_{\text{src,rad}}
  \label{eq:opt_det_iec}
\end{equation}
and
\begin{equation}
  \boldsymbol{r}_{\text{det,IEC}} = \mathcal{R}\left(\theta_{g}\right)
  \boldsymbol{r}_{\text{det,rad}}
  \label{eq:opt_det_iec}
\end{equation}
which are the view-by-view projection geometry in the IEC basis.

At this point, the system matrix $\left(\mathcal{H}\right)$ will
reconstruct into the global IEC room coordinates. In the event that
this is a traditional scanning trajectory where the patient or object
stays at the imaging isocenter, this geometry would be sufficient for
performing a reconstruction. However, to then allow for trajectories
where this fixed isocenter is no longer a requirement, we must perform
one more transform the projection geometry to the basis of the
patient.

#+LABEL: fig:opt_coords_img
#+BEGIN_SRC asymptote :file figures/opt/coords_img.pdf :exports results
settings.multisample=0;
settings.prc = false;
settings.render = 0;
settings."outformat=pdf";

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(5cm);
addMargins(0.5cm, 0.5cm);

// view configuration
currentprojection=orthographic(100,-300,150,up=Z);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// shift different axes along x in IEC
// real ax_shift = 10;
real ax_scale=50;

// origin
triple iso=(0, 0, 0);

// gantry rotation
real gtheta=45;
transform3 grot=rotate(gtheta, Y);

// // kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,vlen,0), (0,0,ulen), det_cent-(0,vlen/2,ulen/2));
triple det0 = det_cent-(0,ulen/2,vlen/2);

// real s=5;
// triple u = (det0+s*(0,1,0));
// triple v = (det0+s*(0,0,1));
// triple w = (det0+s*(-1,0,0));

// // detector coordinate system
// draw(det0--u,blue,Arrow3,L=Label("$u$", position=EndPoint, align=W));
// draw(det0--v,blue,Arrow3,L=Label("$v$", position=EndPoint, align=N));
// draw(det0--w,blue,Arrow3,L=Label("$w$", position=EndPoint, align=S));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
real op=0.2;
draw(grot*src..grot*(det_cent-(0, -vlen/2, -ulen/2)),blue+opacity(op));
draw(grot*src..grot*(det_cent-(0, vlen/2, -ulen/2)),blue+opacity(op));
draw(grot*src..grot*(det_cent-(0, vlen/2, ulen/2)),blue+opacity(op));
draw(grot*src..grot*(det_cent-(0, -vlen/2, ulen/2)),blue+opacity(op));

// show grot angle
draw(grot*src..grot*det_cent, red+dashed+opacity(op), Arrow3);

draw(Label("$\theta_g$",position=MidPoint,E),
     arc((0,0,0), (2*ax_scale/3,0,0), grot*(2*ax_scale/3,0,0)), red+opacity(op));

draw(grot*detector, blue+opacity(op));

// Draw axis
// rad
draw(Label("$y_{IEC}$",1),(0,0,0)--(0,ax_scale,0),dashed+opacity(op),Arrow3);
draw(Label("$x_{IEC}$",1),(0,0,0)--(ax_scale,0,0),dashed+opacity(op),Arrow3);
draw(Label("$z_{IEC}$",1),(0,0,0)--(0,0,ax_scale),dashed+opacity(op),Arrow3);

draw(Label("gantry",1),(0,ax_scale+50,0)--(0,ax_scale+70,0),red+dashed,Arrow3);

// img coordinates
transform3 pshift=shift(-40, -40, -20);

draw(Label("$r_{img}$",position=EndPoint,NW),(0,0,0)--pshift*(0,0,0),red,Arrow3);

draw(Label("$z_{img}$",position=EndPoint,N),pshift*(0,0,0)--pshift*(0,ax_scale,0),Arrow3);
draw(Label("$x_{img}$",position=EndPoint,S),pshift*(0,0,0)--pshift*(ax_scale,0,0),Arrow3);
draw(Label("$y_{img}$",position=EndPoint),pshift*(0,0,0)--pshift*(0,0,-ax_scale),Arrow3);
#+END_SRC

#+CAPTION:  The image or patient coordinate system that will be used as the basis for the reconstruction system matrix $\matchal{H}$ in Equation ([[ref:eq:opt_linmodel_patient]]). By using the view-by-view transform enabled by optimization-based methods, this can incorporates the relative motion of the imaging source and detector as well as the motion of the couch and gantry relative to the point of interest in the patient dentoted by $\boldsymbol{r}_{img}}$.
#+LABEL: fig:opt_coords_img
#+ATTR_LaTeX: :width 0.75\textwidth
#+RESULTS: fig:opt_coords_img
[[file:figures/opt/coords_img.pdf]]

To scan a patient with a trajectory where either the imaging object or
the isocenter itself are changing relative to each other during a
scan, it is then necessary to make an additional transform the
projection geometry into the basis of desired image space. Again, for
IGRT, this is the image space of the patient's treatment volume whose
basis vectors are schematically depicted in Figure
([[ref:fig:opt_coords_img]]).

As an example of this, Figure ([[ref:fig:opt_coords_img]]) illustrates one
view where there is a translation vector ($\boldsymbol{r}_{\text{img}}$) denoting a
transformation of the patient's imaging isocenter away from the
mechanical isocenter of the imaging system. If this offset can be
determined for each projection view, the detector data can be
transformed into the basis of the patient's imaging volume. Though
this transform need not be limited to translation, the form presented
here would then involve a final transform of the form
\begin{equation}
\mathcal{T}_{{\text{img,IEC}}}\left(\theta_{g}\right) = \begin{bmatrix}
  1 & 0 & 0 & -r_{x,IEC} \\
  0 & 1 & 0 & -r_{y,IEC} \\
  0 & 0 & 1 & -r_{z,IEC} \\
  0 & 0 & 0 & 0
\end{bmatrix},
\label{eq:opt_rot_rad_iec}
\end{equation}
and the requisite transform of the system matrix would then be the
necessary transfrom $\mathcal{T}_{\text{IEC,patient}}$ needed to
reconstruct from view-by-view shifts of the image object and the
imaging system into the fixed coordinate system of the patient's image
space. 

As we will show in the following chapters, this framework provides a
very robust way to handle a variety of non-circular trajectories that
have such shifts between the imaging system and the object. In our
work the TrueBeam system, these shifts could arise from motion of the
imaging arms relative to the patient, motion of the patient table, or
even simultaneous motion of both.

**** code                                    :noexport:

** Metric Evaluation
   :PROPERTIES:
   :ID:       bbb809be-d901-4945-b045-bb886cf349bd
   :END:
Though we by no means wish to suggest that this framework is limited
to a particular hardware implementation, or even simply to the purview
of IGRT alone, the TrueBeam system and the practical issues that
currently face the clinic with its use motivated this investigation.
As we present this as a potential solution to some of the limitations
in the clinic, we must demonstrate that in bringing the benefits of
these new trajectories, we are not adversely impacting the subsequent
image quality. We emphasize that image quality alone cannot ultimately
determine the true value of any particular imaging modality or
technique.

It is imperative that for any translation of novel technology to a
clinical setting to occur, rigorous clinical studies must be performed
to determine the true impact any technology has on the real metric of
performance which is the task-based utility. How that is defined is
itself a challenging component in any field, but in medicine this must
be given consideration to the patient outcome.

Image quality is itself one component of the myriad factors that must
be considered when evaluating a clinical technique. As we discuss this
framework of reconstructing from non-circular trajectories with
optimization-based reconstruction, we will use image quality as a
surrogate for clinical utility. Though the trajectories we will look
at were formulated to address practical limitations of the current
state of the art, the benefits to the clinical workflow must
eventually be evaluated with the ultimate patient outcome. What we do
posit is that if the framework can achieve reconstructions with image
quality that is comparable to existing techniques that have already
met the stringent clinical evaluation criteria, then the additional
benefits allowed by the non-circular trajectories truly do have the
potential to improve clinical utility.

As we look at some examples of different scanning trajectories that
could be beneficial to the IGRT clinical workflow, we will use some of
the following image quality metrics to compare reconstructions using
this framework to the images of existing clinical techniques. We have
attempted to select metrics based on existing clinical phantoms and
image quality phantoms so as to reflect the potential image quality of
these methods were they to be used clinically. Though some of the uses
cases provide scanning configurations for which clinical image quality
phantoms do not exist, we tried to use phantoms with direct clinical
relevance.

#+CAPTION: Schematic from the Catphan manual of the the CTP 404 sensitometry module which features a variety of different electron density inserts which can be used for contrast and CT number analysis as well as beads and wires for extracting spatial resolution metrics.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:opt_ctp404
[[file:figures/opt/catphan_ctp404.png]]

The majority of the quantitative metrics we present come from scans of
the Catphan 504 (The Phantom Laboratory, Salem, NY). This is a
standard quality assessment (QA) phantom for clinical CT devices that
provides a series of sections with different objects for calculating
image quality metrics. We used the CTP 404 sensitometry module shown
in Figure ([[ref:fig:opt_ctp404]]) and the CTP 528 spatial resolution
module shown in Figure ([[ref:fig:opt_ctp528]]).

There are a number of ways to evaluate the spatial resolution from
images of the Catphan phantom in a CT image. The CTP 528 module
contains a circular array of bar patterns which we used to
subjectively determine the highest frequency set which is resolvable.
The same module also has two 0.28mm tungsten carbide beads simulating
an impulse source from which a point spread and then modulation
transfer function (MTF) can be determined. Furthermore, the MTF can be
calculated from the bar patterns themselves
cite:droege_practical_1982, as well as any suitably high contrast edge
in the image cite:rossmann_point_1969.

#+CAPTION: Schematic from the Catphan manual of the CTP 528 module that provides a bar-pattern phantom for evaluating spatial resolution metrics.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:opt_ctp528
[[file:figures/opt/catphan_ctp528.png]]

While the use of MTF in CT has its challenges, notably the assumption
of shift-invariance is not satisfied, it still can be useful when
treated with some care. Each of the methods above has some advantages
and disadvantages. The point source method can provide 3D directional
estimates of the point-spread function (PSF), however it can also be
sensitive to the location of the bead relative to the image grid with
significant difference between a bead located totally within a single
voxel or on the interface of many. The bar pattern based evaluation is
a clear complement to the visual analysis, however the orientation of
the bars relative to the grid will affect some frequencies differently
than others which can result in atypical appearing MTF curves. Using
an edge spread analysis on the circular phantom boundary provides many
samples, at varying directions to the image grid which can be averaged
out. It can be impacted by scatter or saturation in the air region
near the phantom boundary, however this has not proven to be a
significant factor in the images we have analyzed.

The image slice for analysis, the central slice here, is first
thresholded based on the image intensity, the connected component with
area of the appropriate size is isolated and any holes in the
thresholded region are filled. The center of this region is taken as
the phantom center and used as the origin of the coordinates for
analysis. The data are then resampled at high density, along radial
spokes at 8 angles chosen to avoid surface alignment marks, using a
linear interpolant from 5 mm inside to 5 mm outside the surface
boundary. The edge-spread function is then the mean $(\mu(X))$
subtracted profile over the standard deviation $(\sigma(X))$, or
\begin{equation}
\text{ESF} = \frac{X-\mu(X)}{\sigma(X)}.
\end{equation}
In standard form, the line-spread function (LSF) can be computed from
the derivative of the edge-spread function (ESF),
\begin{equation}
\text{LSF} = \frac{d}{dX}\text{ESF},
\end{equation}
and the MTF as the discrete fourier transform $(\mathcal{D})$ of the
LSF,
\begin{equation}
\text{MTF} = \mathcal{D}(\text{LSF})
\end{equation}

To characterize low-contrast resolution, we calculated the
contrast-to-noise ratio (CNR) using the polystyrene insert in the CTP
404 sensitometry module. These inserts have CT numbers which are the
closest to the water-like polymer that surrounds them. The metric is
defined as
\begin{equation}
\label{eq:lcv}
\text{CNR} = \frac{2\left|\mu_{\text{roi}}-\mu_{\text{bkg}}\right|}{\sigma_\text{roi}+\sigma_\text{bkg}}
\end{equation}
where $\sigma$ represents the standard deviation and $\mu$ the mean of the of
the pixel values in the respective regions.

The last metric we evaluated was the reproducibility of the CT numbers
in the images from the different scanning trajectories we
investigated. For this we used the mean and standard deviations in
ROIs for all the material inserts of the Catphan CTP 404 sensitometry
module in addition to the polystyrene and background ROIs used for the
low-contrast CNR calculations. We also evaluated three additional ROIs
of the water-like background for a total of four background ROIs.

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[height=1.75in]{figures/opt/cirs/cross_sectioned.jpg}
  \caption{}
  \label{fig:opt_cirs_sec}
\end{subfigure}
\qquad %add desired spacing between images, e. g. ~, \quad, \qquad,
% \hfill etc.
% (or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[height=1.75in]{figures/opt/cirs/ed_setup.jpg}
  \caption{}
  \label{fig:opt_cirs_setup}
\end{subfigure}
\caption{The CIRS torso phantom. On the left is a picture of the
  phantom broken apart so that the cross-sectional composition of the
  slices is visible. The anthropomorphic phantom is designed to
  provide soft-tissue organ structures with realistic electron
  densities. The image on the right shows the phantom setup on the
  linac treatment couch.}
\label{fig:opt_cirs}
\end{figure}

#+END_EXPORT

In addition to the CTP 504 Catphan modules, we also used the CIRS
model 600 torso phantom shown in Figure ([[ref:fig:opt_cirs]]) to evaluate
these trajectories with this non-circular scanning trajectory
configuration. Though we primarily used this anthropomorphic phantom
to produce clinically-relevant reconstructions in the use-case we
envisioned for these proposed trajectories, we also extracted CT
numbers from ROIs in some of the soft-tissue organs corresponding to
aorta, liver and spleen in the phantom's abdomen.
** Conclusion
As our framework was developed in the context of addressing current
limitations of using CBCT for IGRT, we wanted to evaluate the image
quality obtained from examples of real-data scans of such non-circular
trajectories to address two existing clinical issues. To do this, we
use our framework to build the necessary reconstruction geometry
transforms for the TrueBeam system and selected image quality metrics
from standard clinical phantoms for comparing reconstructions from
this framework against current clinical image quality. In the next two
chapters, we will look at two specific examples of two types of
non-circular trajectories that address two existing limitations and
compare the subsequent image quality to the current clinical standard.
** ideas                                     :noexport:
Given that part of the robust nature of optimization-based algorithms
is the ability to handle the poorly-conditioned nature of the inverse
problem...
* Geometric calibration                      :geo:
  :PROPERTIES:
  :ID:       652970b8-4916-4190-b83b-2d6ae117c8b3
  :END:
** notes                                     :noexport:
   :PROPERTIES:
   :ID:       5c9cdd8b-721f-49b3-b136-c3282bf3659c
   :END:
** Introduction
   :PROPERTIES:
   :ID:       26feb0f0-f33e-4972-af9c-f73e0124f074
   :END:
Correctly modeling the geometric parameters of the image acquisition
is a critical component of tomographic image reconstruction. This is
true regardless of whether reconstruction is done with analytic-based
or optimization-based methods. Any inconsistency between the real
projection geometry and that used for image reconstruction creates
artifacts in the reconstructed image
cite:rougee_geometrical_1993,fahrig_three-dimensional_2000,noo_analytic_2000,smekal_geometric_2004,cho_accurate_2005,yang_geometric_2006,panetta_optimization-based_2008,daly_geometric_2008,li_generic_2010,wicklein_image_2012.
An example of such an artifact is shown in Figure
([[ref:fig:geo_cal_catphan_example]]). This is no less true when using
non-standard scanning trajectories. Thus we developed a calibration
procedure that can accommodate the different scanning configurations
including non-standard scanning trajectories and scenarios in which
the object, source and detector are all moving during the scan.

#+BEGIN_EXPORT latex
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/geo/catphan_virt_1p5x_nocal.png}
    \caption{}
    \label{fig:geo_virt_catphan_nocal}
  \end{subfigure}
  ~ %add desired spacing between images, e. g. ~, \quad, \qquad,
  % \hfill etc.
  % (or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/geo/catphan_virt_1p5x_cal.jpg}
    \caption{}
    \label{fig:geo_virt_catphan_cal}
  \end{subfigure}
  \caption{Transverse slice of the Catphan 504 phantom. The image on
    the left is reconstructed without geometric calibration, and the
    image on the right is constructed with geometric calibration. The
    arrow in red indicates one example of the geometric distortion
    incurred by incorrectly modeling the scanning geometry. This
    blurring and subsequent loss of spatial resolution is a typical
    consequence of poor geometric calibration.}
  \label{fig:geo_cal_catphan_example}
\end{figure}
#+END_EXPORT

Previous work on geometric calibration for tomographic image
reconstruction has approached the calibration problem via analytic
cite:noo_analytic_2000,smekal_geometric_2004,cho_accurate_2005,yang_geometric_2006,daly_geometric_2008
and estimation
cite:gullberg_estimation_1990,rougee_geometrical_1993,mitschke_optimal_2000,silver_determination_2000,panetta_optimization-based_2008
frameworks. Initial calibration efforts utilized optimization-based
methods to determine the geometric offsets from projections of a known
phantom geometry and nominal system setup. By framing the calibration
as an optimization problem, the acquisition parameters were estimated
in a way that minimized a cost function associated with improper
modeling of the acquisition geometry.

These calibration methods (analytic-based methods included) usually
rely on a known calibration phantom, which is typically a set of
highly attenuating fiducials arranged in a specific pattern. After
scanning the phantom with the system of interest, the detected
fiducials are then compared to predicted positions based on the known
geometry of the phantom and the nominal projection geometry. In the
analytic-based approach, the view parameters are determined by solving
for parameters that would transform the projection of the phantom to
match the observed projection. In the optimization-based approach,
geometric parameters are varied to improve the match between the
projection of the modeled fiducials and the detected fiducials in the
sinogram.

Both methods of performing geometric calibration have their own
strengths and weaknesses. The biggest advantage of utilizing
analytic-based calibration methods is that the sensitivity to
initialization and the sensitivity to the order of parameter variation
due to nonlinearity and coupling of parameters faced by estimation are
avoided cite:smekal_geometric_2004. However, as with
optimization-based reconstruction, optimization-based calibration
methods are more flexible in providing calibration offsets for the
novel trajectories that we studied.

Using previous work for optimization-based geometric calibration
cite:rougee_geometrical_1993,gullberg_estimation_1990,silver_determination_2000,
we developed a calibration method that utilizes a phantom with known
placement of highly attenuating fiducials. By scanning this phantom
and comparing the projections to the modeled forward-projection of a
mathematical model of the phantom, we can more accurately determine
the system matrix $(\mathcal{H})$ in Equation
([[ref:eq:opt_linmodel_patient]]) for reconstructing from a non-circular
scanning trajectory with optimization-based methods resulting in
reduced image artifacts.

** Methods
   :PROPERTIES:
   :ID:       0b636fe5-fe45-4f10-a5fc-2de8a82bfbe4
   :END:
Where analytic-based methods, such as FDK, require a certain
acquisition trajectory such as a fixed scanning radius of the source
and detector and the angular position of each projection, the
optimization-based system matrix makes no assumptions of the geometry
in other views. As such, we created a reconstruction framework that
incorporates the best geometric estimate of the projection geometry
from each view. The flexibility to incorporate geometric corrections
in this way is another useful aspect in using optimization-based
methods for image reconstruction.

Before attempting to determine any geometric errors in our scanning
acquisition, we first modified the calculation of our system matrix to
incorporate the geometry information provided by the TrueBeam system
as discussed in [[id:9e81dc1a-091f-4614-9d0f-5a5d4ee4f0d1][Varian coordinates]]. In doing this, we took advantage
of all the inherent geometry information that is provided with the
current clinical system. This information then provided an initial
estimate of the scanning geometry which we could then refine with the
calibration information we extracted with our calibration protocol.
*** Phantoms
    :PROPERTIES:
    :ID:       F5BECB45-8652-47A3-915C-1E96DA6110E7
    :END:
The first calibration phantom we fabricated for determining geometric
offsets is shown in Figure (\ref{fig:geo_geocal}). The phantom is a
15.2 cm outer diameter acrylic tube with a spiral pattern of CT-spot
fiducials placed 2.5 cm along the axial direction every $45^{\circ}$.
When scanned, the CT spots are clearly visible in the projection
images which is ideal for automating the fiducial detection in the
data domain.

However, we realized that using such a spiral calibration phantom
creates a degree of ambiguity in the geometry of the projected
fiducials. With both this phantom and additional calibration phantoms
we created, too much symmetry in the phantom design leads to a rather
challenging objective function. Given that only a small portion of the
phantom is visible in any one projection view, excessive symmetry
produces multiple minima in the objective function where a simple
axial shift and rotation offset allows for multiple matches of the
modeled fiducials and those in the real data. To avoid such
complexity, a calibration phantom with intentional asymmetry is
desirable so that the projected fiducials can be indentified and
matched without ambiguity.

In addition to the necessary complexity created by this phantom,
another concern for a calibration phantom is the uncertainty in the
geometry of the phantom itself. Though the guide lines on the cylinder
were inscribed with the lathe and its rotational stage, we placed the
fiducials by hand. As we were trying to determine millimeter offsets
with our calibration, this fiducial placement was suboptimal.

#+CAPTION: Initial geometric calibration phantom with a spiral fiducial pattern.
#+ATTR_LaTeX: scale=0.75
#+LABEL: fig:geo_geocal
[[../../research/trajectories/geometry/geocal/20140901_extended_cllc.jpg]]

The phantom we then decided to use for calibration was the Isocal
phantom created by Varian shown in Figure ([[ref:fig:geo_isocal]]).
Additionally, the phantom is manufactured by Varian to help align the
MV-treatment isocenter with the kV-imaging isocenter. The Isocal
phantom directly addresses the two problems encountered with our first
phantom. First, the phantom is designed with intentional asymmetry.
The position of the beads on this phantom have a much tighter
tolerance than that of our original phantom.

#+CAPTION: Varian's Isocal phantom positioned at the isocenter.
#+ATTR_LaTeX: scale=0.75
#+LABEL: fig:geo_isocal
[[../../research/phantoms/isocal/imgs/161012_isocal.jpg]]

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{figures/geo/old_geocal_full_1701x1024x768}
  \caption{}
  \label{fig:geo_oldcal_proj}
\end{subfigure}
~ %add desired spacing between images, e. g. ~, \quad, \qquad,
% \hfill etc.
% (or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{figures/geo/isocal_full_914x1024x768}
  \caption{}
  \label{fig:geo_isocal_proj}
\end{subfigure}
\caption{(a) shows a projection of our first calibration phantom
  consisting of a single spiral of fiducials around the acrylic tube.
  (b) shows a projection of Varian's isocal calibration phantom. The
  additional fiducials seen in each projection, and their unambiguous
  layout in the projection help prevent local minima when searching
  for correct geometry offsets}
\label{fig:geo_cal_sens_cost}
\end{figure}
#+END_EXPORT

*** Calibration method
    :PROPERTIES:
    :ID:       F53F4B5A-83EB-4B16-9B6D-F557D3E441C2
    :END:
We designed a calibration procedure specifically for the non-standard
scanning trajectories we implemented on the TrueBeam system with
Developer Mode. Using the methods described in the section [[id:58A6E225-522B-4620-BEDB-F81AD30070C3][/Framework
implementation with Varian TrueBeam kV-CBCT system/]], we used the
view-by-view header information from the TrueBeam system to initialize
our calibration procedure. Starting with this initial estimate with
which we calculated our reconstruction system matrix $\mathcal{H}$,
the additional information extracted from our calibration was used to
improve the estimate of both the system matrix and subsequently the
estimated image from the reconstruction.

# *uml flow chart*

#+BEGIN_UML

#+END_UML

Figure ([[ref:fig:geo_cal_schematic]]) provides a schematic illustration
of the Isocal phantom for a single view. Ideally, the nominal geometry
used to calculate a single projection would produce the simulated
projected fiducials in blue. However, as both our work and that of
others has found, this is not usually the case
cite:rougee_geometrical_1993,noo_analytic_2000,smekal_geometric_2004,cho_accurate_2005,yang_geometric_2006,li_generic_2010,wicklein_image_2012.
Discrepancies between the reported geometry and the actual scanning
geometry can arise from multiple sources in a given acquisition.

With a typical CBCT scan, deviations from the nominal geometry can
occur in both the phantom's setup (translation and rotation in all
three dimensions) as well as that of the source and detector positions
(due to translation and rotation deviations in the gantry, source, and
detector). The collective impact of these various discrepancies will
produce projection views for which the projected fiducials in the data
domain do not match the simulated projections from the nominal
geometry as shown by the red projected fiducials in Figure
([[ref:fig:geo_cal_schematic]]).

#+NAME: fig:geo_cal_schematic
#+BEGIN_SRC asymptote :file figures/geo/cal_schematic.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(10cm);
currentprojection=orthographic(-15,5,13,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// Draw axis
// draw(Label("$y$",1),(0,0,0)--(0,5,0),red,Arrow3);
// draw(Label("$x$",1),(0,0,0)--(5,0,0),red,Arrow3);
// draw(Label("$z$",1),(0,0,0)--(0,0,5),red,Arrow3);

// kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,ulen,0), (0,0,vlen), det_cent-(0,ulen/2,vlen/2));

triple det0 = det_cent-(0,ulen/2,vlen/2);
real s=5;
triple u = (det0+s*(0,1,0));
triple v = (det0+s*(0,0,1));
triple w = (det0+s*(-1,0,0));

// detector coordinate system
draw(det0--u,blue,Arrow3,L=Label("$u$", position=EndPoint, align=W));
draw(det0--v,blue,Arrow3,L=Label("$v$", position=EndPoint, align=N));
draw(det0--w,blue,Arrow3,L=Label("$w$", position=EndPoint, align=S));

draw(detector, blue);

// path3 det180 = rot180*detector;
// path3 det270 = rot270*detector;

// uncal detector coordinate system
transform3 det_pitch=rotate(-5, det_cent, det_cent+(-1,0,0));
transform3 det_roll=rotate(-5, det_cent, det_cent+(0,0,1));
transform3 det_yaw=rotate(5, det_cent, det_cent+(0,-1,0));
transform3 det_shift=shift(5, -8, 2);

path3 detector_uncal = det_pitch*det_roll*det_yaw*det_shift*detector;
path3 det_cent_uncal = det_pitch*det_roll*det_yaw*det_shift*det_cent;
// path3 detector_uncal = det_shift*detector;
// path3 det_cent_uncal = det_shift*det_cent;
real op_uncal=0.35;
draw(detector_uncal, red+opacity(op_uncal));

// labels
//From Charles Staats's tutorial
//Direction of a point toward the camera.
triple cameradirection(triple pt, projection P=currentprojection) {
  if (P.infinity) {
    return unit(P.camera);
  } else {
    return unit(P.camera - pt);
  }
}

//Move a point closer to the camera.
triple towardcamera(triple pt, real distance=1, projection P=currentprojection) {
  return pt + distance * cameradirection(pt, P);
}

// label("$\theta=0^{\circ}$",red,align=S,position=towardcamera((det_cent-(0, ulen/2, -vlen/2))));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// uncal source
// triple src_uncal=shift(0,10,5)*(svrt,slat, slng);

// lines from source to detector edges
draw(src..det_cent-(0,-ulen/2,-vlen/2),blue+opacity(0.15));
draw(src..det_cent-(0,-ulen/2,vlen/2),blue+opacity(0.15));
draw(src..det_cent-(0,ulen/2,vlen/2),blue+opacity(0.15));
draw(src..det_cent-(0,ulen/2,-vlen/2),blue+opacity(0.15));

draw(Label("$X_{\theta_g=0^{\circ}}$", 1),src--det_cent-(110,0,0), blue, arrow=Arrow3);

// transformed frame vectors
triple det0_uncal = point(detector_uncal, 0);
triple u_p = point(detector_uncal, 1) - det0_uncal;
triple v_p = point(detector_uncal, 3) - det0_uncal;

// unit vectors
triple uhat_p = u_p / length(u_p);
triple vhat_p = v_p / length(v_p);
triple what_p = cross(uhat_p, -vhat_p);

// scale
triple u_p = s*uhat_p + det0_uncal;
triple v_p = s*vhat_p + det0_uncal;
triple w_p = s*what_p + det0_uncal;

// uncalibrated detector coordinate system
draw(det0_uncal--u_p,red,Arrow3,L=Label("$u'$", position=EndPoint, align=SE));
draw(det0_uncal--v_p,red,Arrow3,L=Label("$v'$", position=EndPoint, align=S));
draw(det0_uncal--w_p,red,Arrow3,L=Label("$w'$", position=EndPoint, align=S));

// draw(point(detector_uncal, 1)--src, red+opacity(0.15));
// real arrowlength = 5
// vector v_p=new path(real x){
//     return point(detector_uncal, 1)--arrowlength*(-1)*point(detector_uncal, 2));
// };

// draw(v_p)
// draw(point(detector_uncal, 1)--point(detector_uncal, 2),red, arrow=Arrow3);

// // and for real projection
// draw(src_uncal..point(detector_uncal, 0), red+opacity(0.15));
// draw(src_uncal..point(detector_uncal, 1), red+opacity(0.15));
// draw(src_uncal..point(detector_uncal, 2), red+opacity(0.15));
// draw(src_uncal..point(detector_uncal, 3), red+opacity(0.15));

// draw(Label("$\mathcal{H}$", 1),src--det_cent_uncal, red, arrow=Arrow3);

// Draw cylinder
// cylinder(startpoint3d, radius, length, along_this_axis)
triple start = (0,0,-8);
real length = 16;
real radius = 11.3;
triple ax = (0,0,1);
revolution r = cylinder(start,radius,length,ax);
draw(r,black);

// isocal spots
triple[] isocal={(0,-11.3,-7.5),
                 (7.9903,-7.9903,-7.5),
                 (7.9903,7.9903,-7.5),
                 (-11.3,0.0,-7.5),
                 (-7.9903,7.9903,-5),
                 (11.3,0.0,-3),
                 (0,11.3,-2),
                 (-10.4398,4.3243,2),
                 (4.3243,10.4398,3),
                 (-10.4398,-4.3243,5),
                 (4.3243,-10.4398,5),
                 (10.4398,-4.3243,7.5),
                 (10.4398,4.3243,7.5),
                 (-4.3243,10.4398,7.5),
                 (-4.3243,-10.4398,7.5)
};

dot(isocal, black);

// project points
transform3 proj=planeproject(detector);
transform3 proj_uncal=planeproject(detector_uncal);
// transform3 proj090=planeproject(det090);
// transform3 proj180=planeproject(det180);
// transform3 proj270=planeproject(det270);

dot(proj*isocal,blue);
dot(proj_uncal*isocal,red+opacity(op_uncal));
// dot(proj090*isocal,red);
// dot(proj180*isocal,red);
// dot(proj270*isocal,red);
#+END_SRC

#+CAPTION: Schematic represenation of a single projection view for the isocal phantom with the TrueBeam kV-CBCT scanning geometry. The blue detector and projected isocal fiducials correspond to the self-reported geometry from the imaging system. The red detector and projected fiducials illustrate how translation and rotation offsets of both the phantom and the source-detector system create variations in the projected fiducials in the sinogram space. The bottom left corner corresponds to the origin of the detector coordinate system. The detector's translation and rotation offsets are exaggerated here for illustrative purposes.
#+LABEL: fig:geo_cal_schematic
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS: fig:geo_cal_schematic
[[file:figures/geo/cal_schematic.pdf]]

Starting with the nominal scanning geometry reported by the projection
metadata, we first build an initial projection matrix $\boldsymbol{X}$
that transforms the simulated phantom fiducials in room coordinates to
projected spots in detector coordinates. The matrix $\boldsymbol{X}$
is calculated using the variables describing each view shown in Figure
([[ref:fig:geo_cal_proj]]). The source and detector (including the
detector's frame vectors $\left\{ \hat{u}, \hat{v}, \hat{w} \right\}$)
are rotated into the global image space by rotating these vectors by
the gantry angle $\left( \theta_{g} \right)$ at each view. The gantry rotation
axis is the logitudinal axis of the cylinder in Figure
([[ref:fig:geo_cal_schematic]]) and the $y$ axis in Figure
([[ref:fig:geo_cal_proj]]).

Projection of the fiducial coordinates onto the detector needs to be
done in a coordinate system aligned with the detector’s frame vectors.
The source-to-detector distance needed for projection is the distance
along a direction normal to the detector plane, i.e. parallel to the
frame vector $w$. The normal distance from source to detector is
calculated by first choosing a ray connecting the source to the
detector, $\vec{r}_{\text{sd}}$. The component of this ray that is
orthogonal to the detector is then found using the dot product
\begin{equation}
  L=\vec{r}_{sd}}\cdot \hat{w},
  \label{eq:geo_along}
\end{equation}
where the frame vector $\hat{w}$ corresponds to the detector's normal
unit vector. This then provides the vector describing the piercing
point $\left( \vec{p} \right)$ at that view which is given by
\begin{equation}
  \vec{p}=\vec{r}_s+L \hat{w},
  \label{eq:geo_pierce}
\end{equation}
where $\vec{r}_s$ is the vector corresponding to the source position in
the image coordinates for that view.

#+NAME: fig:geo_cal_proj
#+BEGIN_SRC asymptote :file figures/geo/cal_proj.pdf :exports results
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;

import graph3;
import geometry;
import solids;
import three;

// view configuration
size(10cm);
currentprojection=orthographic(-15,10,20,up=Y);
// currentprojection=perspective(-15,5,13,up=Y);
// currentlight=White;

// Draw axis
real ax_scale=15;
draw(Label("$z$",position=EndPoint,align=N),(0,0,0)--(0,ax_scale,0),black,Arrow3);
draw(Label("$x$",position=EndPoint,align=S),(0,0,0)--(ax_scale,0,0),black,Arrow3);
draw(Label("$y$",position=EndPoint,align=SW),(0,0,0)--(0,0,-ax_scale),black,Arrow3);

// show gantry angle
draw(Label("$\theta_{g}$", (2, -0.5, 0)), arc((0, 0, 0), (ax_scale/3, 0, 0), (0, -ax_scale/3, 0)), red, arrow=Arrow3);

// kV schematic
real dlat=-13, dlng=0, dvrt=50;
triple det_cent=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,ulen,0), (0,0,vlen), det_cent-(0,ulen/2,vlen/2));

triple det0 = det_cent-(0,ulen/2,vlen/2);
triple u = (det0+ax_scale/2*(0,1,0));
triple v = (det0+ax_scale/2*(0,0,1));
triple w = (det0+ax_scale/2*(-1,0,0));

// detector norm
triple dnorm = (det_cent+ax_scale*(-1,0,0));

// detector coordinate system
draw(det0--u,black,Arrow3,L=Label("$u$", position=EndPoint, align=W));
draw(det0--v,black,Arrow3,L=Label("$v$", position=EndPoint, align=N));
draw(det0--w,black,Arrow3,L=Label("$w$", position=EndPoint, align=N));

draw(detector, black);

// labels
//From Charles Staats's tutorial
//Direction of a point toward the camera.
triple cameradirection(triple pt, projection P=currentprojection) {
  if (P.infinity) {
    return unit(P.camera);
  } else {
    return unit(P.camera - pt);
  }
}

//Move a point closer to the camera.
triple towardcamera(triple pt, real distance=1, projection P=currentprojection) {
  return pt + distance * cameradirection(pt, P);
}

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
draw(src..det_cent-(0,-ulen/2,-vlen/2),black+opacity(0.15));
draw(src..det_cent-(0,-ulen/2,vlen/2),black+opacity(0.15));
draw(src..det_cent-(0,ulen/2,vlen/2),black+opacity(0.15));
draw(src..det_cent-(0,ulen/2,-vlen/2),black+opacity(0.15));

// ray connecting the source to the detector
triple ray_sd = det_cent-src;
draw(L=Label("$\vec{r}_{sd}$", position=EndPoint, align=E), src--det_cent, blue, Arrow3);

// dot product of ray onto normal vecotr
real along = dot(ray_sd, dnorm);

// detector projection operator
transform3 proj=planeproject(detector);

// show pierecing point
triple pierce = proj*src;

draw(L=Label("$\vec{p}$", position=EndPoint, align=NW),src--pierce,blue+dashed,arrow=Arrow3);
draw(L=Label("$\vec{p}_{uv}$", position=EndPoint, align=SE),det_cent--pierce,red+dashed,arrow=Arrow3);
// draw(src--pierce,red+dotted, arrow=Arrow3);
#+END_SRC

#+CAPTION: Schematic of a single projection view and the associated variables used in building the projective transform matrix $\left( \boldsymbol{X} \right)$ for that view. The $\left\{x, y, z \right\}$ coordinate system corresponds to the standard IEC global coordinate system, and the $\left\{u, v, w \right\}$ coordinate system corresponds to the detector frame vectors for that view. The red arrow labeled by $\theta_g$ denotes the gantry rotation angle which is defined from the $x$ axis as shown here for the kV imaging system. The blue vector $\vec{r}_{sd}$ points from the source to the detector center, and the blue vector $\vec{p}$ shows the piercing point of the x-ray source on the detector. The red vector $\vec{p}_{uv}$ corresponds to the piercing point in the detector basis as calculated in Equation ([[ref:eq:geo_pierecuv]]).
#+LABEL: fig:geo_cal_proj
#+ATTR_LaTeX: :width 0.9\textwidth
#+RESULTS: fig:geo_cal_proj
[[file:figures/geo/cal_proj.pdf]]

With this new piercing point, it is possible to now construct a
transform that projects the fiducials as well as transforms them to
the detector basis. The transform to the detector basis is represented
by the homogeneous coordinate transform
\begin{equation}
  \boldsymbol{G} = \begin{bmatrix}
    u_i & u_j & u_k & -r_{s,x} \\
    v_i & v_j & v_k & -r_{s,y} \\
    w_i & w_j & w_k & -r_{s,z} \\
    0 & 0 & 0 & 1
  \end{bmatrix}.
  \label{eq:geo_gmat}
\end{equation}
where $\left[-r_{{s,x}}, -r_{{s,y}}, -r_{{s,z}} \right]$ are the
room-coordinate components of the source position. Then using the
orthogonal ray component found in Equation ([[ref:eq:geo_along]]), the
homogeneous coordinate projection matrix is
\begin{equation}
  \boldsymbol{P} = \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & \frac{1}{L}  \\
    0 & 0 & 0 & 0
  \end{bmatrix}.
  \label{eq:geo_pmat}
\end{equation}
Using these transforms so that they are pre-multiplied by the fiducial
position vectors, the combined transform is then
\begin{equation}
  \boldsymbol{M} = \boldsymbol{G}\boldsymbol{P}.
  \label{eq:geo_magicmat}
\end{equation}
which transforms a room coordinate point into the detector basis, and
then projects it onto the detector plane.

Finally, this information can be combined to create a single transform
of the fiducials in the global image coordinate system to the
projected spots on the detector in discretized detector bin
coordinates. First, the coordinates of the piercing point must be
calculated in the detector basis as
\begin{equation}
  \vec{p}_{uv} = \left(\vec{p}-\vec{r}_d\right)\boldsymbol{G},
  \label{eq:geo_pierecuv}
\end{equation}
where $\vec{r}_d_{}$ is the center of the detector in room coordinates.
With all this, the projection transform used to calculate the
projected fiducials in discretized detector bin coordinates is
\begin{equation}
  \boldsymbol{X} = \boldsymbol{M}\boldsymbol{T} (\vec{p}_{uv})
  \boldsymbol{S}\left( \left[\frac{1}{s_{\text{pix}}},
    \frac{1}{s_{\text{pix}}}, 1 \right]\right) \boldsymbol{T} \left(
  \left[\frac{u_{\text{len}}}{2}+0.5, \frac{v_{\text{len}}}{2}+0.5, 0
    \right] \right),
  \label{eq:geo_xproj}
\end{equation}
where $\boldsymbol{S}$ is a scaling transformation along the $\left\{
u,v \right\}$ basis by the inverse of the pixel size $\left(
s_{{\text{pix}} \right)$, and \boldsymbol{T} is a translation
transformation to place the origin of the discretized detector basis
at the center of the corner pixel.

With the projection transform $\boldsymbol{X}$, each vector
corresponding to the fiducials on the Isocal phantom can be projected
onto the discretized detector basis as illustrated in Figure
([[ref:fig:geo_cal_schematic]]). These projected spots are then matched to
the detector spots in the real sinogram. The $L_2$ norm between the
real and simulated projected spots is then calculated and serves as
the cost function for the optimization-based calibration.

As with other optimization-based calibration procedures, we
iteratively vary the parameters corresponding to the geometric degrees
of freedom (DOF) of the scanning trajectory. The phantom pose
(position and orientation) is first allowed to vary in the room
coordinate system to account for potential setup errors between the
room coordinates and the modeled position of the phantom. Once the
pose of the Isocal phantom is identified, then the source, detector,
and patient couch translations and rotations are allowed to vary, and
the cost of the simulated fiducial projections are calculated at each
step. We use the Nelder-Mead simplex algorithm
cite:lagarias_convergence_1998 to minimize the $L_{2}\text{-norm}$ cost
function.

Given that there are there are different combinations of couch, source
and detector motions that can cause the same change of the object
relative to the source and detector within the image coordinate
system, there are some degrees of freedom that can couple with others.
For instance, shifting the patient in the positive longitudinal
direction is effectively the same as allowing the source and detector
to move the same distance in the negative longitudinal direction. This
requires that only a few parameters are allowed to vary at once as
allowing too many parameters on this non-convex surface will often
produce nonphysical geometric corrections. Once the cost has been
minimized, the geometric offsets are used as the calibration
information for calculating the system matrix $\mathcal{H}$ for the
image reconstruction.

For a new trajectory, this phantom is first scanned to identify any
potential corrections to the parameters reported in the TrueBeam data
headers. Though we find the self-reported position from the
acquisition metadata to be very accurate, there are still some scanning
configurations for which the additional refinement from our geometric
calibration is critical for obtaining the best quality reconstruction.
This is particularly true for scanning trajectories where the object
and the kV imaging system move simultaneously.
*** Geometric-offset artifact catalog        :noexport:
    :PROPERTIES:
    :ID:       DED4A0A6-3775-41ED-AF64-BD6604B2B3AD
    :END:
Though the type of artifacts that are introduced by geometric offsets
for circular scanning trajectories are relatively well known, this
same sort of understanding is lacking for these new trajectories. To
study how geometric offsets affect images reconstructed from these new
trajectories, we will create a simulation catalog of artifacts
produced by different geometric errors. By introducing intentional
geometric inconsistencies in the reconstruction system matrix, we can
characterize the artifacts that appear in the reconstruction compared
to a numerically-exact inverse crime reconstruction.

As one of our primary objectives in using these novel trajectories is
to create an extended axial FOV image, we need to study how these
geometric errors degrade the image quality along the axial
direction. To ensure our simulation can adequately identify these
artifacts, we will create a simulated phantom such as an axially
extended version of the Catphan high resolution module. This will
provide resolution metrics not only in the axial dimension, but also
in the transverse planes as a function of axial position.

The simulation catalog of different artifacts that arise from
geometric offsets will provide a guide to visually identify potential
geometric errors based on the reconstructed image. This provide one
way in which we can verify the effectiveness of our geometric
calibration procedure. By incorporating the calibration information we
obtain with the calibration, known geometric error artifacts should be
reduced.
**** notebooks                               :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"geometry/overview.ipynb")][geometry/overview.ipynb]]
- Overview of the simulated work/analysis
*** Image entropy                            :noexport:
    :PROPERTIES:
    :ID:       2410E321-8750-473F-B6B6-13DC1719B6AE
    :END:
To further verify the effectiveness of the calibration procedure, we
will also need to use additional metrics to quantitatively
characterize the impact of using the calibration on image quality. The
work of Wicklein et al. has suggested that the best metric for
measuring the impact of geometric error on image quality is entropy
$(E)$ of the image's gray-level histogram $(H)$. This is defined as
\begin{equation}
  \label{eq:entropy}
  E=-\sum_{q=0}^Q h(q)\cdot\text{log}(h(q))
\end{equation}
where $Q$ is the maximum intensity value and
\begin{equation}
  \label{eq:norm_hist}
  h(q)=\frac{H(q)}{N}
\end{equation}
is the normalized histogram cite:wicklein_image_2012. For this metric,
minimum entropy is obtained for an image with a single intensity value
while an image with uniform distribution over all intensity values
would have maximum entropy.

Geometric errors introduce blurring at sharp boundaries in the image
which increases the entropy. By reducing geometric errors with
calibration, this blurring effect and subsequently entropy should
reduced. For our non-circular trajectories, Wicklein's conclusion can
be verified readily with the images in our catalog of geometric
errors. The image entropy of the correct-geometry reconstruction will
be against the reconstructions with intentional geometric errors to
determine if improved geometric modeling reduces the image entropy in
Equation (\ref{eq:entropy}).

If the entropy calculations based on simulation agree with Wicklein's
findings, entropy would be reasonable metric to characterize the
benefits and limitations of using the geometric offsets from the
calibration phantom on different non-circular trajectory
reconstructions. We would then use entropy as the metric to compare
reconstructions with and without calibration. From this, we can not
only verify the effectiveness of our calibration method with different
non-circular trajectories, but also then characterize the impact
additional geometric corrections have on image quality.
*** Experimental validation
    :PROPERTIES:
    :ID:       150f19dd-e68d-4226-bdd4-01e31ea1176f
    :END:
To evaluate the efficacy of our calibration procedure, we investigated
its performance on calibrating both a standard, half-fan, circular
trajectory where the couch is stationary as well as a virtual
isocenter trajectory. For purposes of discussion, a virtual isocenter
is where the couch moves simultaneously with the gantry rotation from
a fixed point that we call the virtual isocenter. We will return to
the example of the virtual isocenter trajectory in [[id:99055e18-4b61-404e-9408-ebd5fd0a5d8d][Collision-avoiding
trajectories]]. For each of these trajectories, we used the same
Developer Mode script to scan both the Catphan phantom and the Isocal
phantom. We subsequently used the sinogram from the Isocal scan to
extract calibration offsets for that particular trajectory using the
calibration method described above.

We reconstructed the Catphan scans from these two trajectories with
and without the calibrations offsets. An isotropic image grid of 0.473
mm was used for each reconstruction with application of the half-fan
weighting cite:bian_optimization-based_2013. For all reconstructions,
200 iterations of MLEM were used, as described in the [[id:ad13bdd9-4298-4534-979d-a019d80311a5][Generalized
trajectory framework]] section.
*** figures                                  :noexport:
**** four detector schematic
#+LABEL: fig:geo_schematic
#+BEGIN_SRC asymptote :file figures/geo/schematic.pdf :exports results :tangle no
settings.multisample=0;
settings.outformat="pdf";
settings.prc = false;
settings.render = 0;

import graph3;
import solids;
import three;

// view configuration
size(10cm);
// currentprojection=orthographic(-5,1,5,up=Y);
currentprojection=perspective(-5,1,5,up=Y);
// currentlight=White;

// Draw axis
// draw(Label("$y$",1),(0,0,0)--(0,5,0),red,Arrow3);
// draw(Label("$x$",1),(0,0,0)--(5,0,0),red,Arrow3);
// draw(Label("$z$",1),(0,0,0)--(0,0,5),red,Arrow3);

// kV schematic
real dlat=0, dlng=0, dvrt=50;
triple det=(dvrt,dlat,dlng);
real ulen=40.0, vlen=30.0;

path3 detector=plane((0,ulen,0), (0,0,vlen), det-(0,ulen/2,vlen/2));

transform3 rot090=rotate(90, Z);
transform3 rot180=rotate(180, Z);
transform3 rot270=rotate(270, Z);

path3 det090 = rot090*detector;
path3 det180 = rot180*detector;
path3 det270 = rot270*detector;

draw(detector, black);
draw(det090, black);
draw(det180, black);
draw(det270, black);

// labels
//From Charles Staats's tutorial
//Direction of a point toward the camera.
triple cameradirection(triple pt, projection P=currentprojection) {
  if (P.infinity) {
    return unit(P.camera);
  } else {
    return unit(P.camera - pt);
  }
}

//Move a point closer to the camera.
triple towardcamera(triple pt, real distance=1, projection P=currentprojection) {
  return pt + distance * cameradirection(pt, P);
}

label("$\theta=0^{\circ}$",red,align=S,position=towardcamera((det-(0, ulen/2, -vlen/2))));
// label("$B$",align=S,position=towardcamera((B)));
// label("$C$",align=SE,position=towardcamera((C)));
// label("$D$",align=SE,position=towardcamera((D)));
// label("$E$",align=NE,position=towardcamera((E)));
// label("$F$",align=S,position=towardcamera((F)));

// source
real slat=0, slng=0, svrt=-100;
triple src=(svrt,slat, slng);

// lines from source to detector edges
// draw(src..det-(0,-ulen/2,-vlen/2),black);
// draw(src..det-(0,-ulen/2,vlen/2),black);
// draw(src..det-(0,ulen/2,-vlen/2),black);
// draw(src..det-(0,ulen/2,vlen/2),black);

// Draw cylinder
// cylinder(startpoint3d, radius, length, along_this_axis)
triple start = (0,0,-8);
real length = 16;
real radius = 11.3;
triple ax = (0,0,1);
revolution r = cylinder(start,radius,length,ax);
draw(r,black);

// isocal spots
triple[] isocal={(0,-11.3,-7.5),
                 (7.9903,-7.9903,-7.5),
                 (7.9903,7.9903,-7.5),
                 (-11.3,0.0,-7.5),
                 (-7.9903,7.9903,-5),
                 (11.3,0.0,-3),
                 (0,11.3,-2),
                 (-10.4398,4.3243,2),
                 (4.3243,10.4398,3),
                 (-10.4398,-4.3243,5),
                 (4.3243,-10.4398,5),
                 (10.4398,-4.3243,7.5),
                 (10.4398,4.3243,7.5),
                 (-4.3243,10.4398,7.5),
                 (-4.3243,-10.4398,7.5)
};

dot(isocal, black);

// project points
transform3 proj=planeproject(detector);
transform3 proj090=planeproject(det090);
transform3 proj180=planeproject(det180);
transform3 proj270=planeproject(det270);

dot(proj*isocal,red);
dot(proj090*isocal,red);
dot(proj180*isocal,red);
dot(proj270*isocal,red);
#+END_SRC

#+CAPTION: Schematic representation of the scanning geometry
#+ATTR_LaTeX: :width 0.75\textwidth
#+RESULTS: fig:geo_schematic
** Results
   :PROPERTIES:
   :ID:       bc50c80a-fbb7-41d3-a9d0-ebc552f59896
   :END:
# *** TODO Simulation                          :noexport:
# *** Experimental validation
    # :PROPERTIES:
    # :ID:       2c3c25d5-477a-4013-bf2a-5a74716b9c20
    # :END:
After acquiring the circle and virtual isocenter trajectories of both
the Catphan phantom and the Isocal phantom, we used our calibration
procedure to find the geometric offsets for each view. Table
([[ref:tab:geo_cal_offs]]) shows a subset of the offsets given by our
method for a gantry angles at approximately $90^{\circ}$ intervals. For
these calibrations, we only allowed the optimization program to vary
the detector's lateral and longitudinal position as well as the
source's longitudinal position. With the virtual isocenter trajectory
that also introduces the couch motion, there is a larger amount of
variation in the offset magnitude than in the circle trajectory that
has a stationary treatment couch.

#+ATTR_LATEX: :environment longtable :align l|c|c|c|c
#+CAPTION: Table of selected calibration offsets at approximately $90^{\circ}$ increments of the gantry angle for the circle and virtual isocenter trajectories shown in these results. For these results, only the detector's lateral and longitudinal position as well as the source's longitudinal position in the radiation coordinate system were allowed to vary in this calibration example.
#+NAME: tab:geo_cal_offs
|-------------------+-------------------------------+-------------------+--------------------+------------------|
| Trajectory        | Gantry angle $\left[^{\circ}\right]$ | Detector lat [mm] | Detector long [mm] | Source long [mm] |
|-------------------+-------------------------------+-------------------+--------------------+------------------|
| Circle            |                        -179.9 |              -0.4 |               -0.9 |              1.8 |
|                   |                         -90.2 |               0.4 |               -0.8 |              1.5 |
|                   |                          -0.2 |               0.5 |               -0.8 |              2.0 |
|                   |                          90.2 |              -0.2 |               -1.0 |              2.2 |
|                   |                         180.2 |              -0.4 |               -1.0 |              1.8 |
|-------------------+-------------------------------+-------------------+--------------------+------------------|
| Virtual isocenter |                        -180.1 |              -0.3 |               -0.6 |              2.5 |
|                   |                         -90.0 |               1.6 |                0.1 |              0.7 |
|                   |                           0.0 |               0.7 |               -0.7 |              1.5 |
|                   |                          90.0 |               0.1 |               -1.5 |              3.0 |
|                   |                         178.2 |              -0.2 |               -0.8 |              2.5 |
|-------------------+-------------------------------+-------------------+--------------------+------------------|
#+TBLFM: $2=$2;%.1f::$3=$3;%0.1f::$4=$4;%0.1f::$5=$5;%0.1f

Figure ([[ref:fig:geo_cal_catphan_bar]]) shows the CTP 528 spatial
resolution module slice from the reconstructions of both the circular
scan (left column) and the virtual isocenter scan (right column). The
top row shows the slice from the uncalibrated reconstruction using the
nominal projection geometry from image metadata. The circle and
virtual isocenter scans without calibration demonstrate that moving
the treatment couch during the scan introduces additional geometric
error over the standard circle scan which visually degrades spatial
resolution.

The bottom row of Figure ([[ref:fig:geo_cal_catphan_bar]]) shows the same
slice from the corresponding trajectory with the geometric offsets
from the calibration procedure incorporated into the system matrix
$\mathcal{H}$. For the circular scan, using the calibration
information does provide a bit of an improvement in spatial
resolution. However, the efficacy of the calibration method is
particularly striking for the virtual isocenter scan. By using the
calibration offsets in the reconstruction model, the spatial
resolution of the virtual isocenter reconstruction becomes comparable
to that of the circular scan.

Figure ([[ref:fig:geo_cal_cost]]) shows the $L_{2}_{}-\text{norm}$ of the
distance between the simulated fiducial projections and the real
fiducial projections acquired from the circle and virtual isocenter
scans of the isocal phantom. We can see that the calibration did
effectively reduce this cost from the nominal geometry (blue) to the
calibrated geometry (green). This cost also reflects the same trend we
see in the spatial resolution of the images shown in Figure
([[ref:fig:geo_cal_catphan_bar]]).

#+BEGIN_EXPORT latex
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.65\textwidth}
    \includegraphics[width=\textwidth]{figures/geo/catphanCalComp}
    \caption{}
    \label{fig:geo_cal_catphan_bar}
  \end{subfigure}
  ~ %add desired spacing between images, e. g. ~, \quad, \qquad,
  % \hfill etc.
  % (or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figures/geo/costComp1p5}
    \caption{}
    \label{fig:geo_cal_cost}
  \end{subfigure}
  \caption{(a) shows the 200$^{\text{th}}$ iteration of MLEM
    reconstructions of the CTP 528 spatial resolution module from the
    Catphan phantom for two different trajectories. The left column is
    from a 1.5X circular scan, and the right column is from a 1.5X
    virtual isocenter scan reconstructed onto a 0.473 mm isotropic
    image grid([-100, 2000] HU). The top row shows the reconstruction
    using the nominal geometry from self-reported metadata, and the
    bottom row corresponds to the calibrated reconstructions. (b)
    shows the $L_{2}$-norm used for the calibration cost function
    before (blue) and after (green) calibration for both the circle
    (left) and the virtual isocenter (right).}
  \label{fig:geo_cal_sens_cost}
\end{figure}
#+END_EXPORT

Comparing the the $L_{2}_{}-\text{norm}$ of the uncalibrated scans in Figure
([[ref:fig:geo_cal_cost]]), we see that there is far more disagreement
between modeled and observed Isocal fiducial positions for the virtual
isocenter scan than that of the circular scan, leading to more
artifacts and loss of spatial resolution in the virtual isocenter
reconstruction than in that of the circular scan. With the geometric
calibrations applied, the cost for the virtual isocenter and circular
trajectories is quite comparable, as is the spatial resolution.
**** figures                                 :noexport:
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/calibration_images.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/calibration_images.ipynb]]
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/calibs/calib_analysis.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/calibs/calib_analysis.ipynb]]
**** notes                                   :noexport:
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/calibs/calib_analysis.ipynb")][170603_virtiso_circ_smth_catphan/dynmag/calibs/calib_analysis.ipynb]]
** Discussion
   :PROPERTIES:
   :ID:       CAB89A8B-FC4B-4F9A-A52A-68E17ED2885C
   :END:
From these results, especially with the virtual isocenter, we can see
that there is an improvement in the spatial resolution by
incorporating the calibration offsets obtained from the Isocal phantom
and our calibration procedure. A general loss of spatial resolution is
the typical consequence of attempting to reconstruct an object without
using the correct geometry to construct the system matrix. As shown in
Figure ([[ref:fig:geo_cal_catphan_bar]]), this loss of spatial resolution
can be drastic as in the case of the virtual isocenter trajectory.

It is important to understand that by introducing the motion of the
couch in the virtual isocenter trajectory, there is the subsequent
introduction of additional uncertainty associated with the geometry of
the couch position. Both the visual appearance of the spatial
resolution module in Figure ([[ref:fig:geo_cal_catphan_bar]]) as well as
the cost function in Figure ([[ref:fig:geo_cal_sens_cost]]) prior to
calibration reflect the additional uncertainty introduced by the couch
motion. However, the ability to recover the bar phantom pattern and
achieve a similar cost function after calibration as the circle
trajectory demonstrate that this additional uncertainty can be
accounted for with calibration.

It is also interesting to note the sinusoidal appearance of the cost
function as plotted against gantry angle in Figure
([[ref:fig:geo_cal_sens_cost]]). The variation as a function of the
gantry's orientation is most likely due to the variation in the torque
applied to the gantry by gravity. Though this gravitational impact has
been studied before cite:sharpe_stability_2005, it is interesting to
see the additional uncertainty this effect has when also combining the
simultaneous couch motion into the trajectory.

One of the most challenging aspects of using an optimization-based
calibration procedure such as ours is that different offset variables
can couple with other parameters that geometrically impart the same
effective offset relative to the image space coordinate system. An
example of that would be a couch offset in one direction being
equivalent to a detector offset in the opposite direction. While this
ambiguity is exactly the same feature we utilize when implementing
some of trajectories, i.e., an axial-FOV extension by either
translating the couch or the imaging arms, it does complicate the
calibration procedure.

In this work, we addressed by only allowing some parameters to vary
while keeping other variables we know do have uncertainty fixed. For
example in Table ([[ref:tab:geo_cal_offs]]), we only use offsets for the
source and detector for both the circle and virtual isocenter
trajectories. In this case, though we know the couch introduces
additional uncertainty, the calibration procedure is able to
incorporate these offsets into the relative offsets of the source and
detector. As we are ultimately interested in obtaining a proper
reconstruction of the object in the image space, reduction in cost in
the objective function subsequently manifests as an improvement in the
projection geometry relative to the image space.

In future calibration work, it would useful to address this ambiguity
by constraining the optimization function in a way that would ensure
much greater absolute accuracy of the calibration offsets. Though we
did not do that here, this could be done to some degree by taking
known tolerance of the LINAC components into account. For example,
the tolerances of the couch position and the imaging arms could be
used to provide the appropriate weighting for how much the different
offset magnitudes are allowed to vary.

** Conclusion
   :PROPERTIES:
   :ID:       fd41d566-a4b3-4dcd-9f8c-7417276ad25c
   :END:
In developing our optimization-based geometry calibration procedure,
we found that proper geometric calibration is critical to achieving
optimal tomographic image quality. This is particularly true for more
complicated trajectories where additional motion components such as
that of the treatment couch introduce additional degrees of freedom in
which geometric errors can arise. As shown in Figure
([[ref:fig:geo_cal_sens_cost]]), the additional motion of the couch with
the simultaneous motion of the source and detector introduces a larger
deviation from the nominal scanning geometry.

The optimization-based calibration we used in this study provides a
robust framework for calibrating arbitrary scanning trajectories. The
ability to acquire view-by-view calibration information with this
approach dovetails nicely with the optimization-based framework that
enables the reconstruction from the different trajectories we studied
in this research. Though many of the different analytic-based methods
described in the literature could be adapted to some of these
trajectories cite:noo_analytic_2000,smekal_geometric_2004, the benefit
of the optimization-based framework for both reconstruction and
geometric calibration comes from freedom to easily model and
reconstruct from any desired trajectories as well as geometric offsets
that deviate from the analytically prescribed model.

Though this does imply that calibration scans must be acquired for
each scan of interest, there are optimization-based calibration
methods similar to ours that attempt to extract calibration
information with no /a priori/ knowledge of the phantom
cite:panetta_optimization-based_2008. Such calibration methods or
built-in calibration markers in the table are potential ways in which
it would be possible to avoid acquiring calibration information for
every scan of interest. As we used the TrueBeam kV-CBCT system for our
data acquisition, Varian's Isocal phantom provided a convenient means
of calibrating the imaging system as the linac use case already
demands accurate calibration for treatment accuracy in addition to
image quality alone.

In the following chapters, where we investigate particular
applications of these different trajectories, we will use our
calibration method with the Isocal phantom to more accurately model
the system matrix $\mathcal{H}$. Though the more exotic scanning
trajectories introduce more degrees of freedom that create greater
geometric uncertainty, our calibration procedure determines what these
deviations are from the self-reported geometry metadata. For these
trajectories, we found that incorporating geometric calibration
consistently improves image quality.
* Axial field-of-view extension              :fov:
  :PROPERTIES:
  :ID:       eaae199f-f899-4862-af50-720895a31c36
  :END:
** notes                                     :noexport:
   :PROPERTIES:
   :ID:       7c250434-fff6-41a3-aea3-e7bc9ff88dc6
   :END:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
*** publications
    :PROPERTIES:
    :ID:       48459222-20e7-43e5-9863-5022a5803a1b
    :END:
**** cite:davis_extended_2013
     :PROPERTIES:
     :ID:       5b4c7bca-d59b-4f33-8151-a6b359071249
     :END:
- simulation study of axial FOV extension
**** cite:davis_verifying_2013
     :PROPERTIES:
     :ID:       d4c20a7d-4982-4318-b591-9ff84ee809f5
     :END:
- Trilogy scans of RANDO and Defrise phantom for axial FOV extension
**** cite:pearson_investigation_2013
     :PROPERTIES:
     :ID:       6ae09b4c-d1d3-4705-b110-8a4a0e1f33dd
     :END:
- Similar results to [[id:d4c20a7d-4982-4318-b591-9ff84ee809f5][cite:davis_verifying_2013]] using RANDO and Defrise
  Trilogy scans
**** cite:davis_we-g-brf-07:_2014
     :PROPERTIES:
     :ID:       3f9687ce-f913-43a0-8e96-0ace96d7f67c
     :END:
- AAPM talk using CLLC scan from TrueBeam
**** cite:davis_su-e-i-02:_2015
     :PROPERTIES:
     :ID:       15f62bff-3fae-4083-b4b1-ad0594d25121
     :END:
- AAPM poster for disk phantom metrics
**** cite:davis_non-circular_2015
     :PROPERTIES:
     :ID:       cee07d24-100a-4c78-a42d-59cd707cda3b
     :END:
- Varian meeting showing non-circular scans
** Introduction
   :PROPERTIES:
   :ID:       b815fcd4-92c6-4f72-9905-10acc22b580e
   :END:
# What question (problem) was studied?
A major limitation of linac-mounted CBCT kV-imaging systems is their
axial coverage. This is primarily due to the detector size which is
restricted by both cost and engineering concerns. Unlike modern
diagnostic CT systems, the linac gantry is unable to perform more than
a single rotation in a given direction. Without the ability to
continuously rotate about the patient in the same direction, the
helical scan solution to this limited-axial-FOV problem used by modern
diagnostic CT systems is untenable.

When an extended axial FOV is needed in the IGRT clinic, the current
practice is to acquire two circular scans centered at different axial
positions. Once each independent volume has been reconstructed with an
analytic-based FBP algorithm such as FDK, the two volumes are stacked
to create the extended image. Though this stacked image does extend
the axial coverage beyond that provided by a single circular scan,
there are some limitations to this approach. We investigated if the
non-circular trajectories with optimization-based methods described in
[[id:ad13bdd9-4298-4534-979d-a019d80311a5][Generalized trajectory framework]] can provide a solution to these
shortcomings.

The main problem with the current clinical approach is a limitation
incurred by reconstructing each of the volumes with analytic-based
reconstruction methods, such as FDK. When combining the volumes of two
independently-constructed FDK volumes acquired at different axial
positions, the overlap region between the two axial positions
corresponds to the larger cone angles of the two independent volumes.
As methods like FDK are known to suffer from cone-angle artifacts at
the axial extremes of the reconstruction volume as shown in Figure
([[ref:fig:opt_defrise]]), this volume stacking approach abuts the regions
of the two independent volumes most afflicted with cone angle
artifacts against each other as shown in Figure
([[ref:fig:opt_fov_schematic]]). 

Furthermore, the stacking of FDK volumes is also limited by the axial
coverage allowed by the reconstruction algorithm. In Figure
([[ref:fig:opt_fov_schematic]]), everything bounded by the detectors for
both circles at opposing views constitutes the image support of
optimization-based methods like MLEM. For comparison, the support of
the FDK reconstruction is limited to just the shaded regions of each
circle. 

As the axial spacing between the two circles is increased, the shadow
zones cite:forthmann_adaptive_2009 corresponding to regions outside
the support of the FDK reconstruction further contaminate the region
of overlap. As the spacing between the circles is increased, these
shadows regions encroach into the volume of the stacked FDK image. At
the maximum axial spacing of 20 cm for the TrueBeam system, the shadow
zones extend directly to the center of the image as shown in Figure
([[ref:fig:opt_fov_20cm]]) resulting in missing information in the stacked
volume.

In addition to the shadow zone contamination, there is another
limitation that affects the stacked FDK volume approach. As the two
circular volumes are reconstructed independently, neither scan
benefits from mutually-shared information in the overlap region
between the two scans, which could potentially reduce the cone-angle
artifacts. For axial separations between the two circles $\left(
d\right)$ that is less than the maximum spacing, there is redundant
sampling of the image volume by the two circular scans. This is
illustrated in Figure ([[ref:fig:opt_fov_10cm]]) where the purple region
corresponds to this redundant sampling. For any axial separation less
than the maximum, optimization-based reconstruction methods can take
this redundant sampling into account whereas the FDK volumes are
agnostic to this additional information in the neighboring
reconstruction volume.

Taking advantage of the flexible reconstruction framework described in
[[id:06ec01f2-e128-4baf-9ec7-4569a3aaa886][General CBCT trajectory reconstruction framework with
optimization-based algorithms]], data from more than a single circular
scan can be reconstructed. Provided that the correct geometry of the
acquisition trajectory is well understood and properly calibrated
(e.g. using a calibration method such as that discussed in [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Geometric
calibration]]), the system matrix of the image formation process can be
calculated for arbitrary CBCT scanning configurations. Trajectories
are not limited to the few cases of non-circular trajectories for
which analytic inverse formulations exist such as the line
cite:sidky_volume_2005, circle and line
cite:zeng_cone-beam_1992,katsevich_image_2004, circle and arcs
cite:zou_image_2005-1,katsevich_image_2005, and non-planar orbits
cite:kudo_derivation_1994.

Using some of the trajectories enabled by optimization-based methods,
we can address the problem of the limited axial coverage for
linac-mounted CBCT kV-imaging systems. Rather than increasing the size
of the detector, the source and detector motion can be extended in the
axial direction, allowing projections to be obtained for axial
positions beyond what is illuminated with current detector sizes and a
circular scanning trajectory.

In this chapter, we study a few different trajectories that could
address the limited axial coverage provided by linac-mounted
kV-imaging systems. For the case of the TrueBeam system, the axial
coverage of the treatment FOV is 40 cm while the CBCT coverage from a
single circle is only 20 cm. This limitation can be problematic for
patients with treatment volumes that extend axially beyond what is
visible in a single circular acquisition cite:voong_dosimetric_2014.
The trajectories we investigate in this chapter provide extended axial
coverage. Our hypothesis is that data from scans with extended axial
coverage can be reconstructed into extended FOV images with quality
equivalent to current clinical scans using only a single circle and
resultant limited axial FOV.

** Methods
   :PROPERTIES:
   :ID:       b42e5e65-dfda-4692-8ea6-f6d96bc1dd5b
   :END:
*** Trajectories
    :PROPERTIES:
    :ID:       b16942be-e3d8-4fb2-a872-aa68fe6bd4fd
    :END:
In order to obtain additional axial tomographic information from a
patient beyond what is covered by the detector, there must be a
relative shift along that axis between the patient and the imaging
system. As described to in the [[id:ad13bdd9-4298-4534-979d-a019d80311a5][Generalized trajectory framework]]
section, either the patient or the imaging system can shift along this
direction to obtain the desired projection information as long as the
motion is correctly reflected in the system matrix $\mathcal{H}$. With
the additional projections along the axial direction, it is possible
to extend the axial coverage of the tomographic image beyond that
which is provided by a single circular scan.

The current clinical method of obtaining an extended axial image
involves stacking the FDK reconstructions of two circular scans at
different axial positions. For this reason, the first class of
trajectories we studied was a dual-circle trajectory shown on the left
in Figure ([[ref:fig:fov_3d_trajectories]]). As the linac is only able to
make one complete rotation of the gantry, this is implemented by
acquiring a circular trajectory scan, applying the axial shift, and
then acquiring a second circle by rotating the gantry in the opposite
direction.

#+CAPTION: Source trajectories of the three classes of extended axial-FOV trajectories studied with a separation of 17 cm between the planes of the circular components of the scan. Moving in diametric opposition of the source is the CBCT detector which provides coverage 15 cm above and below the source trajectory in the axial direction (z) All of these trajectories are plotted in the image coordinate space described in the section [[id:9e81dc1a-091f-4614-9d0f-5a5d4ee4f0d1][Varian coordinates]]. On the left is the double circle trajectory that is equivalent to the double circle scan currently used in the clinic to obtain extended axial coverage. In the middle is the circle-line-circle trajectory that acquires additional projection information as the source and detector translate from the axial position of the first circle to that of the second. On the right is the smooth trajectory in which the translation component occurs during the rotation of the two circles.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_3d_trajectories
[[file:figures/fov/3d_trajectories.pdf]]

Another class of trajectories we studied was the circle-line-circle
(CLC) trajectory shown in the middle of Figure
([[ref:fig:fov_3d_trajectories]]). Like the double circle trajectory, this
trajectory consists of two circles at various axial positions, but
with projections also acquired during the linear shift between the two
axial positions of the circles for the CLC trajectory.

The last class of trajectories we studied will be referred to as the
smooth trajectory which is shown at the right of Figure
([[ref:fig:fov_3d_trajectories]]). It is similar to the CLC trajectory in
that it consists of two circles at two different axial positions with
projections acquired along the axial shift component. The gantry
motion is the same in that it performs two rotations in the opposite
direction. The difference here is that the axial shift component is
begun before the first gantry rotation is complete, and the second
gantry rotation begins before the axial shift is complete. Unlike the
double circle and CLC trajectories, this trajectory does not have a
complete circle at either of the two axial positions.

**** notebooks                               :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170816_circ_clc_smth_catphans/matlab/em/trajectories.ipynb")][truebeam/170816_circ_clc_smth_catphans/matlab/em/trajectories.ipynb]]
- plots of trajectories from real scan data

*** Simulation
    :PROPERTIES:
    :ID:       C07F2BE3-413C-490F-B171-0ADB82B939EA
    :END:
As the current clinical procedure for obtaining an extended axial FOV
CBCT is by stacking together the independently reconstructed images
of two circular scans acquired at different axial locations, we first
used simulations to determine the maximum axial spacing between the
two circular trajectories allowed by this technique. To evaluate this,
we compared the simulated results of stacking
independently-reconstructed FDK images from two circular scans at
various axial separations to the MLEM reconstruction of those same two
circles reconstructed simultaneously as a single acquisition sinogram
cite:davis_extended_2013.

We simulated a Defrise-style phantom modeled with the 3D X-ray
projection software TAKE cite:seger_matlab/c_2005. The phantom was
composed of a 15.2 cm outer diameter acrylic cylinder with alternating
density disks of Delrin and cork 0.5 cm thick. Due to the alternating
density disks along the axial direction, this particular phantom has
been acknowledged by the authors of FDK to be particularly susceptible
to cone-angle artifacts cite:feldkamp_practical_1984. We used the TAKE
software to forward project the phantom as well as generate a
digitized ``truth'' phantom for calculating comparison metrics. The
simulation program generates a forward projection from a specified
trajectory given a mathematical definition of the phantom as well as
its material properties and the spectrum generated by the x-ray
source.

We created projection data for dual-circle trajectories that had
variable axial separation between the two circles. With a 1.5x
magnification factor and a 30 cm detector size along the axial
direction (e.g., geometry equivalent to that of the TrueBeam
kV-imaging detector), a single circular scan has a maximum axial
coverage of 20 cm. Thus, the maximum spacing between the two circles
is 20 cm as any separation larger than this creates a gap between the
two imaging volumes. We therefore created trajectories with 10, 12,
14, 16, 18, and 20 cm separations between the planes of the source's
dual-circle trajectory.

In addition to the double circle trajectory, we also simulated
projections from the CLC and smooth classes of trajectories shown in
Figure ([[ref:fig:fov_3d_trajectories]]). We uniformly distributed 600
views over the entire trajectory. Of these 600 views, 20% were
distributed along the axial translation stage.

For the extended-volume reconstruction using the stacked FDK, we
independently reconstructed each circular scan with FDK using a
standard Hann filter. The reconstruction image space consisted of a
$256\times256$ transverse grid of 1 mm isotropic voxels. To combine the two
reconstructed volumes for an extended axial-coverage image at a given
spacing, the axial location between the two circle positions was used
as a discriminator to select where to truncate each of the two volumes
before stacking them together. In the reconstructed image, the volume
superior to this axial position was taken from the superior circle,
and the volume inferior to this position was taken from the inferior
FDK reconstruction volume.

For the MLEM reconstructions, the projection data were treated as a
single sinogram to reconstruct the extended volume. After defining the
extended image volume, we computed the system matrix for each of the
different spacings and trajectories based on the trajectory of the
source and detector. We used 100 iterations of the MLEM algorithm to
find an estimate for the image.

**** fragments                               :noexport:
Our initial evaluation of the images obtained from non-circular
trajectories is simply a qualitative visual inspection which does
provide an informative assessment of the variety of artifacts that
occur for a given reconstruction. For a more rigorous evaluation of
the images obtained from different trajectories, we will use mutual
information (MI) cite:pluim_mutual-information-based_2003 and the
universal quality index (UQI) cite:wang_universal_2002 to provide a
quantitative assessment of the image similarity between the reference
image and the images from different trajectories.

Simulating forward projections from this trajectory, we compared the
images obtained from stacking together the independent FDK images to
those obtained by reconstructing the two circles as a single
trajectory with MLEM. We also compared stacked FDK images to
reconstructions from the simulated *CLC* and smooth trajectories.

*** Experimental Data
    :PROPERTIES:
    :ID:       0a6741b1-925a-4b69-97ff-7047ceac53d4
    :END:
After identifying potential benefits of addressing the limited axial
FOV using non-circular trajectories as described in the [[id:ad13bdd9-4298-4534-979d-a019d80311a5][Generalized
trajectory framework]] section, we then evaluated how well this approach
worked when implemented on our TrueBeam system using Developer mode as
describe in the [[id:58A6E225-522B-4620-BEDB-F81AD30070C3][Framework implementation with Varian TrueBeam kV-CBCT
system]] section. By using the Developer Mode XML control schema, we
created acquisition scripts that implemented gantry rotations with a
component of axial translation between the patient and the kV-imaging
system. The trajectory plots shown in Figure
([[ref:fig:fov_3d_trajectories]]) are from the actual trajectories of the
three classes studied with a 17 cm gap between the two planes of the
circular orbits.

Though the imaging framework is agnostic to which component of the
system effects the relative motion between the patient and the imaging
system, there are some engineering limitations of the TrueBeam system
that determine how the axial translation component of these
trajectories is implemented. In the current TrueBeam implementation,
the kV-imaging robotic arms cannot perform any translational movement
while the gantry is rotating. As such, all of our axial translation
were implemented by moving the treatment couch for all of the
trajectories instead of translating the robotic arms. As the CLC
trajectory requires no gantry rotation during the translation stage,
we did acquire one CLC trajectory using translation of the robotic
imaging arms for comparison.

#+CAPTION: Catphan  sagittal view showing the axial extent of a single Catphan 504 phantom.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_catphan_sagittal
[[file:figures/fov/catphan_incr_module_pos.png]]

The image quality that results from using these trajectories with
optimization-based algorithms must be quantitatively evaluated for the
different trajectories and spacings chosen. Given that contrast
resolution is important to clinical utility cite:dawson_advances_2007,
we wanted to characterize the low-contrast resolution as a function of
axial position for the different trajectories and spacings. As the
extended axial coverage we obtain with the kV imaging system using
these methods is novel, there is not a standard phantom for
characterizing low-contrast resolution as a function of axial position
within a single scan. Figure ([[ref:fig:fov_catphan_sagittal]]) shows the
limited coverage afforded by a single Catphan 504 phantom.

#+CAPTION: Catphan CTP 515 low-contrast module schematic.
#+ATTR_LaTeX: :width 0.75\textwidth
#+LABEL: fig:fov_catphan_ctp515
[[file:figures/fov/ctp515.png]]

For this reason, we built a custom low-contrast disk phantoms that fit
into an acrylic tube with extended axial coverage as shown in Figure
([[ref:fig:fov_tube_setup]]). The disks themselves, such as the one shown
in Figure ([[ref:fig:fov_disk]]), are designed to provide similar metrics
such as those obtained with the Catphan phantom's low-contrast module
CTP515 shown in Figure ([[ref:fig:fov_catphan_ctp515]]). Additionally, the
largest holes are designed to hold the different electron density
plugs from the Gammex (Middleton, WI) RMI tissue characterization
phantom. By placing four of these disks in the tube, we can obtain
these metrics as a function of axial position within a given
reconstruction.

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{subfigure}[b]{0.55\textwidth}
  \includegraphics[height=1.75in]{figures/fov/disk_phan/tube_setup.jpg}
  \caption{}
  \label{fig:fov_tube_setup}
\end{subfigure}
\qquad %add desired spacing between images, e. g. ~, \quad, \qquad,
% \hfill etc.
% (or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.35\textwidth}
  \includegraphics[height=1.75in]{figures/fov/disk_phan/four_disks.jpg}
  \caption{}
  \label{fig:fov_disk}
\end{subfigure}
\caption{The left image shows the experimental setup of the acrylic
  tube with four low-contrast disks. Given the symmetry of the
  scanning geometry, one disk is placed at the plane between the two
  circles. The remaining three are placed at different axial positions
  in one half of the image volume. The right image shows the four
  low-contrast disks with the larger holes holding solid water RMI
  inserts.}
\label{fig:fov_disk_phan}
\end{figure}

#+END_EXPORT

After some preliminary studies, we found the nominal 1% low-contrast
inserts were too challenging to consistently identify on the linac's
kV-imaging system. Thus, we decided to use two Catphan 504 phantoms to
provide features for obtaining image quality metrics. As we needed to
acquire image quality metrics over the extended axial coverage, we
placed the two Catphan phantoms end to end. This effectively provided
a standard image-quality phantom that also spanned the extended
axial-FOV volume enabled by these trajectories of interest.

For the all of the different trajectory scans, the double-Catphan
configuration was positioned with one of the Catphan's sensitometry
module shown in Figure ([[ref:fig:opt_ctp404]]) aligned at imaging
isocenter. As this module provides many of the features we used to
calculate image metrics, we wanted to acquire metrics with this module
placed so that it is in the plane of the source's orbit for one of the
two circles. By doing this, we could compare the image quality metrics
from the different scanning trajectories against a clinical circular
FDK scan where the image quality is evaluated on the plane where FDK
satisfies Tuy's condition. We acquired all three classes of
trajectories (double circle, CLC, and smooth) with both full-fan and
half-fan detector configurations.

For a LINAC system, it often is the case that the patient's transverse
slice volume exceeds the transverse FOV support allowed by the
trans-axial coverage of the kV-imaging detector when it is centered
with the piercing point of the source to detector ray in the middle of
the detector. To overcome this limitation, a detector offset is given
to the detector so that it is shifted in the lateral dimension in the
radiation coordinate system shown in Figure ([[ref:fig:opt_coords_rad]])
cite:chang_asymmetric_1995,cho_cone-beam_1995. In doing this, the
transaxial FOV is increased as this half-fan configuration acquires
projections from half of the phantom or patient in the first
$180^{\circ}$ of rotation and the second half of the phantom or patient
projections in the second $180^{\circ}$ of rotation..

We also scanned the CIRS torso phantom shown in Figure
([[ref:fig:opt_cirs_setup]]). We aligned the phantom so that the center of
phantom was placed at the midpoint between the axial position of the
two circular components of the different trajectories. We again
acquired the three classes of scanning trajectories, but only with a
half-fan detector configuration as this larger phantom would incur
truncation artifacts with a full-fan configuration.

In addition to acquiring the different trajectory scans of these
phantoms, we also repeated the scans with the Isocal phantom to
acquire geometric calibration information. As the Isocal phantom is
designed to align the MV-treatment isocenter with the kV-imaging
system's isocenter, it has a fixed mounting point on the treatment
couch. In order to extract the calibration information for the
different trajectories, we positioned the Isocal phantom on the
treatment table at the location where we placed the double Catphans
and the CIRS torso phantom. As described in [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Geometric calibration]], we
used the Isocal scans to provide calibration corrections for all three
trajectories with both the full-fan and half-fan detector
configurations.

The clinical reconstruction software uses a larger voxel size for
half-fan detector scans than for full-fan detector configurations. We
therefore reconstructed the CIRS torso phantom onto a 0.836 mm
isotropic voxel grid. However, as voxel size is a critical parameter
of the reconstruction program, we reconstructed all of the scans of
the double-Catphan configuration onto a 0.473 mm isotropic image grid
for all detector configurations so that only the detector
configuration would be the independent variable. As we will discuss in
the next chapter, we selected 200 iterations of MLEM for all of our
optimization-based reconstructions.

In addition to reconstructing the extended-axial-FOV sinograms using
the optimization-based framework, we also reconstructed the superior
and inferior circles of the double circle using Varian's clinical FDK
algorithm in iTools. In addition to the default reconstruction chain,
we also reconstructed the two circles without Varian's pre-processing
chain that provides a scatter-correction to the projection data. We
did this because no scatter correction modeling was implemented in our
MLEM reconstructions. Though we had initially attempted to extract the
pre-processed projection data from iTools to use in our reconstruction
chain, we discovered that some of the non-standard motions we
implemented with the linac could not be accommodated in iTools as it
did not conform to the typical circular trajectory anticipated by
Varian's software.

For additional comparison, we also reconstructed the superior and
inferior circle independently with our analytic-based reconstruction
chain. We then stacked these two independent volumes together the same
way as for the FDK reconstructions. Finally, as MLEM generally
provides better spatial resolution that FDK, we also reconstructed the
two circles without pre-processing using the iTools FDK with a sharp
kernel as to increase the spatial resolution from the FDK
reconstructions.
**** fragments                               :noexport:
For the dual-circle-extended-line trajectory, it was possible to
acquire this in Developer Mode by controlling just the c-arms. This
trajectory shown in Figure (\ref{fig:cllc_traj}) acquires data from
two circles 19 cm apart and during the translation of the source and
detector from the superior to inferior circle. It also acquires an
additional 4.5 cm linear scan above and below the two circles, which
helps reduce the cone-angle artifacts at the edge of the
FOV. Downsampling from this data set can provide scan data for the
dual circle, the dual circle and line, and the dual circle extended
line. We scanned the CIRS Torso Phantom (Computerized Imaging
Reference Systems, Norfolk, VA) which contains low-contrast structures
unlike the RANDO phantom.

One limitation of our version of Developer Mode is that it is not
possible to move the source and detector arms during the gantry
rotation. For this work, any desired arm translation during gantry
rotation is mimicked with the couch translation whenever it will
produce an equivalent relative translation. While this is not exactly
equivalent, it allows a close approximation of such a trajectory. For
this reason, the smooth trajectory discussed in the previous section
was implemented with gantry rotation and couch translation.

We determined that though the two methods are comparable for the
smaller axial gaps between the two circles that FDK can support, it
would be clinically advantageous to evaluate larger axial gaps that
are untenable for the stacked FDK method. Using the TrueBeam system,
we then acquired scans from axial spacings of 17, 18,19, and 20 cm
between the two circular planes of these trajectories. These larger
spacings provided data for potential axial FOV's of 37, 38, 39, and 40
cm respectively. However, after some preliminary results, we decided
to use a 17 cm gap between the planes of the two circles for each of
the three classes of trajectories shown in Figure
([[ref:fig:fov_3d_trajectories]]).

To acquire more scan information from the central region between the
two circles, we also simulated two other trajectories. Both of these
trajectories acquire additional view while translating the source and
detector from the axial position of one circle to the other. One of
these trajectories is a circle-line-circle trajectory where the
translation phase of the source and detector between the two circles
is a line as Figure (\ref{fig:traj_clc}) shows. The other trajectory
shown in Figure (\ref{fig:traj_smth}) is a smooth trajectory that is
similar to the circle-line-circle, but the gantry rotation and
longitudinal translation are designed to avoid sharp transition points
in the imaging trajectory.

***** Trajectories
      :PROPERTIES:
      :ID:       4787aeca-bdf3-4b8b-bfda-6c7248cb01d4
      :END:
#+NAME: tab:disk_trajects
  | Trajectory | Axial gap [cm] | Detector configuration | Air scan  | lognorm | Notes                      |
  |------------+----------------+------------------------+-----------+---------+----------------------------|
  | Circle     |                | Full                   |           | x       |                            |
  | Circle     |                | Half                   |           | x       |                            |
  |------------+----------------+------------------------+-----------+---------+----------------------------|
  | CLLC       |             20 | Full                   | 20 cm air | x       |                            |
  | CLLC       |             19 | Full                   | ""        | x       |                            |
  | CLLC       |             18 | Full                   | ""        | x       |                            |
  | CLLC       |             17 | Full                   | ""        | x       |                            |
  |------------+----------------+------------------------+-----------+---------+----------------------------|
  | CLLC       |             18 | Half                   |           | x       | 2 of these for some reason |
  |------------+----------------+------------------------+-----------+---------+----------------------------|
  | SMTH       |             20 | Full                   |           | x       |                            |
  | SMTH       |             19 | Full                   |           | x       |                            |
  | SMTH       |             18 | Full                   |           | x       |                            |
  | SMTH       |             17 | Full                   |           | x       |                            |
  |------------+----------------+------------------------+-----------+---------+----------------------------|
  | SMTH       |             18 | Half                   |           | x       |                            |
  |------------+----------------+------------------------+-----------+---------+----------------------------|

** Results
   :PROPERTIES:
   :ID:       b2a353e8-8531-4a0e-8337-9f702ecf02f8
   :END:
*** Simulation
    :PROPERTIES:
    :ID:       ff434d74-757c-47b8-bd98-9250d2751ff2
    :END:
Our simulations suggested that the optimization-based reconstruction
of the dual-circle trajectory is comparable to the clinical stacked
FDK method when the axial spacing is small enough that the stacked FDK
method is still able to yield a complete reconstruction. As shown in
Figure ([[ref:fig:opt_fov_schematic]]), larger axial spacings
$\left(d\right)$ between the two circles results in larger portions of
the image volume falling outside of FDK's support volume. For the
geometry of our Defrise-style phantom and our TrueBeam kV-imaging
system geometry, the stacked-FDK method and the optimization-based
reconstruction were comparable up to a gap of approximately 14 cm. For
larger axial gaps, the FDK shadow zone between the two volumes begins
to infiltrate the reconstruction volume creating voids in the
reconstruction volume.

#+CAPTION: Plot of the RMSE for extended volumes of different simulated trajectories with different spacing between planes of the circles, compared to the central CBCT volume of a single circular scan which is an axial FOV of 20 cm.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_take_rmse
[[file:figures/fov/take/central_cbct_rmse.pdf]]

Figure ([[ref:fig:fov_take_rmse]]) shows a root-mean-square error (RMSE)
comparison of the three classes of trajectories as well as the stacked
FDK method with different axial spacings between the two planes of the
circles. The volume for which the RMSE is calculated is the central
volume between the two circles with a 20 cm axial length, which would
be the region seen with a single circular scan at the midplane. The
figure shows that for any extended volume spacing, the stacked-FDK
reconstruction from two separate circles deviates the most from the
truth, and it degrades with increasing separation.

#+BEGIN_EXPORT latex
\begin{figure*}[t!]
  \centering
  \begin{tabular}{lccc}
    \toprule
    &FDK stacked&MLEM double circle&MLEM smooth\\
    \midrule

    18~cm&
    \includegraphics[height=3cm]{figures/fov/take/fdk_18cm.png}&
    \includegraphics[height=3cm]{figures/fov/take/mlem_dual_18cm.png}&
    \includegraphics[height=3cm]{figures/fov/take/mlem_smth_18cm.png}\\
    20~cm&
    \includegraphics[height=3cm]{figures/fov/take/fdk_20cm.png}&
    \includegraphics[height=3cm]{figures/fov/take/mlem_dual_20cm.png}&
    \includegraphics[height=3cm]{figures/fov/take/mlem_smth_20cm.png}\\

    \bottomrule
  \end{tabular}
  \caption{Mid-sagittal views of the simulated Defrise disk phantom
    reconstructions at different separation distances. The display
    window is [0.1, 0.3]~cm$^{-1}$. The left column shows the stacked
    FDK extended volumes, and the remaining columns show the
    100$^{\text{th}}$ iteration of the MLEM extended volumes for
    different trajectories. In the stacked-FDK image at the maximum 20
    cm spacing shown on the bottom left, the encroachment of the
    shadow zones into the reconstruction volume appear as two black
    wedges into the Defrise phantom volume.}
  \label{fig:fov_sim_take}
  %\vspace{-1em}
\end{figure*}
#+END_EXPORT

Figure ([[ref:fig:fov_take_rmse]]) also shows that the optimization-based
reconstruction of the same dual-circle trajectory is much closer to
the truth, but also demonstrates degradation with increasing spacing
between the two circles. Finally, the CLC trajectory and the smooth
trajectories reconstructions remain relatively constant for increasing
spacing, with the smooth trajectory being closer to the truth. The
slices shown in Figure ([[ref:fig:fov_sim_take]]) visually agree with
these results. Notice that in the center of the volume, both the CLC
and smooth trajectories are able to recover most of the alternating
disks by acquiring some projections in the region between the circles.
Furthermore, by acquiring these projections in the overlap region
while also rotating as with the smooth trajectory, there is an
additional improvement in this central region. The double circle and
line trajectory was left out of Figure ([[ref:fig:fov_sim_take]]) since
the results were not visually distinguishable from the smooth
trajectory reconstructions.

**** notebooks                               :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"take/metrics.ipynb")][take/metrics.ipynb]]

*** Experimental Data
    :PROPERTIES:
    :ID:       da41c36b-5e9a-4058-8b45-83b22e4f92d1
    :END:
Figure ([[ref:fig:fov_catphan_sagittal]]) shows the central sagittal
slices from the reconstructions of the dual-Catphan phantom scanned
with each of the extended-axial-FOV trajectories in both the full-fan
and half-fan detector configurations. The left column of the figure
represents full-fan detector configuration scans, and the right column
the half-fan detector configuration scans. From the top row to the
bottom, these images correspond to the double circle, the CLC, and the
smooth trajectory.

#+CAPTION: Sagittal slices of the dual-Catphan MLEM reconstruction acquired with the double-circle, the CLC, and the smooth trajectories (in order from top to bottom). The left column corresponds to the full-fan detector configuration, and the right column corresponds to the half-fan detector configuration. The display window is [-160, 240] HU.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_dcatphans
[[file:figures/fov/catphanFOV.pdf]]

We first investigated the quantitative Hounsfield units (HU) from the
different sensitometry modules. Figure ([[ref:fig:sensROIplot]]) shows the
mean ROI value for each of the Catphan sensitometry modules for the
stacked FDK and the stacked MLEM reconstructions as well as the
extended-axial-FOV reconstructions. The height of each of the bars is
the standard deviation of the ROI. The first plot in Figure
([[ref:fig:fov_sensROIfull]]) corresponds to the full-fan detector scans,
and the bottom plot in Figure ([[ref:fig:fov_sensROIhalf]]) corresponds to
the half-fan detector configuration.

#+BEGIN_EXPORT latex
\begin{figure}
\centering
\begin{subfigure}[b]{0.9\textwidth}
\includegraphics[width=\textwidth]{figures/fov/rois/sensROIplot_full.pdf}
\caption{}
\label{fig:fov_sensROIfull}
\end{subfigure}
~ %add desired spacing between images, e. g. ~, \quad, \qquad,
% \hfill etc.
% (or a blank line to force the subfigure onto a new line)
\begin{subfigure}[b]{0.9\textwidth}
\includegraphics[width=\textwidth]{figures/fov/rois/sensROIplot_half.pdf}
\caption{}
\label{fig:fov_sensROIhalf}
\end{subfigure}
\caption{Plots of the Catphan CTP 404 sensitometry insert ROIs for the
  different classes of trajectories studied. Each bar in the plot is
  centered on the mean ROI value, and the height of the bar is the
  standard deviation of that ROI. The top plot (a) shows the ROI
  measurements for the full-fan detector scans, and the bottom plot
  (b) shows the corresponding measurements from the half-fan detector
  scans. For each material ROI, the different scanning trajectory
  results are presented from left to right in the same order listed in
  the legend.}
\label{fig:sensROIplot}
\end{figure}
#+END_EXPORT

To further investigate the relationship between the full-fan and
half-fan configuration as well as the algorithm used, we plotted the
ROI values for just the stacked circle trajectories. As the
introduction of additional trajectory components will be applicable
for the optimization-based framework, this comparison simply provides
a baseline of how MLEM directly compares to the clinical standard.
Figure ([[ref:fig:fov_sensROI_full_half]]) shows the ROI CT numbers of
both the FDK and MLEM reconstructions for both the full-fan and
half-fan detector configurations. Again, each bar is centered on the
mean CT number, and the height corresponds to the standard deviation
of the ROI.

#+CAPTION: Comparison of the MLEM algorithm as a direct replacement of the current clinical method of axial-FOV extension by stacking two independently reconstructed circular scans together. These ROIs are measured from two independently reconstructed circular scans (both full and half fan) using MLEM and FDK. As in Figure ([[ref:fig:sensROIplot]]), the bars are centered on the mean CT number of the ROI, and the height corresponds to the standard deviation in that ROI.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_sensROI_full_half
[[file:figures/fov/rois/sensROIplot_full_half_fdk.pdf]]

We then studied the impact the different scanning configurations and
algorithms had on the spatial resolution of the reconstruction. Though
the MTF is a problematic metric of spatial resolution in CT due to its
violation of linear shift invariance, it can provide a useful
benchmark for evaluating the impact different scanning parameters
could have on the reconstruction's spatial resolution. By using
different MTF metrics from different features in the Catphan, we could
get an approximate characterization of how the different classes of
trajectories reconstructed with our framework compare to the current
clinical standard of stacked FDK.

#+CAPTION: Grid of the different spatial resolution metrics extracted from the MTF analysis of the dual-Catphan phantom scan using the different trajectory classes. The green points are the full-fan detector configuration and the blue points are the half-fan detector configuration.
#+ATTR_LaTeX: :width \textwidth 
#+LABEL: fig:fov_mtf_alg
[[file:figures/fov/mtf/alg_grid.pdf]]

The spatial resolution metrics we extracted from the dual-Catphan
reconstructions from the different classes of trajectories are shown
in Figure ([[ref:fig:fov_mtf_alg]]). This plot shows the different MTF
values for the different algorithms with both the full and half-fan
configuration. As the lack of spatial-shift invariance in CT makes
using the MTF metric only a rough estimate of spatial resolution
performance, there are a few reconstructions where the metric values
are somewhat anomalous.

#+CAPTION: Metrics of acrylic CNR for FDK and MLEM.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_acrylic_cnr
[[file:figures/fov/cnr/acrylic.pdf]]

In addition to the spatial resolution metrics, we also used the CTP
404 sensitometry module to calculate the CNR of the acrylic and
polystyrene inserts. These are the inserts that provide the lowest
contrast relative to the water-equivalent inserts as can be seen in
the ROI measurements in Figure ([[ref:fig:sensROIplot]]). Figures
([[ref:fig:fov_acrylic_cnr]]) and ([[ref:fig:fov_poly_cnr]]) show the
calculated CNR plots for the different algorithms and trajectories for
both the full-fan and half-fan detector configurations for two
different contrast plugs, acrylic and polystyrene.

#+CAPTION: Metrics of polystyrene CNR for FDK and MLEM.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_poly_cnr
[[file:figures/fov/cnr/poly.pdf]]

Finally, the reconstructed images of the anthropomorphic CIRS torso
phantom provide a visual illustration of the three different
trajectory classes. The rows in Figure ([[ref:fig:fov_ed]]) show the
central sagittal, coronal, and transverse slices (from top to bottom
respectively) of the CIRS torso phantom scanned with the three
extended-axial-FOV trajectories using a half-fan detector
configuration. Each column in the figure corresponds to one of the
scanning trajectories.

#+CAPTION: Sagittal, coronal, and transverse slices of the CIRS torso phantom reconstructions. Given the incrased size of this anthropomorphic phantom, only the half-fan configuration was used as the full-fan configuration would have incurred truncation artifacts. The display window is [-160, 240] HU.
#+ATTR_LaTeX: :width \textwidth
#+LABEL: fig:fov_ed
[[file:figures/fov/edFOV.pdf]]

**** notebooks                               :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170816_circ_clc_smth_catphans/fov_images.ipynb")][truebeam/170816_circ_clc_smth_catphans/fov_images.ipynb]]
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170816_circ_clc_smth_catphans/metrics_catphans.ipynb")][truebeam/170816_circ_clc_smth_catphans/metrics_catphans.ipynb]]
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170816_circ_clc_smth_catphans/matlab/em/metrics/catphans.ipynb")][truebeam/170816_circ_clc_smth_catphans/matlab/em/metrics/catphans.ipynb]]
- initial analysis that didn't include the iTools FDK
**** figs                                    :noexport:
***** dual catphans
#+BEGIN_SRC sh :dir ~/cloud/medical_physics/thesis/thesis/figures/fov
rsync -avz remus:/data/amdavis/truebeam/170816_circ_clc_smth_catphans/figs/ .
#+END_SRC
** Discussion
By increasing the separation between the two circular scans up to the
maximum spacing of 20 cm, it is apparent that FDK has fundamental
support limitations that restricts the acceptable distance between
these two circles to less than the maximum 20 cm spacing due to the
increasing size of the shadow zone with increased separation between
the two planes of the circles. This is particularly problematic in
that the infiltration of the shadow zones into the reconstruction
volume occur in the region between the two circles. It is likely that
if such an extended image volume were needed clinically, it would be
axially centered on the region of interest. As such, using the
stacked-FDK method for these larger axial volumes would place the
region of interest directly in the overlap region where FDK is plagued
by both cone-angle artifacts and the shadow zone.

Optimization-based reconstruction methods can use information from
both circular scans simultaneously, leading to improved reconstruction
of the image in the shadow zone as seen in Figure
([[ref:fig:fov_sim_take]]). However, as it can be seen in Figure
([[ref:fig:fov_catphan_sagittal]]), artifacts can still appear in the
overlap region even with optimization based method. The streaking is
particularly noticeable in these results for two reasons.

The first issue is the fact that there is a sharp density change in
the axial direction much like the difficult Defrise-like phantom
design we used in simulation. We made an effort to minimize this
drastic density change from the Catphan to air and then directly back
to the Catphan by inserting a urethane plug we machined to fit in the
ends of the two phantoms. In addition to this, we also sandwiched a
foam disk in the region to attempt to fill the flush concavities of
the two Catphan tops. 

Another problem with this particular data is related to contamination
of the beam at the edge of the axial FOV from the collimator blade
appearing in the FOV. Though this collimator blade would be slightly
inconvenient in a typical circular scan, it would not be excessively
problematic as it would appear in the region typically affected by
cone-angle artifacts. Here however, as the edge of the axial FOV
appears in the center of the image, this additional source of
inconsistency exacerbates an already challenging feature to
reconstruct with a CBCT system.

For future work on this particular use of non-circular trajectories,
it would first be beneficial to ensure the collimator blades do
encroach onto the detector. Especially along the axial extremes of the
detector as that will contaminate what would probably be the region of
most interest. It would also be nice to place an image quality module
in the overlap region to evaluate the image quality that this method
would be able to provide without the collimator blade contamination.

Despite the limitations of this study, the decision to place the image
quality modules at the axial position of the circle's source plane
gives an upper limit on what FDK can reasonably achieve, even as a
standalone circular scan comparison. By evaluating the two algorithms
at a location where FDK does satisfy Tuy's condition, we can see in
the results that MLEM can do just as well if not better than FDK.

For example, in the comparison of the stacked,
independently-reconstructed, dual-circle trajectories using both
algorithms, it can be seen that FDk fails to be consistent with itself
in the full-fan versus half-fan configuration. As Figure
([[ref:fig:fov_sensROI_full_half]]) shows, the CT numbers for the FDK with
the different detector configuration do not agree with each other. The
two detector configurations for MLEM however, not only are consistent
with each other, but they also fall between the two extremes bracketed
by the FDK results. The consistency of the MLEM results, and the fact
that they fall between the FDK results suggests that MLEM is probably
also closer to the real CT number.

Finally, it is important to point out that for the smooth trajectory,
the half-fan configuration does not provide complete support when
using the half-fan detector configuration. In a full-fan
configuration, the typical \pi-plus-fan-angle angular coverage
provides sufficient projection data. With the half-fan configuration
however, this is not the case; so as the axial-translation component
of the trajectory begins, there is insufficient support at the axial
extremes of the entire extended image.

However, as both the simulation and experimental results show,
distributing some of the angular coverage during the translation does
help to improve the image quality in the overlap region. As we have
mentioned, this would probably be the region of most interest if a
technique like this were used in the clinic. Therefore, while the
axial extremes of the extended volume are degraded, as can be seen in
Figure ([[ref:fig:fov_ed]]) especially in the shoulders of the torso
phantom, the streaking in the overlap region is significantly reduced
as opposed to the double circle and CLC trajectories. Therefore, if
using a half-fan configuration with such a trajectory, care must be
take to determine which part of the tomographic image requires higher
fidelity.

# - couch or C-arms show recon w/ both and also show table break

** Conclusion
   :PROPERTIES:
   :ID:       99a861bc-c072-4082-806f-9279fa7c3a3c
   :END:
We found that the use of our optimization-based, non-circular scanning
trajectories could successfully reconstruct extended-axial-FOV
reconstructions that are comparable to the current clinical image
quality achieved with a circular scan and FDK. In addition to being
able to maintain comparable image quality in the region where FDK
performs the best, our framework was able to extend the axial-FOV
coverage beyond the axial separation distances allowed to FDK by the
fundamental limitations of its support. Our hypothesis that our
optimization-based reconstruction framework could reconstruct from
extended axial coverage non-circular trajectories was correct. We also
found that the image quality from these reconstructions was at least
as good as the current clinical standard. Though additional studies
need to be conducted to perform quantitative image quality analysis in
the overlap region, we do know this framework provides a feasible
means addressing the limited axial FOV coverage that currently affects
the clinical use of CBCT in IGRT.
* Collision-avoiding trajectories            :col:
  :PROPERTIES:
  :ID:       99055e18-4b61-404e-9408-ebd5fd0a5d8d
  :END:
** notes                                     :noexport:
   :PROPERTIES:
   :ID:       53a46fd0-a854-4b6a-a253-dde04d4f7a87
   :END:
- General approach seems to be to make the chapters presentations of
  different studies (papers/proceedings) and the subsequent results
  and conclusions that can be made.
*** publications
    :PROPERTIES:
    :ID:       32703eae-6f65-4a6a-9f23-813e60747126
    :END:
- 2015 MIC virtual isocenter
- 2016 CT meeting dyanmic magnification
- 2016 MIC mixed magnification
- 2017 Varian dynamic magnification
** Introduction
   :PROPERTIES:
   :ID:       b0e53ca9-9c57-46e5-a558-c878b2ee1bdd
   :END:
Given the clinical benefits provided by the linac-mounted CBCT sytem,
it is detrimental when adequate tomographic information cannot be
obtained from the kV-imaging CBCT system. One such situation is when a
collision between the patient and the machine arises. While there has
been substantial work done aimed at the detection and avoidance of
collisions in treatment delivery
cite:humm_collision_1995,chao_image_2001,tsiakalos_graphical_2001,nioutsikou_patient-specific_2003,hua_practical_2004,becker_collision_2013,padilla_patient-specific_2014,padilla_collision_2015,
the methods are often insufficient for standard CBCT imaging because
they generally seek to avoid collisions preventing ideal treatment
positions and preventing complete collection of tomographic image
information. A generalized imaging framework such as the one we use
may allow for the use of patient-specific collision-avoiding CBCT
trajectories..

Collision avoiding trajectories may be of particular concern in breast
and lung cancer patients where the arm position increases the
likelihood of potential collisions as shown in Figure
([[ref:fig:col_barbie_collision]]). Collisions also present a problem in
treatment of posterior and lateral lesions in stereotactic body
radiosurgery (SBRT). Similarly in prone breast treatments, where the
target is near the couch top and a lateral couch translation is needed
to bring the target to isocenter, collision with the contralateral
side of the patient may occur. When collisions do occur, the angular
range available for scanning is restricted and it is not possible to
acquire a complete circular scan in the treatment position.

#+BEGIN_EXPORT latex
\begin{figure*}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/col/barbie_mv.png}
    \caption{}
    \label{fig:col_barbie_mv}
  \end{subfigure}
  ~%add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
  %(or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/col/barbie_kv.png}
    \caption{}
    \label{fig:col_barbie_kv}
  \end{subfigure}
  \caption{Two examples of potential collision for a
    typical patient setup using a mannequin in a supine treatment
    position. As can be seen, collisions can occur both with the face
    of the MV treatment head (distance 41.7 cm from isocenter for this
    linac) and with the kV detector (distance 45-70 cm from isocenter,
    depending on magnification).}
  \label{fig:col_barbie_collision}
\end{figure*}
#+END_EXPORT

To avoid collisions with the LINAC head, it might be desirable to move
the patient away from the gantry by translating the couch. To avoid
collisions with the imaging panel, the patient might also be moved
away from the panel. As many linac-mounted, kV-imaging panels have
motion capabilities, another solution would be to move the imager away
from the patient in the collision zone, which changes the imaging
magnification for that portion of the scan. Given that the clearance
distance of the kV-imaging panel is not much larger than that of the
MV-treatment head, a collision avoidance solution should account for
both of these components.

Here, we investigate trajectories that could allow the acquisition of
sufficient projection information for a clinically useful image while
avoiding a potential patient collision with the gantry such as those
shown in Figure ([[ref:fig:col_barbie_collision]]). One trajectory that
would avoid a patient collision with the MV-treatment head is a
virtual isocenter trajectory, which increases the effective
source-to-axis distance (SAD) for all gantry angles. By using this
increased SAD for an imaging trajectory, the clearance between the
patient and the MV-treatment head as the gantry rotates is increased
and the collision is avoided.

The virtual isocenter trajectory utilizes synchronized gantry rotation
and couch translation to maintain a fixed distance (``virtual SAD'')
between the MV source and a chosen center of rotation (``virtual
isocenter'') in the patient as shown by the red circle in Figure
([[ref:fig:col_virtual_iso]]). At the beginning of the scan, the patient
is moved away from the linac head along the MV beam direction. As the
gantry rotates, the couch moves continuously to maintain the specified
separation as shown in Figure ([[ref:fig:col_virtual_iso]]). The virtual
SAD can be chosen large enough such that collisions as shown in Figure
([[ref:fig:col_barbie_mv]]) are avoided; at this point in the trajectory,
the couch would have moved far enough to the left to avoid the
collision. Note that it is only the distance to the linac head that is
increased in the virtual SAD technique; the distance from the kV
source and detector to the patient and to each other are unchanged.

#+BEGIN_EXPORT latex
\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figures/col/gantry_3angles.eps}
\caption{Patient, kV and MV beams and kV detector at several angles
  during a virtual isocenter rotation. Room coordinate system (dotted
  axes) has its origin at mechanical isocenter, also the intersection
  of the MV (red) and kV (green) beam axes. As the gantry rotates, the
  patient (filled contour) is continually shifted to maintain a
  specified distance along the MV beam direction between the
  mechanical isocenter and the chosen virtual isocenter (circle symbol
  within the patient). The path of the virtual isocenter is a circle
  about the mechanical isocenter, with radius equal to the chosen
  shift (12 cm from the isocenter in this example). Detector may or
  may not be shifted as shown, depending on virtual isocenter position
  and patient geometry.
\label{fig:col_virtual_iso}}
\end{figure*}
#+END_EXPORT

Another trajectory that could avoid a patient collision with the kV
detector would be one during which either the patient or the detector
is moved during the scan in the angular range of a collision. Either
solution leads to changing kV-CBCT imaging magnification during the
acquisition. Again, optimization-based reconstruction methods can
readily handle such a change in magnification provided the projection
information is correctly incorporated into the system matrix.

Finally, we study a trajectory that combines virtual isocenter and
dynamic magnification trajectories to create a hybrid scanning
acquisition that could alleviate collisions with both the MV-treatment
head and the kV-CBCT detector. With such a trajectory, the potential
collisions with both the linac head and the kV detector panel are
resolved. We use such a trajectory as an example of a patient-specific
scanning trajectory that could be implemented to resolve potential
collisions with two components of the linac treatment system.

** Methods and Materials
   :PROPERTIES:
   :ID:       973b1793-b733-43ce-a7aa-dd31af58c680
   :END:
*** Scans
    :PROPERTIES:
    :ID:       dd0b68a5-c0eb-4c57-a28f-c27e2c57c8d8
    :END:
For the circular scans, the gantry made a full rotation about the
patient with the treatment volume at a fixed mechanical SAD of 100 cm.
For the virtual isocenter scans, the patient couch was translated
continuously in the gantry rotation plane during gantry rotation to
maintain a distance of 112 cm between the MV source and the chosen
target point within the treatment volume (the "virtual isocenter"),
rather than the mechanical SAD of 100 cm as shown in Figure
([[ref:fig:col_virtual_iso]]). We generated all of the scanning
trajectories in this study using the Developer Mode 2.0 XML schema to
define the positions of the gantry, the kV imaging arms, and the
patient treatment table. The schema was also used to enable
kV-projection imaging during the scan. We used a half-fan detector
configuration with a 13 cm offset for the circular acquisition, and an
equivalent offset for the virtual isocenter to obtain the same
illumination.

To increase the clearance between the kV detector and the patient, we
increased the radius of the kV detector with accompanying increase in
magnification of the kV imaging system. Currently, the detector
positioning arm cannot be moved while the gantry rotates. Thus, to
create projection datasets where the detector distance changes during
a scan, we acquired multiple scans using different detector positions
and subsequently spliced these together to create the sinograms of
interest with the corresponding system matrix $\mathcal{H}$. This
allowed us to create different dynamic magnification scan datasets. We
acquired both circular and virtual isocenter trajectories with
detector positions of 50 cm, 60 cm and 70 cm away from the mechanical
isocenter for magnifications of 1.5X, 1.6X and 1.7X respectively. In
each case, the detector cover is 5 cm closer to the patient than the
CsI layer, potentially leading to collisions with the limits shown in
the first plot in Figure ([[ref:fig:col_collision_zones]]).

#+CAPTION: Collision zones in the patient image space for the kV detector cover and the MV treatment head accessory mount. The left figure shows the increasing radius of the kV-detector collision zone with an increase in magnification. The middle figure shows the increased radius of the kV-detector collision zone for the two dynamic magnification trajectories utilizing a $45^{\circ}$ bump at a higher magnification. The right figure shows the increased radius of the MV-treatment-head collision zone when using the virtual isocenter scanning trajectory.
#+ATTR_LaTeX: :width \textwidth :float multicolumn
#+LABEL: fig:col_collision_zones
[[file:figures/col/collision_zones.pdf]]

To create the combined sinogram of a hypothetical collision-avoiding
dynamic magnification scan, we replaced a $45^{\circ}$ region of the 1.5X
circular scan with the corresponding angular range from scans at
different magnifications. We chose this region to be centered on the
angular position corresponding to the mannequin's elbow in Figure
([[ref:fig:col_barbie_collision]]). Increasing the magnification in this
region corresponds to increasing the clearance between the kV-detector
and the patient. Increasing the magnification to 1.6X and 1.7X
provides an additional 10 cm and 20 cm of clearance respectively. We
also created an additional $35^{\circ}$ 1.7X bump magnification with
$5^{\circ}$ transitions at a 1.6X magnification. The kV-detector
collision zones of these dynamic magnification trajectories are shown
in the middle plot shown in Figure ([[ref:fig:col_collision_zones]]).

The virtual isocenter imaging trajectory would alleviate the potential
collision with the MV treatment head accessory mount shown in Figure
([[ref:fig:col_barbie_mv]]). The radius of the accessory mount from the
mechanical isocenter is 41.7 cm. Using a virtual isocenter would
increase the radius of the collision zone by 12cm to alleviate
potential collisions (as shown in ([[ref:fig:col_collision_zones]])).
Utilizing a different virtual SAD would allow for additional clearance
if necessary.

The last set of trajectories we studied combines the dynamic
magnification with the virtual isocenter trajectory. As the collision
radius with the MV treatment head and the kV detector are similar for
the current clinical scan trajectories, collisions with either could
arise. By combining the change in magnification with the virtual
isocenter trajectory, both collision zones could be avoided. Table
([[ref:tab:col_trajectories]]) shows the different scans investigated in
this study.

# +ATTR_LATEX: :environment longtable
#+CAPTION: Scanning trajectories
#+NAME: tab:col_trajectories
|-------------------+------------------------------------------|
| Trajectory        | Magnification                            |
|-------------------+------------------------------------------|
| Circle            | 1.5X                                     |
|                   | 1.5X & $45^{\circ}$ 1.6X bump                   |
|                   | 1.5X & $45^{\circ}$ 1.7X bump                   |
|                   | 1.5X & $35^{\circ}$ 1.7X bump, 1.6X transitions |
|-------------------+------------------------------------------|
| Virtual isocenter | 1.5X                                     |
|                   | 1.5X & $45^{\circ}$ 1.6X bump                   |
|                   | 1.5X & $45^{\circ}$ 1.7X bump                   |
|                   | 1.5X & $35^{\circ}$ 1.7X bump, 1.6X transitions |
|-------------------+------------------------------------------|
**** figures                                 :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/collision_avoidance.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/collision_avoidance.ipynb]]
*** TODO [#A] Generalized-trajectory framework :noexport:
    DEADLINE: <2017-12-01 Fri>
In applying the generalized-reconstruction framework discussed in
[[id:58A6E225-522B-4620-BEDB-F81AD30070C3][Framework implementation with Varian TrueBeam kV-CBCT system]] to this
specific non-circular trajectory use case of collision avoidance, care
must be taken to correctly transform the coordinate system of the
imaging geometry to correctly with the patient's treatment. In the
case of utilizing the virtual isocenter to prevent potential patient
collisions with the linac treatment head, it was necessary to
implement these calculations in order to acquire projection
information that was equivalent to that of the standard clinical
scanning configuration.

*** Reconstruction
    :PROPERTIES:
    :ID:       d0eac288-37d6-4cef-97c8-7896dcc67733
    :END:
The addition of couch motion to the imaging trajectory does increase
the degrees of freedom for which proper geometric calibration must be
acquired. Using the methods described in the chapter [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Geometric
calibration]], we computed corrections to the nominal reported couch,
source and detector positions for each of the tested trajectories.

We reconstructed all of these fixed magnification and dynamic
magnification scans from circular and virtual isocenter trajectories
into the patient image space described by the imaging model in
Equation ([[ref:eq:opt_linmodel_patient]]). The Catphan scans were
reconstructed onto an isotropic voxel size of 0.473 mm. The CIRS torso
scans were reconstructed onto an isotropic voxel size of 0.836 mm. As
the circular acquisition with 1.5X magnification is the typical
clinical acquisition trajectory, this provides a clinical reference
volume for the reconstructions from the other scanning configurations.

#+CAPTION: Plot of the Catphan's edge-spread function MTF at 50% and 25% as well as the MTF AUC for the clinical circular 1.5X half-fan scan. The effectie plateau in these spatial resolution metrics at 200 iterations is why we selected this as the fixed iteration number for all of our reconstructions.
#+ATTR_LaTeX: :width 0.8\textwidth
#+LABEL: fig:col_mtf_vs_iteration
[[file:figures/col/edge_spread_mtf_iteration.pdf]]


For the number of iterations in our reconstruction program, we
selected 200 iterations as subsequent improvements in spatial
resolution with further iterations were diminished. This is shown in
Figure ([[ref:fig:col_mtf_vs_iteration]]) which plots as a function of
iteration numnber the 25% and 50% crossing spatial frequencies of the
modular transfer function (MTF) and the area under the curve (AUC) of
the MTF. The MTF was found using the edge spread function from the
MLEM reconstruction of the Catphan phantom acquired with a circular
scan at 1.5X magnification.
**** figs                                    :noexport:
***** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/iteration_plots.ipynb")][truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/iteration_plots.ipynb]]
*** analysis                                 :noexport:
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"161213_virtiso_circ_half_dynmag_catphan_isocal/collision_avoidance.ipynb")][collisions figures]]
- [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"170126_virtiso_circ_half_dynmag_ed/ed_images.ipynb")][ed analysis]]
** Results
   :PROPERTIES:
   :ID:       28832b04-7d26-4ef8-83f2-08db94493ab9
   :END:
Figure ([[ref:fig:col_recons_catphan]]) shows slices of the CTP 528
spatial-resolution module from the $200^{\text{th}}$ iteration of the
MLEM reconstructions of the Catphan phantom for the different scanning
trajectories. The top row shows reconstructions from the circular
scanning trajectories, and the bottom row shows reconstructions from
the virtual isocenter trajectories. The left column is from a single
1.5X magnification, and the remaining columns are different
synthesized trajectories with different magnifications as illustrated
in Figure ([[ref:fig:col_collision_zones]]). In all of these images, the
$8^{\text{th}}$ largest gauge is visually resolvable.

#+CAPTION: Images of the Catphan 528 spatial resolution module in a display window of [-100, 2000] HU. The top row shows all the circular scan permutations while the bottom row shows those of the virtual isocenter. The columns show different magnification combinations from left to right of 1.5X only, 1.5X with a 1.6X bump, 1.5X with a 1.7X bump, and a 1.5X with a 1.7X bump and a 1.6X transition on either side. For all of the reconstructions, the 8$^{\text{th}}$ largest gauge is resolvable (indicated by the red arrow).
#+ATTR_LaTeX: :width \textwidth :float multicolumn
#+LABEL: fig:col_recons_catphan
[[file:figures/col/catphanDynmagQuarter.pdf]]

The visual similarity in the spatial resolution shown in Figure
([[ref:fig:col_recons_catphan]]) is reflected in the MTF metrics for all of
the different scanning configurations. We compared MTF metrics derived
from the PSF using the Catphan beads, the bar pattern shown in Figure
([[ref:fig:col_recons_catphan]]), and the edge-spread function (ESF) measure
along an ensemble of radial lines. When comparing these MTF-based
metrics between the circle and the virtual isocenter scans with
different magnifications, we found no clear trend distinguishing the
different trajectories.

#+CAPTION: Plot of low-contrast polystyrene CNR and error bars corresponding to $\pm$ one standard deviation of the CNR from the Catphan scanned with both the circular and virtual isocenter trajectories.
#+ATTR_LaTeX: :width 0.8\textwidth
#+LABEL: fig:col_catphan_cnr
[[file:figures/col/catphanCNR_ps.pdf]]

Figure ([[ref:fig:col_catphan_cnr]]) shows the low-contrast CNR from the
Catphan with these different imaging configurations which are also in
good agreement with each other. In addition to using the material rods
in the CTP 404 sensitometry module to calculate the CNR, we also
compared mean values from each of the materials for the different
scanning trajectories and magnifications. Figure
([[ref:fig:col_catphan_rois]]) shows the ROI means for these different
scanning configurations. The height of the bar represents the standard
deviation of the ROI. The first four bars for each material are from
the circular scans, and the remaining four from the virtual isocenter
scans.

#+BEGIN_EXPORT latex
\begin{figure*}
  \centering
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figures/col/sensROIplot.pdf}
    \caption{}
    \label{fig:col_catphan_rois}
  \end{subfigure}
  ~%add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
  %(or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{\textwidth}
    \includegraphics[width=\textwidth]{figures/col/edROIplot.pdf}
    \caption{}
    \label{fig:col_ed_rois}
  \end{subfigure}
  \caption{ROI material comaprison results for the Catphan CTP 404
    module and the CIRS torso phantom. The height of the bars are $\pm$
    one standard deviation of the ROI mean. The first four bars for
    each material ROI are from the circular scans, and the remaining four
    bars for each material ROI are from the virtual isocenter scans. The
    order of the scans for each material ROI are displayed in the order listed in the
    legend in (a) from left to right.}
  \label{fig:col_hu_results}
\end{figure*}
#+END_EXPORT

#+CAPTION: Images of the CIRS torso phantom's abdomen in a display window of display window of [-100, 200] HU. The top row shows all the circular scan permutations while the bottom row shows those of the virtual isocenter. The columns show different magnification combinations from left to right of 1.5X only, 1.5X with a 1.6X bump, 1.5X with a 1.7X bump, and a 1.5X with a 1.7X bump and a 1.6X transition on either side.
#+ATTR_LaTeX: :width \textwidth :float multicolumn :placement
#+LABEL: fig:col_recons_ed
[[file:figures/col/edDynmag_soft.pdf]]

Figure ([[ref:fig:col_recons_ed]]) shows an abdominal slice from the
$200^{\text{th}}$ iteration MLEM reconstruction of the CIRS torso phantom
scanned with a 13 cm offset half-fan configuration. The layout of
these images is the same as that in Figure
([[ref:fig:col_recons_catphan]]) with the top row showing magnification
variations from the circular trajectory. The bottom row shows the
corresponding magnifications from the virtual isocenter trajectory.
The slice is the same as that in Figure ([[ref:fig:col_ed_rois]]) which we
used to calculate values for three organ ROIs.

For the different organ ROIs, we recorded the means and standard
deviations for the different scanning trajectories and magnifications.
Figure ([[ref:fig:col_ed_rois]]) shows these mean values and the
associated standard deviations. Though the circular scan variations
fluctuate more than the virtual isocenter scans, the values are in
agreement for the different organs of interest. As with Figure
([[ref:fig:col_catphan_rois]]), the first four points for each organ are
from the circular scan, and the remaining four are from the virtual
isocenter trajectory.
*** fixed illumination analysis              :noexport:
**** [[file:/ssh:remus:/data/amdavis/truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/figs/][figs]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/catphan_images.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/catphan_images.ipynb]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/metric_analysis.ipynb")][truebeam/170603_virtiso_circ_smth_catphan/dynmag/em/dlatlonslon/metric_analysis.ipynb]]
*** new analysis                             :noexport:
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/catphan_images.ipynb")][161213_virtiso_circ_half_dynmag_catphan_isocal/catphan_images.ipynb]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/161213_virtiso_circ_half_dynmag_catphan_isocal/metrics.ipynb")][161213_virtiso_circ_half_dynmag_catphan_isocal/metrics.ipynb]]
**** [[ipynb:(:url-or-port%20"https://remus.uchicago.edu:9999"%20:name%20"truebeam/170126_virtiso_circ_half_dynmag_ed/ed_images.ipynb")][170126_virtiso_circ_half_dynmag_ed/ed_images.ipynb]]
*** old analysis                             :noexport:
    :PROPERTIES:
    :var:      iter=75
    :ID:       c2336149-1ac8-4474-ae0a-ed1b97efcdf8
    :END:
**** catphan
     :PROPERTIES:
     :ID:       066a0563-0e56-4ae2-ba5d-66c120f05c92
     :END:
***** contrast
      :PROPERTIES:
      :ID:       12232f76-bd36-4c93-abc4-3d14828dbbc5
      :END:
****** images
       :PROPERTIES:
       :ID:       9694ff06-d9cc-40f0-aaa1-7e5b3f937bf5
       :END:
 #+BEGIN_SRC python :results file
import dicom
import glob
import numpy as np
import matplotlib.pyplot as plt

from IPython.core.debugger import Tracer
debug_here = Tracer()

def crop(center, width, res):
    """Crop image

    Keyword Arguments:
    center -- [x, y] of center
    width  -- deisred width (mm)
    res    -- res (mm/px)
    """
    px_width = np.int(width*0.5/res)

    xbox = [center[0]-px_width, center[0]+px_width]
    ybox = [center[1]-px_width, center[1]+px_width]

    return(xbox, ybox)

# window
window_hu = [-160, 240]         # HU
window_em = [0.015, 0.026]      # mm^1

# itools
catphan_dcm = dicom.read_file(('itools/161213_catphan_circ_1p5x_ringrem/IMG_0043.dcm'))
catphan_hu = catphan_dcm.pixel_array*catphan_dcm.RescaleSlope+catphan_dcm.RescaleIntercept

# crop
width = 230.                 # mm each way

res_hu = 0.473                 # mm/px
center_hu = [np.int(catphan_hu.shape[0]*0.5), np.int(catphan_hu.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

catphan_hu = catphan_hu[winx[0]:winx[1], winy[0]:winy[1]]

plt.imsave('figures/catphan_itools_lcr.png', catphan_hu, vmin=window_hu[0], vmax=window_hu[1])

# recon
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"

files = sorted(glob.glob(dir+"*catphan*itools*{0:04d}*.raw".format(iter)))

catphan_circular = np.fromfile(files[0], 'f').reshape(125, 528, 528).swapaxes(1, 2).T
catphan_virtiso = np.fromfile(files[1], 'f').reshape(125, 528, 528).swapaxes(1, 2).T

catphan_circular = catphan_circular[...,
                                    int(catphan_circular.shape[2]/2)]
catphan_virtiso = catphan_virtiso[...,
                                  int(catphan_virtiso.shape[2]/2)]

# crop
res_hu = 0.473                 # mm/px
center_circular = [np.int(catphan_circular.shape[0]*0.5), np.int(catphan_circular.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

catphan_circular = catphan_circular[winx[0]:winx[1], winy[0]:winy[1]]
catphan_virtiso = catphan_virtiso[winx[0]:winx[1], winy[0]:winy[1]]

plt.imsave('figures/catphan_circular_lcr_mlem_iter_{0:03d}.png'.format(iter), catphan_circular, vmin=window_em[0], vmax=window_em[1])
plt.imsave('figures/catphan_virtiso_lcr_mlem_iter_{0:03d}.png'.format(iter), catphan_virtiso, vmin=window_em[0], vmax=window_em[1])

# return('figures/catphan_itools_lcr.png')
# return('figures/catphan_circular_lcr_mlem.png')
# return('figures/catphan_virtiso_lcr_mlem.png')

fig = plt.figure()
ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

ax1.imshow(catphan_hu, vmin=window_hu[0], vmax=window_hu[1])
ax1.set_title('Circular iTools FDK')
ax1.axis('off')

ax2.imshow(catphan_circular, vmin=window_em[0], vmax=window_em[1])
ax2.set_title('Circular MLEM')
ax2.axis('off')

ax3.imshow(catphan_virtiso, vmin=window_em[0], vmax=window_em[1])
ax3.set_title('Virtual Isocenter MLEM')
ax3.axis('off')

fig.savefig('figures/catphan_comparison_iter_{0:03d}.png'.format(iter), bbox_inches="tight")
return('figures/catphan_comparison_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/catphan_comparison_iter_075.png]]
****** itools analysis
       :PROPERTIES:
       :ID:       bc6df6dd-13e6-4bc5-826c-2002d54ab552
       :END:
  Contrast analysis for catphan

 #+BEGIN_SRC python :results output
import dicom
import numpy as np
import matplotlib.pyplot as plt

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

catphan_dcm = dicom.read_file(('itools/161213_catphan_circ_1p5x_ringrem/IMG_0042.dcm'))
catphan_hu = catphan_dcm.pixel_array*catphan_dcm.RescaleSlope+catphan_dcm.RescaleIntercept

itools_lcr = lcr.CatphanLowContrast(catphan_hu, xres=0.473, x0=121.8/0.473,
                                    y0=121.6/0.473, z=0, rot=-3.48, hu=True)

itools_lcr.save_contrast_calcs('data/', 'catphan_circular_itools')

# itools_lcr.show_rod_locs(vmin=-60, vmax=60)
# plt.savefig('figures/catphan_itools_lcr_locs.png')
# return('figures/catphan_itools_lcr_locs.png')
print(itools_lcr.contrast_1_0)
print(itools_lcr.contrast_0_5)
print(itools_lcr.contrast_0_3)
 #+END_SRC

 #+RESULTS:
 #+begin_example
              % contrast  % contrast sigma       cnr  cnr sigma
rod diameter
15.0            1.273217          1.022240  1.236393   1.414493
9.0             1.157174          1.021059  1.100177   1.415368
8.0             0.767365          1.017061  0.898154   1.437275
7.0             1.198443          1.021447  1.296850   1.420209
6.0             0.486577          1.014224  0.484239   1.414228
5.0             0.860374          1.018018  0.881201   1.415018
4.0             0.763490          1.017019  0.933650   1.452495
3.0             0.356576          1.012901  0.589711   1.701662
2.0             1.844718          1.027938  2.757142   1.586562
              % contrast  % contrast sigma       cnr  cnr sigma
rod diameter
15.0            0.501931          1.033669  0.492042   1.414261
9.0             0.094065          1.029462  0.093504   1.414567
8.0             0.392379          1.032535  0.429770   1.425485
7.0            -0.057559          1.027902  0.061673   1.421552
6.0             0.466486          1.033301  0.477422   1.416169
5.0             0.405244          1.032665  0.482771   1.449648
4.0            -0.082372          1.027647  0.091132   1.427591
3.0            -0.630458          1.022024  0.675272   1.421494
2.0            -0.591860          1.022407  0.984642   1.735271
              % contrast  % contrast sigma       cnr  cnr sigma
rod diameter
15.0            0.162203          0.979250  0.181559   1.420491
9.0            -0.001550          0.977648  0.001615   1.414454
8.0             0.488048          0.982444  0.519364   1.415367
7.0             0.614937          0.983694  0.624087   1.414256
6.0             0.189741          0.979519  0.207107   1.417398
5.0             1.030511          0.987745  1.524829   1.548857
4.0             0.985444          0.987344  1.008152   1.414214
3.0             0.322520          0.980822  0.318188   1.415103
2.0            -0.096169          0.976723  0.107345   1.420092
 #+end_example
****** recon em analysis
       :PROPERTIES:
       :ID:       73598a41-2659-4be4-8473-9086ba73c896
       :END:
 Results from my reconstructions

 #+BEGIN_SRC python :results output
import glob
import numpy as np
import matplotlib.pyplot as plt

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

# get files we have
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"
files = sorted(glob.glob(dir+"*catphan*itools*{0:04d}*.raw".format(iter)))

catphan_circular = np.fromfile(files[0], 'f').reshape(125, 528, 528).swapaxes(1, 2).T
catphan_virtiso = np.fromfile(files[1], 'f').reshape(125, 528, 528).swapaxes(1, 2).T

catphan_circular = catphan_circular[...,
                                    int(catphan_circular.shape[2]/2)]
catphan_virtiso = catphan_virtiso[...,
                                  int(catphan_virtiso.shape[2]/2)]

circular_lcr = lcr.CatphanLowContrast(catphan_circular, xres=0.473,
                                      x0=263.5, y0=261.5, z=0, rot=-3.,
                                      hu=False)

virtiso_lcr = lcr.CatphanLowContrast(catphan_virtiso, xres=0.473,
                                     x0=272, y0=259.5, z=0, rot=-3.,
                                     hu=False)

circular_lcr.save_contrast_calcs('data/', 'catphan_circular_mlem_iter_{0:03d}'.format(iter))
virtiso_lcr.save_contrast_calcs('data/', 'catphan_virtiso_mlem_iter_{0:03d}'.format(iter))

# circ_fig = circular_lcr.show_rod_locs(vmin=0.02, vmax=0.021)
# virt_fig = virtiso_lcr.show_rod_locs(vmin=0.019, vmax=0.021)

# circ_fig.savefig('figures/catphan_circular_mlem_lcr_locs.png')
# virt_fig.savefig('figures/catphan_virtiso_mlem_lcr_locs.png')
# return('figures/catphan_circular_mlem_lcr_locs.png')
# return('figures/virtiso_circular_mlem_lcr_locs.png')

print("\n0.3% circular")
print(circular_lcr.contrast_0_3)
print("\n0.3% virtiso")
print(virtiso_lcr.contrast_0_3)

print("\n0.5% circular")
print(circular_lcr.contrast_0_5)
print("\n0.5% virtiso")
print(virtiso_lcr.contrast_0_5)

print("\n1.0% circular")
print(circular_lcr.contrast_1_0)
print("\n1.0% virtiso")
print(virtiso_lcr.contrast_1_0)
 #+END_SRC

 #+RESULTS:
 #+begin_example

0.3% circular
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.336178          0.632722  0.757847   1.423412
9.0     0.292402          0.669551  0.619270   1.415762
8.0     0.131968          0.623152  0.302362   1.426568
7.0     0.431134          0.613007  1.009752   1.431675
6.0     0.290603          0.656327  0.628716   1.417611
5.0     0.422215          0.665411  0.900781   1.416314
4.0     0.155166          0.543975  0.431161   1.509609
3.0    -0.297085          0.688549  0.609311   1.414347
2.0     0.472236          0.741477  0.903903   1.416268

0.3% virtiso
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.382718          0.830310  0.658319   1.424841
9.0     0.092026          0.799518  0.165280   1.435069
8.0    -0.107992          0.868174  0.176177   1.417189
7.0    -0.103785          0.786340  0.190046   1.440932
6.0    -0.309173          0.774152  0.576760   1.447345
5.0    -0.309976          0.759113  0.594024   1.458054
4.0    -0.223083          1.130837  0.282885   1.435041
3.0    -0.471983          0.698019  1.039611   1.543806
2.0    -1.038081          0.691397  2.308892   1.551891

0.5% circular
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.335700          0.647368  0.735412   1.415590
9.0     0.015566          0.591873  0.037623   1.430468
8.0     0.560906          0.624661  1.278832   1.419516
7.0     0.200324          0.689673  0.411264   1.414540
6.0    -0.258247          0.630936  0.579385   1.417608
5.0     0.550274          0.624253  1.255414   1.419604
4.0     0.465531          0.577228  1.165342   1.440343
3.0     0.078896          0.601583  0.187137   1.426210
2.0    -0.371316          0.476344  1.444140   1.859480

0.5% virtiso
      % contrast  % contrast sigma       cnr  cnr sigma
15.0   -0.323800          0.992989  0.467154   1.435720
9.0    -0.265211          0.949907  0.405867   1.456524
8.0     0.103588          0.939622  0.161663   1.465258
7.0     0.500131          0.977952  0.741149   1.444188
6.0     0.876336          0.922225  1.421072   1.485184
5.0     0.751536          0.897809  1.275159   1.513860
4.0     0.118879          0.984507  0.174040   1.440150
3.0     1.058663          1.008137  1.516077   1.433655
2.0     0.703962          0.820208  1.728628   2.000000

1.0% circular
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    0.891881          0.658649  1.933036   1.420049
9.0     0.723097          0.732432  1.401420   1.414637
8.0     0.697721          0.628473  1.594919   1.430160
7.0     0.958346          0.679275  2.008902   1.416360
6.0     0.700465          0.639470  1.568403   1.425579
5.0     0.878039          0.685795  1.821070   1.415579
4.0     0.613320          0.672501  1.296906   1.417139
3.0     0.315199          0.567085  0.827869   1.485735
2.0     0.664848          0.506692  2.641720   2.000000

1.0% virtiso
      % contrast  % contrast sigma       cnr  cnr sigma
15.0    1.216002          0.926873  1.869765   1.415754
9.0     0.418370          0.884876  0.673363   1.420661
8.0     1.236294          0.892132  1.982379   1.420123
7.0     0.963466          0.803941  1.755233   1.454411
6.0     1.147464          0.792635  2.137994   1.464240
5.0     0.164518          0.983530  0.236795   1.414503
4.0    -0.124803          0.796152  0.227947   1.455467
3.0    -0.180899          0.874025  0.294034   1.422201
2.0    -1.164900          0.681244  2.957545   1.749484
 #+end_example
****** plots
       :PROPERTIES:
       :ID:       229ce930-658c-447c-9cbc-d1958f97022b
       :END:
******* CNR
        :PROPERTIES:
        :ID:       184b9d1e-9b95-4aa3-a7f9-127053b3246e
        :END:
 #+BEGIN_SRC python :results file
import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas
import seaborn as sns

sns.set(font='serif', font_scale=0.8)

from itertools import cycle
lines = ["-","--","-."]
linecycler = cycle(lines)

from matplotlib.ticker import FormatStrFormatter

# setup plot params
sns.set_context("paper")

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

# load previous calculations
circ_fdk = sorted(glob.glob("data/*itools*rods.pkl"))
circ_em = sorted(glob.glob("data/*circular_mlem*_iter_{0:03d}*rods.pkl".format(iter)))
virt_em = sorted(glob.glob("data/*virtiso*_iter_{0:03d}*rods.pkl".format(iter)))

# load 0.3%, 0.5%, 1.0% rod contrast
circ_fdk = [pandas.read_pickle(f) for f in circ_fdk]
circ_em = [pandas.read_pickle(f) for f in circ_em]
virt_em = [pandas.read_pickle(f) for f in virt_em]

# data sets
titles = ['0.3% contrast rods', '0.5% contrast rods', '1.0% contrast rods']

fig, axs = plt.subplots(3, 1, True)

for j, ax in enumerate(axs):
    ax.errorbar(circ_fdk[j].index, 'cnr', yerr='cnr sigma', data=circ_fdk[j], label='FDK Circular', ls=next(linecycler))
    ax.errorbar(circ_em[j].index, 'cnr', yerr='cnr sigma', data=circ_em[j], label='MLEM Circular', ls=next(linecycler))
    ax.errorbar(virt_em[j].index, 'cnr', yerr='cnr sigma', data=virt_em[j], label='MLEM Virtual Isocenter', ls=next(linecycler))

    ax.set_xlim([1, 16])
    # ax.set_ylim([-3, 3])
    ax.set_ylabel('CNR')
    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))
    ax.set_title(titles[j])

ax.legend(loc='best', fancybox=True, framealpha=0.5)
ax.set_xlabel('Rod diameter [mm]')

fig.savefig('figures/cnr_iter_{0:03d}.pdf'.format(iter))

fig.savefig('figures/cnr_iter_{0:03d}.png'.format(iter))
return('figures/cnr_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/cnr_iter_075.png]]

******* % contrast
        :PROPERTIES:
        :ID:       03ee4467-a1d4-4d7e-8c12-b8e767bf43a3
        :END:
 #+BEGIN_SRC python :results file
import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas
import seaborn as sns

sns.set(font='serif', font_scale=0.8)

from itertools import cycle
lines = ["-","--","-."]
linecycler = cycle(lines)

from matplotlib.ticker import FormatStrFormatter

# setup plot params
sns.set_context("paper")

from phantoms import lcr

from IPython.core.debugger import Tracer
debug_here = Tracer()

# load previous calculations
circ_fdk = sorted(glob.glob("data/*itools*rods.pkl"))
circ_em = sorted(glob.glob("data/*circular_mlem*_iter_{0:03d}*rods.pkl".format(iter)))
virt_em = sorted(glob.glob("data/*virtiso*_iter_{0:03d}*rods.pkl".format(iter)))

# load 0.3%, 0.5%, 1.0% rod contrast
circ_fdk = [pandas.read_pickle(f) for f in circ_fdk]
circ_em = [pandas.read_pickle(f) for f in circ_em]
virt_em = [pandas.read_pickle(f) for f in virt_em]

# data sets
titles = ['0.3% contrast rods', '0.5% contrast rods', '1.0% contrast rods']

fig, axs = plt.subplots(3, 1, True)

for j, ax in enumerate(axs):
    ax.errorbar(circ_fdk[j].index, '% contrast', yerr='% contrast sigma', data=circ_fdk[j], label='FDK Circular', ls=next(linecycler))
    ax.errorbar(circ_em[j].index, '% contrast', yerr='% contrast sigma', data=circ_em[j], label='MLEM Circular', ls=next(linecycler))
    ax.errorbar(virt_em[j].index, '% contrast', yerr='% contrast sigma', data=virt_em[j], label='MLEM Virtual Isocenter', ls=next(linecycler))

    ax.set_xlim([1, 16])
    ax.set_ylim([-3, 3])
    ax.set_ylabel('% contrast')
    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))
    ax.set_title(titles[j])

ax.legend(loc='best', fancybox=True, framealpha=0.5)
ax.set_xlabel('Rod diameter [mm]')

fig.savefig('figures/percent_contrast_iter_{0:03d}.pdf'.format(iter))

fig.savefig('figures/percent_contrast_iter_{0:03d}.png'.format(iter))
return('figures/percent_contrast_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/percent_contrast_iter_075.png]]

***** spatial res
      :PROPERTIES:
      :ID:       b755dc97-c01c-461c-99d3-7f116bfc4f5f
      :END:
****** images
       :PROPERTIES:
       :ID:       1a7be01c-fc76-42bf-a09d-7e7556456fd8
       :END:
  #+BEGIN_SRC python :results file
import dicom
import glob
import numpy as np
import matplotlib.pyplot as plt

from IPython.core.debugger import Tracer
debug_here = Tracer()


def crop(center, width, res):
    """Crop image

    Keyword Arguments:
    center -- [x, y] of center
    width  -- deisred width (mm)
    res    -- res (mm/px)
    """
    px_width = np.int(width*0.5/res)

    xbox = [center[0]-px_width, center[0]+px_width]
    ybox = [center[1]-px_width, center[1]+px_width]

    return(xbox, ybox)

# window
window_hu = [150, 1000]         # HU
window_em = [0.022, 0.032]      # mm^1

# itools
catphan_dcm = dicom.read_file(('itools/150902_catphan_full_low_contrast/hu/IMG_0075.dcm'))
catphan_hu = catphan_dcm.pixel_array*catphan_dcm.RescaleSlope+catphan_dcm.RescaleIntercept

# crop
width = 130.                 # mm each way

res_hu = 0.473                 # mm/px
center_hu = [np.int(catphan_hu.shape[0]*0.5), np.int(catphan_hu.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

catphan_hu = catphan_hu[winx[0]:center_hu[0], winy[0]:winy[1]]

plt.imsave('figures/catphan_itools_sr.png', catphan_hu, vmin=window_hu[0], vmax=window_hu[1])

# recon
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"
files = sorted(glob.glob(dir+"*catphan*itools*{0:04d}*.raw".format(iter)))

catphan_circular = np.fromfile(files[0], 'f').reshape(125, 528, 528).swapaxes(1, 2).T
catphan_virtiso = np.fromfile(files[1], 'f').reshape(125, 528, 528).swapaxes(1, 2).T

sr_slice = 93
catphan_circular = catphan_circular[..., sr_slice]
catphan_virtiso = catphan_virtiso[..., sr_slice]

# crop
res_em = 0.5                 # mm/px
center_circular = [np.int(catphan_circular.shape[0]*0.5), np.int(catphan_circular.shape[1]*0.5)]

winx, winy = crop(center_circular, width, res_em)

catphan_circular = catphan_circular[winx[0]:center_circular[0], winy[0]:winy[1]]
catphan_virtiso = catphan_virtiso[winx[0]:center_circular[0], winy[0]:winy[1]]

plt.imsave('figures/catphan_circular_sr_mlem_iter_{0:03d}.png'.format(iter), catphan_circular, vmin=window_em[0], vmax=window_em[1])
plt.imsave('figures/catphan_virtiso_sr_mlem_iter_{0:03d}.png'.format(iter), catphan_virtiso, vmin=window_em[0], vmax=window_em[1])

# return('figures/catphan_itools_sr.png')
# return('figures/catphan_circular_sr_mlem.png')
# return('figures/catphan_virtiso_sr_mlem.png')

fig = plt.figure()
ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

ax1.imshow(catphan_hu, vmin=window_hu[0], vmax=window_hu[1])
ax1.set_title('Circular iTools FDK')
ax1.axis('off')

ax2.imshow(catphan_circular, vmin=window_em[0], vmax=window_em[1])
ax2.set_title('Circular MLEM')
ax2.axis('off')

ax3.imshow(catphan_virtiso, vmin=window_em[0], vmax=window_em[1])
ax3.set_title('Virtual Isocenter MLEM')
ax3.axis('off')

fig.savefig('figures/catphan_comparison_sr_iter_{0:03d}.png'.format(iter), bbox_inches="tight")
return('figures/catphan_comparison_sr_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/catphan_comparison_sr_iter_075.png]]
**** ed
     :PROPERTIES:
     :ID:       fc37283b-966f-4f98-8693-4c885b4c516d
     :END:
  Generate slices for Ed
  #+BEGIN_SRC python :results file
import glob
import numpy as np
import matplotlib.pyplot as plt
import dicom
# import pickle

# window
window_hu = [-200, 240]         # HU
window_em = [0.015, 0.025]      # mm^1

from IPython.core.debugger import Tracer
debug_here = Tracer()


def crop(center, width, res):
    """Crop image

    Keyword Arguments:
    center -- [x, y] of center
    width  -- deisred width (mm)
    res    -- res (mm/px)
    """
    px_width = np.int(width*0.5/res)

    xbox = [center[0]-px_width, center[0]+px_width]
    ybox = [center[1]-px_width, center[1]+px_width]

    return(xbox, ybox)

# itools
ed_dcm = dicom.read_file(('itools/150902_ed_circular_half_13cm_offset/hu/IMG_0042.dcm'))
ed_hu = ed_dcm.pixel_array*ed_dcm.RescaleSlope+ed_dcm.RescaleIntercept

# crop
width = 300.                 # mm each way

res_hu = 0.836                 # mm/px
center_hu = [np.int(ed_hu.shape[0]*0.5), np.int(ed_hu.shape[1]*0.5)]

winx, winy = crop(center_hu, width, res_hu)

ed_hu = ed_hu[winx[0]:winx[1], winy[0]:winy[1]]

# recon
dir = "/home/amdavis/research/truebeam/150902_virtiso_cbct_catphan_ed/itools/img/"
files = sorted(glob.glob(dir+"*ed*itools*{0:04d}*.raw".format(iter)))

ed_circular = np.fromfile(files[0], 'f').reshape(126, 418, 418).swapaxes(1, 2).T
ed_virtiso = np.fromfile(files[1], 'f').reshape(126, 418, 418).swapaxes(1, 2).T

ed_circular = ed_circular[..., int(ed_circular.shape[2]/2+1)]
ed_virtiso = ed_virtiso[..., int(ed_virtiso.shape[2]/2+1)]

# crop
res_em = 0.836                    # mm/px
center_em = [int(ed_circular.shape[0]*0.5), int(ed_circular.shape[1]*0.5)]

winx, winy = crop(center_em, width, res_em)

ed_circular = ed_circular[winx[0]:winx[1], winy[0]:winy[1]]
ed_virtiso = ed_virtiso[winx[0]:winx[1], winy[0]:winy[1]]

# save img slice
plt.imsave('figures/ed_itools_fdk.png', ed_hu, vmin=window_hu[0], vmax=window_hu[1])
plt.imsave('figures/ed_circular_mlem_iter_{0:03d}.png'.format(iter), ed_circular, vmin=window_em[0], vmax=window_em[1])
plt.imsave('figures/ed_virtiso_mlem_iter_{0:03d}.png'.format(iter), ed_virtiso, vmin=window_em[0], vmax=window_em[1])

# return('figures/ed_itools_fdk.png')
# return('figures/catphan_circular_lcr_mlem.png')
# return('figures/catphan_virtiso_lcr_mlem.png')

# display all three
fig = plt.figure()
ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

ax1.imshow(ed_hu, vmin=window_hu[0], vmax=window_hu[1])
ax1.set_title('Circular iTools FDK')
ax1.axis('off')

ax2.imshow(ed_circular, vmin=window_em[0], vmax=window_em[1])
ax2.set_title('Circular MLEM')
ax2.axis('off')

ax3.imshow(ed_virtiso, vmin=window_em[0], vmax=window_em[1])
ax3.set_title('Virtual Isocenter MLEM')
ax3.axis('off')

fig.savefig('figures/ed_comparison_iter_{0:03d}.png'.format(iter), bbox_inches="tight")
return('figures/ed_comparison_iter_{0:03d}.png'.format(iter))
 #+END_SRC

 #+RESULTS:
 [[file:figures/ed_comparison_iter_075.png]]

** Discussion
   :PROPERTIES:
   :ID:       5d03aa38-f620-4ad1-a60d-f02d5000ea97
   :END:
# *summarize experiment and results in first discussion paragraph*

As mentioned earlier, the virtual isocenter trajectory is designed to
increase the distance between the gantry head and the patient by
synchronized table translation and gantry motion. The geometry of the
imaging arms remains unchanged, though the center of the image space
is moved from the mechanical isocenter to the virtual isocenter. As
shown in the previous section, this results in CBCT image quality that
is comparable to a normal circular scan.

It is certainly possible to envision situations in which collisions
with the kV imaging source or (more likely) the detector also occur.
The system matrix in our optimization-based reconstruction method can
incorporate changes in the position of the imaging arms as well as the
patient position. Thus a trajectory with variable source-detector
distance, caused by the detector moving to avoid a patient collision,
can also be reconstructed. Such a variable magnification scan may be
performed with the patient couch moving in a virtual isocenter
trajectory, or with the patient couch fixed and rotation about the
physical machine isocenter.

All virtual isocenter scanning in the present work was done in
TrueBeam Developer Mode, which is a strictly nonclinical mode of
operation. Simultaneous motion of couch, gantry and imaging arms is
not fully supported by the TrueBeam; however, the motions required for
the virtual isocenter scan, which involve only coupled gantry rotation
and couch translation, are feasible in Developer Mode. Although the
linac can clearly execute the required motions and acquire the images,
virtual isocenter scanning is as yet not available as a clinical
capability. In addition, these scans must be reconstructed using
iterative optimization-based methods, rather than the current
clinically available filtered back-projection method. A historic
concern about optimization-based methods has been reconstruction
speed. These are very computationally intensive programs, but with the
recent availability of GPU-based processing, reconstruction times are
more manageable.

** Conclusion
   :PROPERTIES:
   :ID:       016dd868-817a-44fc-8717-e64fdc5bc0d3
   :END:
Virtual isocenter trajectories and dynamic magnification are
potentially useful as collision-avoiding alternatives to standard
isocentric rotation, both in cases where arc treatments are being
delivered and in cases where CBCT scanning is desirable, but a normal
isocentric scan could cause gantry-patient collisions. Using
optimization-based reconstruction methods, patient-specific, collision
avoiding imaging trajectories that utilize virtual isocenter CBCT
scans and different kV-detector magnifications can be reconstructed by
incorporating the view-by-view imaging and patient geometry into the
system matrix. Image quality, as characterized by spatial resolution
and low contrast object detectability, is comparable for virtual
isocenter scans and for standard isocentric scans using different
magnification bumps to avoid kV-detector collisions. Thus, virtual
isocenter CBCT scans and kV-detector magnification changes could be
combined with optimization-based reconstruction as a useful clinical
approach in collision-plagued situations.

* Conclusions                                :conc:
  :PROPERTIES:
  :ID:       1bade25b-80d6-4650-b8a3-baf370fa657c
  :END:
In this dissertation work, we developed a framework that leverages
optimization-based reconstruction methods to enable generalized,
non-circular, scanning trajectories in CBCT. Where analytic-based
reconstruction methods require a prescribed trajectory in order to
derive an analytic inverse, optimization-based methods require no such
assumption regarding the trajectory by which the projection views were
acquired. This agnosticism of optimization-methods to the order and
geometry by which projections are acquired allows for dynamic,
view-by-view modifications to the scanning trajectory that would be
untenable if the scanning trajectory were fixed by necessity of the
reconstruction program's requirements.

We describe our generalized framework for reconstructing from
generalized scanning trajectories using optimization-based
reconstruction methods in [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Chapter 2]]. Though we limited ourselves to
MLEM to solve our reconstruction problem, we by no means imply that
this framework is dependent on this algorithm. Not only can other
optimization-based algorithms be plugged into this framework, more
sophisticated optimization techniques may be better suited to this
optimization problem. However, regardless of the optimization-based
algorithm employed in this paradigm, it is always critical that the
user ensure that the parameters of the algorithm are carefully
selected for the desired task.

In addition to developing this framework, we also developed a general
calibration procedure in [[id:652970b8-4916-4190-b83b-2d6ae117c8b3][Chapter 3]] that would accommodate view-by-view
corrections to the different non-circular trajectories we studied. We
then proceeded to use this calibration protocol to make calibration
corrections for the non-circular trajectory classes we studied in the
subsequent chapters. Though optimization-based algorithms are very
robust, the view-by-view agnosticism we utilize for our trajectory
framework is only beneficial if the geometry describing each of the
views in the system matrix is correct. As with all inverse problems,
the answer provided by the inverse is only useful if you have solved
the right problem.

As our investigation into different non-circular trajectories was
motivated by existing clinical limitations currently encountered in
using linac-mounted CBCT for IGRT, we then found two clinical examples
where the ability to use non-circular trajectories could provide a
solution. By first selecting two particular tasks to test our
framework, we were able to constrain our investigation of the
trajectory parameters that were relevant to solving these problems.
Just as the parameters of the optimization program must be selected
for the desired task, similar task-based considerations must be given
to selecting what type of non-circular trajectory, if any, would be
suited for intended application.

The first clinical limitation we studied in [[id:eaae199f-f899-4862-af50-720895a31c36][Chapter 4]] is the problem
of the limited axial FOV provided by linac-mounted CBCT systems. Since
the axial coverage provided by the CBCT detector is limited by
engineering constraints, we hypothesized that non-circular
trajectories would be able to extend the axial FOV while maintaining
image quality that is comparable to current clinical methods. In
addition to studying the double circle trajectory that is comparable
to the current clinical practice of stacking the independently
reconstructed FDK volumes of two circles together, we also studied the
circle-line-circle and smooth trajectory classes that include
acquiring projections as the CBCT imaging system translates between
the two planes of the circular components of the scan. We found that
not only does our framework with MLEM perform as well as FDK in the
portion of the reconstructed volume where FDK satisfies Tuy's
condition, but that it is also able to improve the image quality in
the region between the planes of the source's circular orbit.
Additionally, our framework demonstrated that it is possible to extend
the axial spacing between the planes of the two circles into distances
that exceed the support of two stacked FDK volumes.

The second clinical problem in using linac-mounted CBCT for IGRT that
we investigated in [[id:99055e18-4b61-404e-9408-ebd5fd0a5d8d][Chapter 5]] is that of potential patient collisions
with the linac when attempting to acquire a CBCT. For some of the
treatment positions used for breast, lung, and head and neck cancer
patients, the orientation of the patient on the treatment table puts
them at risk of being hit by the linac as it rotates around the
patient. In this study, we investigated different non-circular
trajectories that could alleviate the different types of collisions
potentially faced by these patients. One such trajectory would
increase the radius of the kV-imaging detector in a potential
collision zone to create a dynamic magnification trajectory. To avoid
potential collisions with the linac treatment head, we studied a
virtual isocenter trajectory that moved the patient couch while the
gantry rotated to maintain a safe distance between the patient and
treatment head to ensure no collision would take place. Finally, we
created a trajectory that combined the virtual isocenter trajectory
with the dynamic magnification in order to create a trajectory that
could alleviate collisions with both the kV-detector and the treatment
head. For each of these different configurations, we showed we could
obtain reconstructions with image quality comparable to the standard
clinical circular trajectory.

In conclusion, we found that our non-circular scanning trajectory
framework using optimization-based reconstruction methods have the
potential to address limitation of linac-mounted CBCT for IGRT. We
selected specific non-circular trajectories that we knew had the
potential to address real clinical limitations. In finding that the
subsequent image quality was no worse than that achieved by the
existing clinical methods, we hopefully demonstrated that these
non-circular scanning trajectories have the potential to address
limitations of CBCT in IGRT. Though we did not explicitly study any
other application here, we do not think this framework is limited to
these two applications or even solely to the purview of radiotherapy.
In selecting the two examples shown here, we have only wished to
demonstrate the potential utility enabled by non-circular trajectories
with optimization-based reconstruction. As with all tomographic
reconstruction problems, careful consideration must be given to the
desired task and further task-based metric analysis must be performed
to evaluate not only the performance of the chosen reconstruction
chain, but also to that of the chosen scanning trajectory.

\makebibliography
